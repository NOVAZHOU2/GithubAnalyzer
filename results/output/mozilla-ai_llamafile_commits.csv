项目名称,项目URL,提交ID,提交者,提交时间,提交信息,提交链接
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9509d91,Nathan Brake,2025-11-05T17:06:18Z,feat: move docs to mkdocs (#824)  * feat: move docs to mkdocs  * Refactor so that docs are direct copy paste  * Fix links  * Update README.md  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>  * Update docs/quickstart.md  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>  * Apply suggestions from code review  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>  ---------  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>,https://github.com/mozilla-ai/llamafile/commit/9509d911179dcb18ca61ee9e45de26d29c4f9bd5
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9d975d0,Nathan Brake,2025-11-04T15:42:46Z,"chore: llama.cpp as submodule (#819)  * feat: integrate whisper.cpp as a submodule with patches  * simplify naming  * Not final state but wanted to get this up: with these edits now the apply-patches script perfectly lines up with the current whisper.cpp folder in the main branch  * apply patches in CI  * Update ci.yml  * Update ci.yml  * fix: register whisper.cpp submodule  * pin whisper.cpp to commit  * move to patches  * patches  * Refactor  * convert stable diffusion to submodule  * llama.cpp as submodule  * add to make setup  * whitespace  * patch all deps  * Fix whitespace issues  * Cleanup of files that are both renamed and copied, part 1  * further cleanup  * split patches out into their own files  * Update llama.cpp.patches/apply-patches.sh  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>  ---------  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>",https://github.com/mozilla-ai/llamafile/commit/9d975d095e6cfceac01f4586ad601136efaeaed4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7ee25fe,Nathan Brake,2025-11-03T18:48:55Z,chore: convert stable diffusion to submodule (#818)  * feat: integrate whisper.cpp as a submodule with patches  * simplify naming  * Not final state but wanted to get this up: with these edits now the apply-patches script perfectly lines up with the current whisper.cpp folder in the main branch  * apply patches in CI  * Update ci.yml  * Update ci.yml  * fix: register whisper.cpp submodule  * pin whisper.cpp to commit  * move to patches  * patches  * Refactor  * convert stable diffusion to submodule  * allow manual trigger,https://github.com/mozilla-ai/llamafile/commit/7ee25fea6360a2a2f8b45006ca004d2db74158b2
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1a5d1c2,Nathan Brake,2025-11-03T18:12:27Z,chore: integrate whisper.cpp as a submodule (#813)  * feat: integrate whisper.cpp as a submodule with patches  * simplify naming  * Not final state but wanted to get this up: with these edits now the apply-patches script perfectly lines up with the current whisper.cpp folder in the main branch  * apply patches in CI  * Update ci.yml  * Update ci.yml  * fix: register whisper.cpp submodule  * pin whisper.cpp to commit  * move to patches  * patches  * Refactor  * Update Makefile  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>  ---------  Co-authored-by: Davide Eynard <davide.eynard@gmail.com>,https://github.com/mozilla-ai/llamafile/commit/1a5d1c2e5bc9fdb8c2e0192d93dfe716f7fdd4de
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6b46419,Nathan Brake,2025-10-31T16:26:26Z,chore: Update README.md to include call for community feedback on llamafile (#812)  * Update README.md to include a call for community feedback on llamafile  * Update README.md to include a call for community feedback on llamafile,https://github.com/mozilla-ai/llamafile/commit/6b464191def244cd9f97bba098129424672196fb
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,cfa861a,CJ Pais,2025-06-30T19:03:05Z,Merge pull request #760 from henfiber/accept-content-array  Accept array in chat message content field,https://github.com/mozilla-ai/llamafile/commit/cfa861a69cb9fb3b1101d1c435ec6c2bfa35365c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1562542,henfiber,2025-06-01T04:05:48Z,accept array in chat message content field,https://github.com/mozilla-ai/llamafile/commit/15625421c83c8b18042c57160da439c32b934702
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ff0c02e,CJ Pais,2025-05-14T22:05:36Z,Release llamafile v0.9.3,https://github.com/mozilla-ai/llamafile/commit/ff0c02e6c560d88324966e88a718485989b41c1e
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,51b357b,CJ Pais,2025-05-13T19:48:05Z,Merge pull request #743 from cjpais/qwen3-support  Qwen3 Support,https://github.com/mozilla-ai/llamafile/commit/51b357b9774796d455716134c323477156a4c7b7
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e7b29e1,CJ Pais,2025-05-13T19:45:58Z,use code from ik,https://github.com/mozilla-ai/llamafile/commit/e7b29e19119e17be6bca372f9da63a9655873c78
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5d67144,CJ Pais,2025-04-30T18:42:23Z,add names of models in,https://github.com/mozilla-ai/llamafile/commit/5d67144ccf42742a0bdf5b34922e4ba2665fdba6
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,bd1bbe9,CJ Pais,2025-04-21T18:29:37Z,Merge pull request #744 from cjpais/phi4-support  Add phi4 support,https://github.com/mozilla-ai/llamafile/commit/bd1bbe9aabb1ee12dbdcafa8936db443c571eb9d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e6daab0,CJ Pais,2025-04-16T14:17:09Z,"Merge pull request #745 from cjrh/patch-1  Update README.md, fix llama 8B table stats",https://github.com/mozilla-ai/llamafile/commit/e6daab04b51482009bf598a7cdaddeed8a1ba197
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a06e3b2,Caleb Hattingh,2025-04-16T09:40:11Z,"Update README.md, fix llama 8B table stats",https://github.com/mozilla-ai/llamafile/commit/a06e3b2a242785a152bcab4995d9e3af39bc59f6
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a4ece76,CJ Pais,2025-04-13T19:43:02Z,add phi4 support,https://github.com/mozilla-ai/llamafile/commit/a4ece762cae2708b611ed5fbaae3a463ff2f7c8a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8348de9,CJ Pais,2025-04-13T19:12:01Z,qwen3,https://github.com/mozilla-ai/llamafile/commit/8348de9a18360b32247afbd528e60fe1bbea8345
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c7f379e,CJ Pais,2025-04-11T15:31:33Z,fix crash if messages key does not exist,https://github.com/mozilla-ai/llamafile/commit/c7f379e2502cdc6b45164c660870e6a1640441af
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7998b11,CJ Pais,2025-04-09T23:17:47Z,Merge pull request #742 from cjpais/localscore-plaintext  Add Plaintext output option to LocalScore + Respect NO_COLOR env var,https://github.com/mozilla-ai/llamafile/commit/7998b11b63f57860c72eb2f9fd576a073e82e69d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d108545,CJ Pais,2025-04-09T23:11:42Z,disable for ascii 0,https://github.com/mozilla-ai/llamafile/commit/d108545b676512c33298c7ee139ed445bcbb0a9f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,81da07b,CJ Pais,2025-04-09T23:09:40Z,respect user NO_COLOR preference in localscore,https://github.com/mozilla-ai/llamafile/commit/81da07b34c7ad5f4bb5d2aa69199838642fa20d5
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f4d2640,CJ Pais,2025-04-09T22:49:41Z,add plaintext cli option to print results in plaintext,https://github.com/mozilla-ai/llamafile/commit/f4d2640553d9af55256182c9963750edc8ae3fdc
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,cf1cc74,CJ Pais,2025-04-09T22:29:33Z,Merge pull request #733 from dmcardle/js-fix-relative-url  Preserve URL path when building relative URLs in JS,https://github.com/mozilla-ai/llamafile/commit/cf1cc74af34cb9141a84f5d03b70507831c0b0a0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5d69a67,CJ Pais,2025-04-07T17:01:07Z,Merge pull request #740 from rsanheim/patch-1  Fix link to troubleshooting guide,https://github.com/mozilla-ai/llamafile/commit/5d69a67da57c2762bcb3f0ef16b4b24d79d50e41
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1e35ba7,Rob Sanheim,2025-04-06T23:15:55Z,Fix link to troubleshooting guide  The current link 404s.,https://github.com/mozilla-ai/llamafile/commit/1e35ba769e7bdb56f8926ded998d9d20f8e21c24
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,b49946f,Dan McArdle,2025-03-29T21:49:12Z,"Preserve URL path when building relative URLs in JS  It's necessary to preserve the path because the server might be hosted under a subdirectory, specified by `--url-prefix`.  Fixes #732",https://github.com/mozilla-ai/llamafile/commit/b49946f4ad4992483a745c9948ec403a36f075c7
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1e777d2,CJ Pais,2025-04-03T19:07:57Z,Update README.md  update llamafile table,https://github.com/mozilla-ai/llamafile/commit/1e777d2734f9796802e7bf6f59ad81454f6e7091
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,764b51f,CJ Pais,2025-04-03T16:16:06Z,Release llamafile v0.9.2,https://github.com/mozilla-ai/llamafile/commit/764b51f015ded7deed9bb358f555ce82508c3fcd
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,11fe18e,CJ Pais,2025-04-02T21:18:27Z,"Merge pull request #734 from cjpais/LocalScore  This PR introduces LocalScore, an open-source benchmarking tool that measures LLM performance on local hardware. Key features include:  - Measures prompt processing speed, generation speed, and time-to-first-token - Supports CPU/GPU benchmarking across Windows/macOS/Linux - Provides a unified scoring system via geometric mean of metrics - Optional submission to public leaderboard at [localscore.ai](https://localscore.ai) - Multiple execution options (standalone binary, llamafile integration)  The tool collects anonymous hardware specs and performance metrics to help users compare different setups. Includes CLI interface with options for: - GPU backend selection - Multiple test repetitions - Result submission control  Built as part of the Mozilla Builders program.  **Usage Examples:** ```bash # Basic benchmark ./localscore -m model.gguf  # CPU-only test with extended repetitions ./localscore -m model.gguf --cpu --extended  # Automatic result submission ./localscore -m model.gguf -y ```  Further details can be found in the README.",https://github.com/mozilla-ai/llamafile/commit/11fe18e7babc069ef88357a8b08df3056229a208
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5748e86,CJ Pais,2025-04-01T17:02:10Z,Introduce LocalScore CLI,https://github.com/mozilla-ai/llamafile/commit/5748e861ae2a3b2c865dcaec6649c0545cbd4a1f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a9658c7,CJ Pais,2025-03-24T16:36:01Z,Merge pull request #727 from corebonts/incomplete-utf  Avoid streaming incomplete UTF-8 characters,https://github.com/mozilla-ai/llamafile/commit/a9658c7a13b76f914780cdbef71fc22e72254878
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fb7ce5a,CJ Pais,2025-03-24T16:11:16Z,Merge pull request #719 from corebonts/copy-info-buttons  Add copy and info buttons to the chat window and improve small screen UX,https://github.com/mozilla-ai/llamafile/commit/fb7ce5a3a512ae749da5e6cef38fd2b78d5bbc4c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e7e7e83,CJ Pais,2025-03-24T16:10:34Z,slight modifications for display,https://github.com/mozilla-ai/llamafile/commit/e7e7e830d9f1d380bd38ecdab2712ff62848d2fd
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8ff1f50,corebonts,2025-03-21T21:28:05Z,"Avoid streaming incomplete UTF-8 characters  Some characters, like the chinese fù is sometimes returned as two tokens, as ""\u00e8\u00b5"" and ""\u008b"" in this case.  This is also depends on the model, but when it happens, for example with DeepSeek R1, we have to wait for the character to be complete and send it only then.  This resolves #722 and #646",https://github.com/mozilla-ai/llamafile/commit/8ff1f5086b57001e9e327345512f87753fb3ebbc
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,b2e8da7,corebonts,2025-03-20T20:40:39Z,"Improve response stats accuracy  Start the timer when the request is sent, not when the first chunk is received.",https://github.com/mozilla-ai/llamafile/commit/b2e8da7fc68cffe5492a5e7dbc7b14e479605dc3
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0458d9d,corebonts,2025-03-20T20:38:34Z,Show reponse stats also when info button is toggled  This way it is also possible to show it on touch devices.,https://github.com/mozilla-ai/llamafile/commit/0458d9d75fb6184e22170e836e3e1176c65a3b2a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,17c4c7a,corebonts,2025-03-20T17:51:08Z,"Improve small and touch screen experience  - Full screen ""chat application like"" interface on small screens - Smaller spacings and header",https://github.com/mozilla-ai/llamafile/commit/17c4c7a483cbfa535c1da2e18fabf3d5dd4a7c58
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,33f561d,Stephen Hood,2025-03-20T17:24:01Z,Update README.md  Update link to Builders web site.,https://github.com/mozilla-ai/llamafile/commit/33f561d31fed806da84820e8fb32d1d97ca8b664
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7bfb94d,corebonts,2025-03-16T18:53:39Z,Add response stats to the chat,https://github.com/mozilla-ai/llamafile/commit/7bfb94dbf05460b12fa38f968264da0283dd99f8
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7d8f412,corebonts,2025-03-14T22:34:52Z,Add copy to clipboard function to chat messages,https://github.com/mozilla-ai/llamafile/commit/7d8f412a4140dc97efee16eea93d78c4c793ebda
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,2a4430c,corebonts,2025-03-14T20:04:40Z,Make copy button reusable,https://github.com/mozilla-ai/llamafile/commit/2a4430c46d3aa995fd46f44e02566631ebb4d794
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9053d43,corebonts,2025-03-16T18:02:46Z,Avoid chat-container touching the sides,https://github.com/mozilla-ai/llamafile/commit/9053d43d7d92b87353f9b4c1be672c19b62286f3
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f0d65b6,CJ Pais,2025-03-18T17:36:42Z,Merge pull request #717 from corebonts/gemma3  Initial support for Gemma 3 models,https://github.com/mozilla-ai/llamafile/commit/f0d65b65757afdf9949a55cf72fd1833327617ce
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4d20599,CJ Pais,2025-03-18T17:34:08Z,use n_swa_pattern from llama.cpp #12373,https://github.com/mozilla-ai/llamafile/commit/4d205992a31d877436cf973b0af15a6e60bdba5b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f6b3831,corebonts,2025-03-17T21:11:39Z,Initial support for Gemma 3 models  Tested only on text-to-text.,https://github.com/mozilla-ai/llamafile/commit/f6b3831072ea98930256535b488c6ce9eceec8d3
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,17d7f4a,CJ Pais,2025-03-17T18:19:38Z,Merge pull request #608 from gabe-l-hart/GraniteThreeSupport  Granite three support,https://github.com/mozilla-ai/llamafile/commit/17d7f4a5c0d6c8aaf9d03e2bb82f2161fa7db71c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f44916f,Gabe Goodhart,2025-03-14T22:53:58Z,"fix: Detect Granite for models where the template got truncated  For some Granite models, the jinja2 template string is very long and gets truncated when converting to GGUF. The string ""Granite"" appears in the default system prompt logic, so this will catch those models that were truncated before the clause for the <|start_of_role|> token.  NOTE: Any future granite architectures which contain ""Granite"" in the system prompt will need to include their logic _before_ this block.  Branch: GraniteThreeSupport  Signed-off-by: Gabe Goodhart <ghart@us.ibm.com>",https://github.com/mozilla-ai/llamafile/commit/f44916fe8f60dd95593e01a9fc8a921ea7c20519
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f9ab15a,Gabe Goodhart,2024-11-04T23:55:18Z,feat(granite*): Add granite chat template  Branch: GraniteThreeSupport  This is a port of the work done in llama.cpp with a slight tweak for the tool call response: https://github.com/ggerganov/llama.cpp/pull/10013  Signed-off-by: Gabe Goodhart <ghart@us.ibm.com>,https://github.com/mozilla-ai/llamafile/commit/f9ab15ac1ef25bcb76f5a7a7d783f484f92b8663
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fc90175,Gabe Goodhart,2024-11-04T22:28:56Z,"feat(granitemoe): Add support for ""granitemoe"" architecture  This is a port of the work done in llama.cpp directly https://github.com/ggerganov/llama.cpp/pull/9438  Branch: GraniteThreeSupport  Signed-off-by: Gabe Goodhart <ghart@us.ibm.com>",https://github.com/mozilla-ai/llamafile/commit/fc90175c00bbb3a6257f95763f9c46da3dea4cf4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,dc8d208,Gabe Goodhart,2024-11-02T00:32:22Z,"feat(granite): Add support for the ""granite"" architecture in llama.cpp  This is a port of the work done in llama.cpp directly https://github.com/ggerganov/llama.cpp/pull/9412  Branch: GraniteThreeSupport  Signed-off-by: Gabe Goodhart <ghart@us.ibm.com>",https://github.com/mozilla-ai/llamafile/commit/dc8d208fe0694b6b9dc11f1ae704d14f2c61a885
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9d92413,CJ Pais,2025-03-14T20:33:26Z,Merge pull request #585 from halter73/patch-1  Update WSL troubleshooting in README.md,https://github.com/mozilla-ai/llamafile/commit/9d92413afd793666fdeebaa00bdea94e4b51b56b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0b4aab8,CJ Pais,2025-03-14T19:02:56Z,Merge pull request #713 from corebonts/openai-compatibility  Improve OpenAI compatibility for /v1/* endpoints,https://github.com/mozilla-ai/llamafile/commit/0b4aab8ad40a0bef929147e2cd1dc40b46fce58d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,480b76f,CJ Pais,2025-03-14T18:40:58Z,Merge pull request #635 from rgroesslinger/main  add stable-diffusion.cpp to install target (fix #580),https://github.com/mozilla-ai/llamafile/commit/480b76f8c40b583c6185af5a885bcaca4e961286
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c344ac7,CJ Pais,2025-03-14T18:38:13Z,Merge pull request #712 from corebonts/button-arrangement  Unify button look and rearrange buttons to make them more compact,https://github.com/mozilla-ai/llamafile/commit/c344ac7805b8646c8cf4a13c3fd7cb671cb62f13
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0e529dd,CJ Pais,2025-03-14T18:32:09Z,Merge pull request #707 from alonsosilvaallende/add-whisperfile-server-documentation  Add whisperfile server documentation,https://github.com/mozilla-ai/llamafile/commit/0e529dd35abbf36d1001b16d2afdcb287c467631
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8ffca8b,CJ Pais,2025-03-14T18:31:22Z,"--convert doesn't exist for whisperfile, add notes on conversion",https://github.com/mozilla-ai/llamafile/commit/8ffca8b6c6aabf2ed6b011a4f3c161f67dd0f58f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6adc143,CJ Pais,2025-03-14T18:21:14Z,Merge pull request #681 from emilbayes/fix/js-translate-bug  Fix translation bug from cpp to js in TS highlight,https://github.com/mozilla-ai/llamafile/commit/6adc14319b0b0f2f801ff45bd954fc476555b441
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,da28043,CJ Pais,2025-03-14T18:03:23Z,Merge pull request #641 from sizvix/patch-1  URL constructor to get a clean url_prefix (fix #640),https://github.com/mozilla-ai/llamafile/commit/da28043b81c49fddc3b4eacaff7b65b321ae36c7
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8dc2684,CJ Pais,2025-03-14T17:55:10Z,Merge pull request #637 from Mozilla-Ocho/heaversm-code-completion-documentation  Update server readme with code completion (FIM) example,https://github.com/mozilla-ai/llamafile/commit/8dc2684ee1229c3333b8363790d56d0c44924876
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ceff0cb,CJ Pais,2025-03-14T16:54:51Z,Merge pull request #607 from mseri/patch-1  [llamafiler] doc/v1_chat_completions.md: remove duplicate entry,https://github.com/mozilla-ai/llamafile/commit/ceff0cbecdafe646051aaefe8a50787c63fe48b6
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,01cc848,corebonts,2025-03-14T05:16:39Z,Add missing documentation for OpenAI compatible endpoints,https://github.com/mozilla-ai/llamafile/commit/01cc848a23154a603431b884a8f67d433d574eb4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,82b9831,corebonts,2025-03-14T05:15:35Z,"Add /v1/models endpoint  This is usually used by OpenAI clients, like OpenWebUI for discovery and health check.",https://github.com/mozilla-ai/llamafile/commit/82b9831919515a9072dc7cc0f3f4ee46fa40caf8
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,97167eb,corebonts,2025-03-14T05:14:50Z,Add stream_options parameter for OpenAI compatible endpoints,https://github.com/mozilla-ai/llamafile/commit/97167eb633955bc8bd9daf36f67b76c1968dab3f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,43d8f44,corebonts,2025-03-13T17:55:05Z,Apply styles from the chat mode to the completion mode also  - images - button styles - textarea style,https://github.com/mozilla-ai/llamafile/commit/43d8f44748707a332f7ec61c600ee0166168a02f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,11dae28,corebonts,2025-03-12T20:36:37Z,Unify button look and rearrange buttons to make them more compact,https://github.com/mozilla-ai/llamafile/commit/11dae281df64949372f702bd65c93b37b81fb5d9
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,50cd8f1,corebonts,2025-03-12T20:35:29Z,Add button icon for the menu-trigger,https://github.com/mozilla-ai/llamafile/commit/50cd8f1eb71a00082ca8170a6a65098decbdfbe0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6d51f81,corebonts,2025-03-12T20:30:24Z,Replace button icons with fontawsome basic SVGs  It gives a more consistent look.,https://github.com/mozilla-ai/llamafile/commit/6d51f81082f84a875b125bbbfae5e8764ea51c99
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,dd75ece,CJ Pais,2025-03-10T19:05:46Z,Release llamafile v0.9.1,https://github.com/mozilla-ai/llamafile/commit/dd75ecebf3860f6364eee4d54ffef23f463e2aca
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c4c08fe,CJ Pais,2025-03-04T21:42:04Z,Merge pull request #705 from cjpais/cjpais/revert-cosmo-4.0  Revert Cosmopolitan to 3.9.7,https://github.com/mozilla-ai/llamafile/commit/c4c08fe4b8e755997e9c85f4710eeac315ca3e2c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9f1f8ab,Alonso Silva,2025-03-04T07:50:33Z,Change title,https://github.com/mozilla-ai/llamafile/commit/9f1f8aba7d05d20ac63bc68f6a7c2cb8a4b164a4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4f1fae4,Alonso Silva,2025-03-04T06:48:16Z,Add whisperfile server documentation,https://github.com/mozilla-ai/llamafile/commit/4f1fae42d7f103adea5bb987cf889606040fa43e
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,db27540,CJ Pais,2025-03-03T21:54:39Z,revert to 3.9.7,https://github.com/mozilla-ai/llamafile/commit/db27540177241d8f4bf1e1f635adedb08833d2ed
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,29b5f27,CJ Pais,2025-01-30T00:07:37Z,Merge pull request #687 from Xydane/main  Add Support for DeepSeek-R1 models,https://github.com/mozilla-ai/llamafile/commit/29b5f27172306da39a9c70fe25173da1b1564f82
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,72a5f8d,Peter Wilson,2025-01-29T23:32:32Z,Updated README to reflect WSL 2 command for Windows 11 (#685),https://github.com/mozilla-ai/llamafile/commit/72a5f8d7475101ed1c6c70486880ea19b7eca5f5
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5d81c75,Brian,2025-01-29T23:31:29Z,Update Makefile: Fix PHONY (#683),https://github.com/mozilla-ai/llamafile/commit/5d81c7548dec73760d275bfc26b11f04941f2a67
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7af1115,Xydane,2025-01-29T18:33:13Z,remove space,https://github.com/mozilla-ai/llamafile/commit/7af11153b064a7f2859d9f7f05c5b0d0bdaac7eb
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8542280,Xydane,2025-01-29T18:29:50Z,add support for DeepSeek-R1 models,https://github.com/mozilla-ai/llamafile/commit/85422801531799dcecf33f85ef92a2923622cd22
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d57c145,Emil Bay,2025-01-18T08:58:57Z,Fix translation bug from cpp to js in TS highlight,https://github.com/mozilla-ai/llamafile/commit/d57c145dabf3018b4cd99f3f0f54d09d4fa9ca37
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ef7321e,Justine Tunney,2025-01-05T22:41:31Z,Release llamafile v0.9.0,https://github.com/mozilla-ai/llamafile/commit/ef7321e01cf384ca9cb99178671185d969beb290
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e64c7e2,Justine Tunney,2025-01-05T22:39:58Z,Include llamafiler in llamafile binary  It's now possible to say:      llamafile --server --v2 --help     llamafile --server --v2  To use llamafiler from any llamafile binary.,https://github.com/mozilla-ai/llamafile/commit/e64c7e2c62bf559625495970342ab7358a5cab36
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c293359,Justine Tunney,2025-01-03T07:16:13Z,Upgrade to Cosmopolitan v4.0.0,https://github.com/mozilla-ai/llamafile/commit/c2933599286e6d58e63916e4494fdd3b30363ce7
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a8fd4d2,Justine Tunney,2024-12-14T13:06:01Z,"Improve management of multiple slots  The server now does a better job picking the most appropriate slot, when servicing multiple independent completion sessions.",https://github.com/mozilla-ai/llamafile/commit/a8fd4d28c3d2259c98af7035bcdda1a68af6f62c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,38677b5,Justine Tunney,2024-12-14T01:55:40Z,"Support relocating matching suffixes in KV cache  The chat completions endpoint is now able to relocate matching suffixes. It'll happen automatically when your conversation history gets too long. You can also remove messages from the middle of your chat history as the client, and the same optimization will still take place. This grants the new server a higher degree of user control and flexibility than upstream in llama.cpp whose server allows only a single hard-coded system prompt.  This change fixes an issue created by the previous change where upon the context window being filled up, each new chat message typed into the web ui would result in the prefill progress bar appearing because the latter portion of the conversation would need to be reprocessed, after old chat history was deleted. Now all the unpleasant user visible latency is gone",https://github.com/mozilla-ai/llamafile/commit/38677b55ebe9a3a1071f3b5efa3891e8ff059771
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,956e62c,Justine Tunney,2024-12-13T23:25:08Z,Visually indicate messages truncated by context,https://github.com/mozilla-ai/llamafile/commit/956e62ce2765cc2d1c921b3e7b90938b67c19c17
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,08e7a21,Justine Tunney,2024-12-13T22:57:51Z,Forget old messages when running out of context,https://github.com/mozilla-ai/llamafile/commit/08e7a21b68942ea75842b13eef4c281c1f652412
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4158265,Justine Tunney,2024-12-13T13:36:28Z,Show progress bar for prompt processing in web ui,https://github.com/mozilla-ai/llamafile/commit/4158265e6baa627586d043da68d45849ba993604
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fe514ef,Justine Tunney,2024-12-13T11:46:45Z,Add svg for modal close button,https://github.com/mozilla-ai/llamafile/commit/fe514ef73d904d31d9d50b07ecfa65508c889a0a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,43bc1eb,Justine Tunney,2024-12-13T08:02:21Z,Improve buttons in web ui,https://github.com/mozilla-ai/llamafile/commit/43bc1eb28d558e9ed162ad8b0297d2743eac7033
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f51e535,Justine Tunney,2024-12-13T07:41:32Z,Fix emoji editing in chatbot,https://github.com/mozilla-ai/llamafile/commit/f51e5358d09fa5170646bd62edee63c4e8b4c208
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8fa1702,Justine Tunney,2024-12-10T19:33:00Z,Improve pledge() and avoid CUDA exit() in server,https://github.com/mozilla-ai/llamafile/commit/8fa170252e43971703a3f59e887555dbc69a5529
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,59a5d97,Justine Tunney,2024-12-10T19:05:20Z,Remove early cleanup in server,https://github.com/mozilla-ai/llamafile/commit/59a5d97929b966dcaf7428c35b5d31b4ddf43672
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9b03e32,CJ Pais,2024-12-05T15:51:09Z,Call appropriate hip api's (#651),https://github.com/mozilla-ai/llamafile/commit/9b03e32f8a40252f239ee14cb976bcf5ec5f1710
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1fc35e2,Justine Tunney,2024-12-05T05:17:30Z,"Add upload button and support text files  Previously we could drag and drop image files, as well as paste them, in the new llamafiler web ui. Now there's an upload paperclip icon, to make this feature more obvious. Text files are now supported too, in addition to images, which can be helpful for summarization.",https://github.com/mozilla-ai/llamafile/commit/1fc35e20d023e11ca9816a264a43bb1e2427a91e
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,508ea3a,Justine Tunney,2024-12-01T01:00:05Z,Bump llamafile version in readme,https://github.com/mozilla-ai/llamafile/commit/508ea3a125d82d7d93157ea454171003c50c146a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c88f2d3,Justine Tunney,2024-12-01T00:12:03Z,Release llamafile v0.8.17,https://github.com/mozilla-ai/llamafile/commit/c88f2d3b7163c0da6cab68b2fbc19f28153bf645
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4f88da6,Justine Tunney,2024-11-30T22:04:33Z,Document new server flags,https://github.com/mozilla-ai/llamafile/commit/4f88da6ea11b2a614c77cee842f675303ee50431
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6d89f8f,Justine Tunney,2024-11-30T21:27:37Z,Add binary safety check to server,https://github.com/mozilla-ai/llamafile/commit/6d89f8fe9cea5618dd0c572ffa13e8729dee6f20
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,36696f3,Justine Tunney,2024-11-30T03:34:34Z,Add preliminary chat history functionality,https://github.com/mozilla-ai/llamafile/commit/36696f3764dc0947181690ecee368779d1e4ac67
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,abe0d1d,Justine Tunney,2024-11-29T07:57:14Z,Begin setting up chat history database,https://github.com/mozilla-ai/llamafile/commit/abe0d1dc5a6cde8f4cec3c91c41325ef83ba6629
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d8123c7,Justine Tunney,2024-11-29T03:39:23Z,Introduce sqlite  See #644,https://github.com/mozilla-ai/llamafile/commit/d8123c73a24665d81b15958138bf7a01cee9c025
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,76cbe37,Justine Tunney,2024-11-29T03:17:11Z,Introduce mbedtls,https://github.com/mozilla-ai/llamafile/commit/76cbe3773d84d679e8cdc821dbe019556f7d82ba
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,05fa4f3,Justine Tunney,2024-11-29T00:50:21Z,Refactor package structure,https://github.com/mozilla-ai/llamafile/commit/05fa4f35c0fcbf7fb52d9b9f3056640221a97553
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,988c9ec,Justine Tunney,2024-11-26T23:46:50Z,Introduce raw completions web ui,https://github.com/mozilla-ai/llamafile/commit/988c9eccba1472b0d3b3b167d06f7b32548cb3f9
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6b228c0,Sizvix,2024-11-26T08:06:51Z,URL constructor to get a clean url_prefix  Replace the too simple regexp by URL constructor to really get clean url_prefix,https://github.com/mozilla-ai/llamafile/commit/6b228c03ae470c2601069e60053bcdad686e8685
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e5c0921,Justine Tunney,2024-11-25T19:41:08Z,Improve VT100 support,https://github.com/mozilla-ai/llamafile/commit/e5c092163e976cdd6303acdc2a00255df51b51cb
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4b61791,Justine Tunney,2024-11-25T19:07:13Z,Fix VT102 support  It turns out \e[39m wasn't introduced until ECMA-48 3rd c. 1984.,https://github.com/mozilla-ai/llamafile/commit/4b61791cfb366208bf8528bb358996c125ff7fb0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d18ddf1,Justine Tunney,2024-11-24T17:13:46Z,Add redo button to new web ui,https://github.com/mozilla-ai/llamafile/commit/d18ddf1e72cb96ca3f87c0782c96a221fe3fdb8b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,bc82424,Justine Tunney,2024-11-24T05:42:04Z,Add settings modal to web ui,https://github.com/mozilla-ai/llamafile/commit/bc82424cab81717ab7cb315c3606a0a0f7806b26
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a494bd3,Justine Tunney,2024-11-23T19:19:03Z,Disable syntax highlighting in raw completion cli,https://github.com/mozilla-ai/llamafile/commit/a494bd3f998c4002177b50d31c943cdfcde2396b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fb59488,Justine Tunney,2024-11-23T05:55:33Z,Upgrade to Cosmo v3.9.7,https://github.com/mozilla-ai/llamafile/commit/fb59488b7f2ca16899adc75e50bf252ca3e597af
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,38a77c8,Justine Tunney,2024-11-23T05:30:21Z,Display name of model at top of web ui,https://github.com/mozilla-ai/llamafile/commit/38a77c88378de74f72517d2fd2420d19df14c4a0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,12c3761,Justine Tunney,2024-11-23T04:24:59Z,Make CLI chatbot work better with base models,https://github.com/mozilla-ai/llamafile/commit/12c3761326398439c89247ac7dc1f832c0daa25a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,241bf21,Justine Tunney,2024-11-23T04:24:17Z,Introduce /v1/completions endpoint in new server,https://github.com/mozilla-ai/llamafile/commit/241bf21a30f45eadc2fb545581057a6bb9337318
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0965a4b,Justine Tunney,2024-11-23T02:07:13Z,Make some markdown improvements,https://github.com/mozilla-ai/llamafile/commit/0965a4b3c699868299abdd5cb50489c31d941dc9
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,880ebc7,Justine Tunney,2024-11-23T01:05:10Z,Handle empty system prompt better in cli chatbot,https://github.com/mozilla-ai/llamafile/commit/880ebc7902a2a052d42b7fcaf0e80f258633b284
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6f2aab2,Mike Heavers,2024-11-22T19:28:00Z,Update README.md  Add an example of using the /completions endpoint with Curl or Javascript - shows how to use Llamafile to do code completion. Could consider posting this on the main README.md as well.,https://github.com/mozilla-ai/llamafile/commit/6f2aab2176b789111c853107d2a06fb3b8f55e89
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f581c40,Justine Tunney,2024-11-22T18:33:22Z,Fix futex prototype,https://github.com/mozilla-ai/llamafile/commit/f581c400620e089808927a4d6629b15ce90975ea
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ca334a1,Justine Tunney,2024-11-22T18:32:23Z,"Revert ""Handle CTRL-C better on MacOS""  This reverts commit b0b46136ca4e49b5a0738670be2965ef682f1875.",https://github.com/mozilla-ai/llamafile/commit/ca334a1ee8ef80be5bafadf82b8b0a6cd724e655
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,b0b4613,Justine Tunney,2024-11-22T17:59:24Z,Handle CTRL-C better on MacOS,https://github.com/mozilla-ai/llamafile/commit/b0b46136ca4e49b5a0738670be2965ef682f1875
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a1a5c1f,Rainer Größlinger,2024-11-21T10:53:29Z,add stable-diffusion.cpp to install target so sdfile can be built (fixes #580),https://github.com/mozilla-ai/llamafile/commit/a1a5c1f89afb02b5a30495763789ade70d8b1235
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f27e911,Justine Tunney,2024-11-21T04:44:27Z,Sync with json.cpp,https://github.com/mozilla-ai/llamafile/commit/f27e9116d8118dd7f1d41272667aaee0ff6baaab
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,41abfa3,Justine Tunney,2024-11-16T08:28:59Z,Work around multiple image handling,https://github.com/mozilla-ai/llamafile/commit/41abfa3ea8d973b7e8847fc39755f8178f7e04f0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d30da30,Justine Tunney,2024-11-16T03:56:57Z,Syntax highlight D properly,https://github.com/mozilla-ai/llamafile/commit/d30da30e3cf834280643179f8dd296d3b21157c1
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,35bc088,Justine Tunney,2024-11-16T00:47:08Z,Make default system prompt configurable on web,https://github.com/mozilla-ai/llamafile/commit/35bc08814670c78278a1db1ca82240b923b92c87
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,81ed1cf,Justine Tunney,2024-11-15T21:57:01Z,Fix auto scroll issue in web gui,https://github.com/mozilla-ai/llamafile/commit/81ed1cf017b6b21412026863e5cfdb4d3eedc447
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9bb262b,Justine Tunney,2024-11-14T22:47:53Z,"Log CUDA kernel vs. runtime versions  The goal here is to hopefully provide a troubleshooting hint, that helps users resolve CUDA version compatibility issues.",https://github.com/mozilla-ai/llamafile/commit/9bb262b988897ba847b7303b5f11f8b11e0a7a3b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8413a21,Justine Tunney,2024-11-14T16:30:01Z,Fix Ruby builtins in web gui,https://github.com/mozilla-ai/llamafile/commit/8413a217cda326a394c98d04c03d63f1367b40a5
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0f01eb7,Justine Tunney,2024-11-14T16:23:59Z,Fix an extra backslash,https://github.com/mozilla-ai/llamafile/commit/0f01eb7481bbb6f1c01f8f98fb499eb5e386b38f
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6dd451b,Justine Tunney,2024-11-13T09:18:36Z,Make some more quality of life improvements,https://github.com/mozilla-ai/llamafile/commit/6dd451b9327209148539db6f326d88dd2e03eb1d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c21a5fc,Justine Tunney,2024-11-12T06:01:53Z,Fix syntax highlighting on web for PHP,https://github.com/mozilla-ai/llamafile/commit/c21a5fc4a8e08fa2c72ecb9309f744fb62b80709
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,30518ca,Justine Tunney,2024-11-12T05:38:28Z,Respond to HTTP OPTIONS requests,https://github.com/mozilla-ai/llamafile/commit/30518ca1b1608e0d141bd93ab7933d548d4b14c2
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,28c8e22,Justine Tunney,2024-11-12T00:02:54Z,"Scale and decimate images as needed in browser  When the user tries to embed an image file that's very large, or is in a file format that isn't supported by the backend (e.g. webp), the js code will now convert it to jpeg and lower the quality as needed.",https://github.com/mozilla-ai/llamafile/commit/28c8e22b9b43773da54fe23999f522f6ec17c939
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,46284fe,Justine Tunney,2024-11-11T22:13:54Z,"Reduce attack surface of stb_image  The downside of stb_image.h, is it lacks support for some important file formats like webp, yet includes a lot of less popular image formats that haven't been tested very well. I have personal experience fixing badness in this library over the years that can easily be caught with sanitizers so I'd rather avoid exposing more of this library than needed, on public http server endpoints.",https://github.com/mozilla-ai/llamafile/commit/46284fec81b92cb5dc39ca83da144a42857de6a9
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8a0ec61,Justine Tunney,2024-11-11T22:03:46Z,Put new server code in its own namespace,https://github.com/mozilla-ai/llamafile/commit/8a0ec61bd41dd756a580e7ee895e0b99f16cc582
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,bb917bd,Justine Tunney,2024-11-11T13:41:47Z,"Add vision model support to new server  The llamafiler v1 chat completions endpoint now lets you embed data URIs inside messages, which contain base64 encoded images, so --mmproj vision models (e.g. LLaVA) will be able to analyze them. My new web GUI now has support for image uploads too. They can be dragged and dropped just like GitHub's online markdown editor lets you do. You can also paste images.",https://github.com/mozilla-ai/llamafile/commit/bb917bdbe71d3f977ebc7d6f8145e04211cae088
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,a03b47e,Justine Tunney,2024-11-11T03:35:00Z,Refactor chatbot codebase into more files,https://github.com/mozilla-ai/llamafile/commit/a03b47e127e6a42b6b048df65f2451ebdcf93e28
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,3d5b564,Justine Tunney,2024-11-11T02:35:23Z,Optimize build latency of C++ headers,https://github.com/mozilla-ai/llamafile/commit/3d5b5645f7e719c54b26a884eaf56b4260944cd1
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4c7b7d5,Justine Tunney,2024-11-10T23:56:51Z,"Implement data URI parser  To make LLaVA simpler to use I've created an eval_string() function that accepts an arbitrary string input, which is tokenized and decoded. If it has any legal data:foo URI substrings inside it then they'll be replaced with image emdeddings and evaluated separately. This means you can embed images into your JSON chat.completion.messages using <img>, ![](data:..) or simply putting the naked data:.... uri in your message. If it decodes as a valid image file format that STB supports, then LLaVA shall see it.  This change additionally sneaks in the following improvements:  - Introduce --nologo flag for chatbot - Support --no-display-prompt in chatbot - Upgrade STB libraries to latest versions - Overhaul --help and man page documentation - Be smarter about printing \n in chatbot output - Make --gpu flag imply -ngl 999 for ease of use - Use srgb rather than linear scaling in stable diffusion - Support the --verbose flag in the chatbot to display logs - Fix the /stats command which wasn't working correctly earlier",https://github.com/mozilla-ai/llamafile/commit/4c7b7d5a4cc8a0fdb2d23667b87567183ed20e01
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d25c077,Justine Tunney,2024-11-10T08:09:58Z,"Introduce /upload and /forget commands to chatbot  The /upload command allows you to share an image or a text file with the assistant. In the case of images, it'll be printed in the terminal, then fed through LLaVA so that --mmproj vision models can analyze it for you.  The /forget command may be used to erase the oldest chat messages from a context window. This is useful for salvaging a conversation that got too long. When running out of context, the chatbot will no not exit anymore, but instead return control to the REPL so you can free up the resources.",https://github.com/mozilla-ai/llamafile/commit/d25c07745f679a68951a0adba46ca04beb47da60
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,21af0bf,Justine Tunney,2024-11-10T08:09:20Z,Import upstream bestline changes,https://github.com/mozilla-ai/llamafile/commit/21af0bf02de5c9664d05c5f49d26a6817ce9ba06
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,54d3c72,Justine Tunney,2024-11-10T08:09:02Z,Make LLaVA fast again,https://github.com/mozilla-ai/llamafile/commit/54d3c727b4d6dee17c6c1fb0a67af555de9ddc01
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9d6f89f,Justine Tunney,2024-11-10T08:08:04Z,Improve look and printability of new web ui,https://github.com/mozilla-ai/llamafile/commit/9d6f89f0ee0e031fc00534064aca0aa5eb7f1b0d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c0622da,Justine Tunney,2024-11-09T13:13:47Z,Put more work into markdown rendering,https://github.com/mozilla-ai/llamafile/commit/c0622daa4f2d3f4144c06bb77f45a982ed71c682
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,25b6910,Justine Tunney,2024-11-09T08:15:31Z,Make chatbot ui more printer friendly,https://github.com/mozilla-ai/llamafile/commit/25b69100a9876a8e6cf9e0efaae31b437b023ed9
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fa1c98f,Justine Tunney,2024-11-09T06:08:54Z,Improve markdown to html rendering,https://github.com/mozilla-ai/llamafile/commit/fa1c98f9ba6e2b0b2b2b64a911b4eb8220638841
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fb4b3e6,Justine Tunney,2024-11-09T02:54:50Z,"Fix JSON parser bug  After this change, American Fuzzy Lop has been running for 3+ hours, and it hasn't found anything else wrong with the JSON code.",https://github.com/mozilla-ai/llamafile/commit/fb4b3e6e454de9c0873ad55fe33e35cc970aae6b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,33a057e,Justine Tunney,2024-11-09T01:24:16Z,Improve Ruby some more,https://github.com/mozilla-ai/llamafile/commit/33a057ea884000d7070c54f97865a4615ba3294c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5b0fff1,Justine Tunney,2024-11-09T00:49:51Z,Improve Ruby syntax highlighting  It now passes torture tests sent to us by Jan Lelis from ruby.consulting,https://github.com/mozilla-ai/llamafile/commit/5b0fff1cdbaaff8c04bd3f2bea710a488f8e0e54
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8915432,Justine Tunney,2024-11-06T10:02:41Z,Further improve markdown to html  We now emit <li> tags. Generated <pre> tags now have a copy to clipboard button. You can now embed <em> inside <strong> and vice versa.,https://github.com/mozilla-ai/llamafile/commit/89154323633a964ca85bd53d9d5c9e1bb627e5e3
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d25fa3a,Justine Tunney,2024-11-06T07:07:18Z,Improve highlighting in new web ui  Markdown url syntax is now supported. Typos are fixed. Cmake is ported.,https://github.com/mozilla-ai/llamafile/commit/d25fa3a3d91e1f7671dab1245718ef4526e6509b
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,fdfdb13,Justine Tunney,2024-11-06T02:44:09Z,"Port remaining highlighting code to javascript  This change also sneaks in a new /slotz administrative endpoint. The new llamafiler chat completions endpoint, is now consistent with the chatbot in terms of output. We now have a STOP button in the new web GUI.",https://github.com/mozilla-ai/llamafile/commit/fdfdb136c50e6aca15e4b361afee62174f51d525
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,566cdc1,Justine Tunney,2024-11-06T02:42:34Z,Improve Gemma system prompt generation  This change leads to much better outcomes for me.,https://github.com/mozilla-ai/llamafile/commit/566cdc1bd139ab79c3f01c4a4b4973aec01d24a8
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d979a1c,Justine Tunney,2024-11-05T17:32:39Z,Add BNF syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/d979a1ca11f7fac5df480d22c2291039bc9faa71
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,4a8311a,Justine Tunney,2024-11-05T16:49:25Z,Add cmake syntax highlighting  https://x.com/cristianadam/status/1853810004740002218,https://github.com/mozilla-ai/llamafile/commit/4a8311a8feabda225a383b3af92a6d12ca334959
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0995343,Justine Tunney,2024-11-05T13:44:11Z,Add more Clojure keywords,https://github.com/mozilla-ai/llamafile/commit/099534371b38d1bf52047d4d3efd8f2dc56156db
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0068a37,Justine Tunney,2024-11-05T13:36:52Z,Make D syntax highlighting better,https://github.com/mozilla-ai/llamafile/commit/0068a3711d79c568e21f4c570ae02b2b9a2ddce5
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,3d0b56f,Justine Tunney,2024-11-05T02:51:19Z,Make text flow better,https://github.com/mozilla-ai/llamafile/commit/3d0b56f96ff194bd282a11afff53171171884d60
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ef08074,Justine Tunney,2024-11-05T02:44:43Z,Start porting syntax highlighter to JavaScript,https://github.com/mozilla-ai/llamafile/commit/ef08074f3346b33d850fa6d1f594e16f61767460
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9b96502,Justine Tunney,2024-11-04T06:42:27Z,Improve JS/HTML syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/9b965020c5707e0ab236dca27e4a5a8cafd1d509
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,14713b5,Justine Tunney,2024-11-04T05:27:11Z,Get basic chatbot web gui working in llamafiler,https://github.com/mozilla-ai/llamafile/commit/14713b51d10120669139b3bb7e89e06b6a4d99e4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,40e92cf,Justine Tunney,2024-11-03T22:46:36Z,Add Ocaml syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/40e92cf14c2bf770bd049eb77a54838944cba449
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,0e077f8,Marcello Seri,2024-11-03T12:49:26Z,v1_chat_completions.md: remove duplicate entry,https://github.com/mozilla-ai/llamafile/commit/0e077f8e9aa69618efcdca463bacd619f7f24a4e
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,01b8d49,BIGWONG,2024-11-02T23:37:56Z,Remove n-gpu-layer limitation (#534),https://github.com/mozilla-ai/llamafile/commit/01b8d49443eaf460bc6b848cbc8166cf833f2995
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f5a0bd4,Justine Tunney,2024-11-02T07:23:23Z,Fix JS regex highlighting issue,https://github.com/mozilla-ai/llamafile/commit/f5a0bd4f32c10b9873ec27bb7db67a6164dfc934
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,2807ae6,Justine Tunney,2024-11-02T05:21:47Z,Improve Ada syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/2807ae6f5f8469d762736e715faf40ad04832963
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,011d720,Justine Tunney,2024-11-02T03:32:56Z,Release llamafile 0.8.16,https://github.com/mozilla-ai/llamafile/commit/011d720449896784cce935466e0d627342abddd0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,24a4b87,Justine Tunney,2024-11-02T03:14:05Z,Allow new completions endpoint to reuse slots  The llamafiler server also supports GPU now.,https://github.com/mozilla-ai/llamafile/commit/24a4b87ff642880f8487c361243a9e3dcb27b196
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ee4b51a,Justine Tunney,2024-11-01T09:47:19Z,Upgrade to Cosmopolitan v3.9.6,https://github.com/mozilla-ai/llamafile/commit/ee4b51af58b09ed6b1415f56657315faf5bbfdce
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,264e979,Justine Tunney,2024-11-01T02:15:06Z,Add Julia syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/264e97905664ced378f82208cb2f26c92cc8404e
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,8c51aad,Justine Tunney,2024-11-01T02:14:43Z,Upgrade to latest json.cpp code,https://github.com/mozilla-ai/llamafile/commit/8c51aad18f02a1acc3c19fd15d053a1db7ce2efe
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,7ba589d,Justine Tunney,2024-10-31T12:52:04Z,Add Gemma and LLaMA 3.2 links to README,https://github.com/mozilla-ai/llamafile/commit/7ba589d00d1ca9573baf9fecf9ff304c4eeb8e8c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,3d71282,Justine Tunney,2024-10-30T20:48:24Z,Release llamafile 0.8.15,https://github.com/mozilla-ai/llamafile/commit/3d71282b92c8ba3b3a3c7f694d5f42c1f2d27a74
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,532e9fe,Justine Tunney,2024-10-30T04:41:45Z,Make fixes to new chatbot features,https://github.com/mozilla-ai/llamafile/commit/532e9fe6bcf71f32ae38cc45aab204172e5a3e8c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,880894d,Justine Tunney,2024-10-30T00:23:02Z,"Make improvements to chatbot and completions api  - Introduce the /undo command in chatbot.  - Better handling of EOT token. Our last release made the mistake of not   manually inserting an end of turn token when ctrl-c interrupts the llm  - Improve handling of BOS and EOS tokens. Our last release may have   inserted EOS inappropriately as part of tokenization, even though that   should be inserted when applying the chat template.  - The new /push and /pop commands now work properly. Previous revisions   weren't recomputing the logits in the kv cache. The feature now works!  - The `stop` parameter is now supported by the chat completions api.  - The unsupported `n` parameter will be ignored if it's set to 1.",https://github.com/mozilla-ai/llamafile/commit/880894d5c2d639a439db9f7fcf49960b5f0b1eda
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e67522e,Justine Tunney,2024-10-29T19:27:46Z,Add Scala syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/e67522e705b21c9dd69de6167ca7eb774af1b847
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,006f743,Justine Tunney,2024-10-29T09:21:28Z,Add /v1/chat/completions endpoint to llamafiler,https://github.com/mozilla-ai/llamafile/commit/006f7437eedc50624a54f582d091bafc9a023329
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,64a6052,Justine Tunney,2024-10-29T02:08:30Z,Fix --threads-batch flag  You can now configure prefill / prediction thread count separately.,https://github.com/mozilla-ai/llamafile/commit/64a60526db2ced3fa629661173826ee968996176
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,267b8b5,Justine Tunney,2024-10-29T00:29:11Z,Run clang-format on #604,https://github.com/mozilla-ai/llamafile/commit/267b8b590e9f7a12d40137048adfada94d0fd24d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,108191a,Vlad Lasky,2024-10-29T00:05:01Z,Support configurable URL prefix in llamafiler (#604),https://github.com/mozilla-ai/llamafile/commit/108191ad4ca722d7693a09419940fe7ba61a4bb0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,ebcd61c,Justine Tunney,2024-10-28T23:48:52Z,Make more highlight improvements,https://github.com/mozilla-ai/llamafile/commit/ebcd61c1cc3c2156669063da5ccdedd5847e5bc1
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,457cefb,Justine Tunney,2024-10-28T22:08:41Z,Support more highlighting corner cases,https://github.com/mozilla-ai/llamafile/commit/457cefbe35850254377f1d2748378a863becaed4
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,c6e6039,Justine Tunney,2024-10-28T21:12:24Z,Improve Swift and TypeScript syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/c6e60395506561ca542a80c3abe01f28b4dff476
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,38398fa,Justine Tunney,2024-10-28T06:14:06Z,Add R syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/38398fa7b03b213dc404b796febebe91bc20cbfe
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,01ac87a,Justine Tunney,2024-10-28T05:01:50Z,Improve SQL syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/01ac87a121b8075bd7bc119f1b30eeb745580c9a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,9db5a57,Justine Tunney,2024-10-28T04:35:05Z,Add MATLAB syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/9db5a5763d36f6b647ffc4b9c1d7239fc238a99a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6d5aeac,Justine Tunney,2024-10-28T03:01:37Z,Make improvements  - Improve Kotlin syntax highlighting - Skip over malformed utf8 sequences in some languages - Fix C/C++ syntax highlighting of `# foo` with whitespace - Support --[[ multiline comments in Lua syntax highlighting - Introduce --ascii --chat flag for better Apple II experience - Fix bug with triple quote syntax highlighting in Java / Python - Embed -mtiny -Os build of gperf to eliminate extra source code,https://github.com/mozilla-ai/llamafile/commit/6d5aeacce4ec7d8c25da67e7d06d9c21713fdc1c
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,b0efa25,Justine Tunney,2024-10-26T08:31:03Z,Improve highlighting of JavaScript,https://github.com/mozilla-ai/llamafile/commit/b0efa25da1df41603a9783b42a060f55f680f429
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6260c7b,Justine Tunney,2024-10-26T06:19:42Z,Add TeX syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/6260c7b0f09edb8936fcebb4a05a79785c0dc128
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,5ead373,Justine Tunney,2024-10-25T23:54:42Z,"Introduce /clear, /push, and /pop commands",https://github.com/mozilla-ai/llamafile/commit/5ead373a502ac686d111ea03e39dfaa9fb05b9f0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,47ff34f,Justine Tunney,2024-10-25T21:28:32Z,Add --iq --recompile flag for IQ quant CUDA support  See #603,https://github.com/mozilla-ai/llamafile/commit/47ff34f9e3d3a4c8e0da35ca3814199926118083
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,58fc96e,Justine Tunney,2024-10-25T21:02:19Z,Add ld script syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/58fc96e39bbeee099a485984d4c4e526d0398b4a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6ce90b0,Justine Tunney,2024-10-25T20:17:20Z,Support clojure and scheme better,https://github.com/mozilla-ai/llamafile/commit/6ce90b0186c24875bca5b913f7d5723ba5a3cddd
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,e17a6de,Justine Tunney,2024-10-25T20:07:17Z,Add BASIC syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/e17a6de471f23ff98ae898732b9e30e85f290391
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d4eac09,Justine Tunney,2024-10-25T07:32:51Z,Add assembly syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/d4eac09722c519c10def9d29384595daf9f7498a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,6e274b2,Justine Tunney,2024-10-25T04:10:55Z,Add make syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/6e274b2d6a17b4cac44efde3495c9416043f9253
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,f28e954,Justine Tunney,2024-10-25T03:05:25Z,Add m4 syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/f28e95490b02f6a135abc08a1fc2ff4486fcb21a
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,88b0ece,Justine Tunney,2024-10-24T06:10:16Z,Fix regression in markdown bulleted lists,https://github.com/mozilla-ai/llamafile/commit/88b0ece953db8a1d18532b8f3fd86abc0f18bc9d
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,1459ab3,Justine Tunney,2024-10-24T04:14:41Z,Add FORTH syntax highlighting,https://github.com/mozilla-ai/llamafile/commit/1459ab3862d96446cc9cc624dc686b3138b6fd88
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,eee4b46,Vlad Lasky,2024-10-23T10:16:45Z,"Support configurable URL prefix in server (#597)  This change adds support for new commandline parameter --url-prefix to specify a URL prefix (subdirectory) under which the API will be served when llamafile is running in server mode, e.g. --url-prefix /llamafile.",https://github.com/mozilla-ai/llamafile/commit/eee4b46268e6e9f803da710587519abdc691bcac
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,22b2e2c,Justine Tunney,2024-10-22T03:47:03Z,Fix the GitHub Actions build,https://github.com/mozilla-ai/llamafile/commit/22b2e2c95d53a8abd00591a6e2da5b92be1d59e0
mozilla-ai/llamafile,https://github.com/mozilla-ai/llamafile,d484f6e,Justine Tunney,2024-10-22T03:37:21Z,Improve the chatbot  - We now have a /manual mode - We now have a /dump command - We now have a /help command - Chat now prints GPU or CPU info on startup,https://github.com/mozilla-ai/llamafile/commit/d484f6e3958afa2c2e958bc0f8d90a12a1e27435
