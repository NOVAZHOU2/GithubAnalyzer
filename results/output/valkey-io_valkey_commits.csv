项目名称,项目URL,提交ID,提交者,提交时间,提交信息,提交链接
valkey-io/valkey,https://github.com/valkey-io/valkey,04d0bba,zhaozhao.zz,2025-12-04T17:34:52Z,support whole cluster info for INFO command in cluster section (#2876)  Allow users to more easily get cluster information.  Signed-off-by: zhaozhao.zz <zhaozhao.zz@alibaba-inc.com>,https://github.com/valkey-io/valkey/commit/04d0bba398afe056a7a269ae46a81da574020ada
valkey-io/valkey,https://github.com/valkey-io/valkey,3d65a4a,Ouri Half,2025-12-04T17:10:09Z,"Fix deadlock in IO thread shutdown during panic (#2898)  ## Problem IO thread shutdown can deadlock during server panic when the main thread calls `pthread_cancel()` while the IO thread holds its mutex, preventing the thread from observing the cancellation.  ## Solution   Release the IO thread mutex before cancelling to ensure clean thread termination.  ## Testing Reproducer: ``` bash ./src/valkey-server --io-threads 2 --enable-debug-command yes ./src/valkey-cli debug panic ```  Before: Server hangs indefinitely After: Server terminates cleanly  Signed-off-by: Ouri Half <ourih@amazon.com>",https://github.com/valkey-io/valkey/commit/3d65a4aecdcfdd72ff1657317657a4cd665bba5f
valkey-io/valkey,https://github.com/valkey-io/valkey,c90e634,Roshan Khatri,2025-12-04T16:33:21Z,"Add PR and Release benchmark with new changes in framework (#2871)  This adds the workflow improvements for PR and Release benchmark where it runs on `c8g.metal-48xl` for `ARM64` and `c7i.metal-48xl` for `X86`.  ``` Cluster mode: disabled TLS: disabled io-threads: 1, 9 Pipelining: 1, 10 Clients: 1600 Benchmark Treads: 90 Data size: 16 ,96 Commands: SET, GET ```  c8g.metal-48xl Spec: https://aws.amazon.com/ec2/instance-types/c8g/ c7i.metal.48xl Spec: https://aws.amazon.com/ec2/instance-types/c7i/  ``` vCPU: 192 NUMA nodes: 2 Memory (GiB): 384 Network Bandwidth (Gbps): 50 ```  PR benchmarking will be executed on **ARM64** machine as it has been seen to be more consistent. Additionally, it runs 5 iterations for each tests and posts the average and other statistical metrics like - CI99%: 99% Confidence Interval - range where the true population mean is likely to fall - PI99%: 99% Prediction Interval - range where a single future observation is likely to fall - CV: Coefficient of Variation - relative variability (σ/μ × 100%)  _Note: Values with (n=X, σ=Y, CV=Z%, CI99%=±W%, PI99%=±V%) indicate averages from X runs with standard deviation Y, coefficient of variation Z%, 99% confidence interval margin of error ±W% of the mean, and 99% prediction interval margin of error ±V% of the mean. CI bounds [A, B] and PI bounds [C, D] show the actual interval ranges._  For comparing between versions, it adds a workflow which runs on both **ARM64** and **X86** machine. It will also post the comparison between the versions like this: https://github.com/valkey-io/valkey/issues/2580#issuecomment-3399539615  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com> Signed-off-by: Roshan Khatri <117414976+roshkhatri@users.noreply.github.com>",https://github.com/valkey-io/valkey/commit/c90e634f114a0ddecf92eacea4f35e269f89e997
valkey-io/valkey,https://github.com/valkey-io/valkey,70196ee,Rain Valentine,2025-12-03T17:15:45Z,"Add safe iterator tracking in hashtable to prevents invalid access on hashtable delete (#2807)  This makes it safe to delete hashtable while a safe iterator is iterating it. This currently isn't possible, but this improvement is required for fork-less replication #1754 which is being actively worked on.  We discussed these issues in #2611 which guards against a different but related issue: calling hashtableNext again after it has already returned false.  I implemented a singly linked list that hashtable uses to track its current safe iterators. It is used to invalidate all associated safe iterators when the hashtable is released. A singly linked list is acceptable because the list length is always very small - typically zero and no more than a handful.  Also, renames the internal functions:      hashtableReinitIterator -> hashtableRetargetIterator     hashtableResetIterator -> hashtableCleanupIterator  ---------  Signed-off-by: Rain Valentine <rsg000@gmail.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/70196ee20f1b84d5420acfdfe06c354b01c224dd
valkey-io/valkey,https://github.com/valkey-io/valkey,8ec9381,Harkrishn Patro,2025-12-03T16:17:26Z,Send duplicate multi meet packet only for node which supports it (#2840)  This prevents crashes on the older nodes in mixed clusters where some nodes are running 8.0 or older. Mixed clusters often exist temporarily during rolling upgrades.  Fixes: #2341   Signed-off-by: Harkrishn Patro <harkrisp@amazon.com>,https://github.com/valkey-io/valkey/commit/8ec93819746b14b789205ab2115d62f3dd2e3c54
valkey-io/valkey,https://github.com/valkey-io/valkey,c8341d4,Murad Shahmammadli,2025-12-03T16:07:04Z,Replace strcmp with byte-by-byte comparison in valkey-check-aof (#2809)  Fixes #2792  Replace strcmp with byte-by-byte comparison to avoid accidental heap-buffer-overflow errors.  Signed-off-by: murad shahmammadli <shmurad@amazon.com> Co-authored-by: murad shahmammadli <shmurad@amazon.com>,https://github.com/valkey-io/valkey/commit/c8341d416534e219b12daf79fecc93e1fe76f956
valkey-io/valkey,https://github.com/valkey-io/valkey,2e8fba4,Roshan Khatri,2025-12-02T20:40:20Z,[Test Fix] flaky benchmark test for warmup (#2890)  Fixes: https://github.com/valkey-io/valkey/issues/2859 Increased the warmup to 2 sec so we can verify that it runs more number of commands than the actual benchmark.  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>,https://github.com/valkey-io/valkey/commit/2e8fba49a21b5dcd13defa6b96ad0f4ecad44142
valkey-io/valkey,https://github.com/valkey-io/valkey,1b5f245,Jim Brunner,2025-12-02T18:14:33Z,"Refactor of LFU/LRU code for modularity (#2857)  General cleanup on LRU/LFU code. Improve modularity and maintainability.  Specifically: * Consolidates the mathematical logic for LRU/LFU into `lrulfu.c`, with an API in `lrulfu.h`. Knowledge of the LRU/LFU implementation was previously spread out across `db.c`, `evict.c`, `object.c`, `server.c`, and `server.h`. * Separates knowledge of the LRU from knowledge of the object containing the LRU value. `lrulfu.c` knows about the LRU/LFU algorithms, without knowing about the `robj`. `object.c` knows about the `robj` without knowing about the details of the LRU/LFU algorithms. * Eliminated `server.lruclock`, instead using `server.unixtime`. This also eliminates the periodic need to call `mstime()` to maintain the lru clock. * Fixed a minor computation bug in the old `LFUTimeElapsed` function (off by 1 after rollover). * Eliminate specific IF checks for rollover, using defined behavior for unsigned rollover instead. * Fixed a bug in `debug.c` which would perform LFU modification on an LRU value.  ---------  Signed-off-by: Jim Brunner <brunnerj@amazon.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/1b5f245eaecf274f655763f20e30ed4f1966ff41
valkey-io/valkey,https://github.com/valkey-io/valkey,853d111,Zhijun Liao,2025-12-02T14:03:47Z,"Build: Support `make test` when PROG_SUFFIX is used (#2885)  Closes #2883  Support a new environment variable `VALKEY_PROG_SUFFIX` in the test framework, which can be used for running tests if the binaries are compiled with a program suffix. For example, if the binaries are compiled using `make PROG_SUFFIX=-alt` to produce binaries named valkey-server-alt, valkey-cli-alt, etc., run the tests against these binaries using `VALKEY_PROG_SUFFIX=-alt ./runtest` or simply using `make test`.  Now the test with the make variable `PROG_SUFFIX` works well.  ``` % make PROG_SUFFIX=""-alt"" 		... 		... 		CC trace/trace_aof.o     LINK valkey-server-alt     INSTALL valkey-sentinel-alt     CC valkey-cli.o     CC serverassert.o     CC cli_common.o     CC cli_commands.o     LINK valkey-cli-alt     CC valkey-benchmark.o     LINK valkey-benchmark-alt     INSTALL valkey-check-rdb-alt     INSTALL valkey-check-aof-alt  Hint: It's a good idea to run 'make test' ;) %  % make test                                                                 cd src && /Library/Developer/CommandLineTools/usr/bin/make test     CC Makefile.dep     CC release.o     LINK valkey-server-alt     INSTALL valkey-check-aof-alt     INSTALL valkey-check-rdb-alt     LINK valkey-cli-alt     LINK valkey-benchmark-alt Cleanup: may take some time... OK Starting test server at port 21079 [ready]: 39435 Testing unit/pubsub ```  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/853d111f479043603385aeb674273c7b0099fe82
valkey-io/valkey,https://github.com/valkey-io/valkey,3fd0942,Zhijun Liao,2025-12-02T13:14:28Z,"Refactor TCL reference to support running tests with CMake (#2816)  Historically, Valkey’s TCL test suite expected all binaries (src/valkey-server, src/valkey-cli, src/valkey-benchmark, etc.) to exist under the src/ directory. This PR enables Valkey TCL tests to run seamlessly after a CMake build — no manual symlinks or make build required.  The test framework accepts a new environment variable `VALKEY_BIN_DIR` to look for the binaries.  CMake will copy all TCL test entrypoints (runtest, runtest-cluster, etc.) into the CMake build dir (e.g. `cmake-build-debug`) and insert `VALKEY_BIN_DIR` into these. Now we can either do ./cmake-build-debug/runtest at the project root or ./runtest at the Cmake dir to run all tests.  A new CMake post-build target prints a friendly reminder after successful builds, guiding developers on how to run tests with their CMake binaries:  ``` Hint: It is a good idea to run tests with your CMake-built binaries ;)       ./cmake-build-debug/runtest  Build finished ```  A helper TCL script `tests/support/set_executable_path.tcl` is added to support this change, which gets called by all test entrypoints: `runtest`, `runtest-cluster`, `runtest-sentinel`.  ---------  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/3fd0942279cf4f0eb9f7f52659af2901bde84831
valkey-io/valkey,https://github.com/valkey-io/valkey,825d19f,Daniil Kashapov,2025-12-02T12:33:20Z,Make all ACL categories explicit in JSON files (#2887)  Resolves #417  ---------  Signed-off-by: Daniil Kashapov <daniil.kashapov.ykt@gmail.com>,https://github.com/valkey-io/valkey/commit/825d19fb09ad637499d8cd8d851abd58d4929191
valkey-io/valkey,https://github.com/valkey-io/valkey,4a0e20b,Binbin,2025-12-01T02:20:32Z,"Handle failed psync log when there is no replication backlog (#2886)  This crash was introduced in #2877, we will crash when there is no replication backlog.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/4a0e20bbc91da1e776c619df741e0e9377193602
valkey-io/valkey,https://github.com/valkey-io/valkey,a087cc1,Binbin,2025-11-29T04:20:34Z,"Add psync offset range information to the failed psync log (#2877)  Although we can infer this infomartion from the replica logs, i think this still would be useful to see this information directly in the primary logs.  So now we can see the psync offset range when psync fails and then we can analyze and adjust the value of repl-backlog-size.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/a087cc1132cbe2ae17d6063a32c1543f8a31c39e
valkey-io/valkey,https://github.com/valkey-io/valkey,761fba2,Viktor Söderqvist,2025-11-28T09:35:53Z,Fix persisting missing make variables (#2881)  Persist USE_FAST_FLOAT and PROG_SUFFIX to prevent a complete rebuild next time someone types make or make test without specifying variables.  Fixes #2880  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>,https://github.com/valkey-io/valkey/commit/761fba2e9de2b1cf4f9081220565f78f1922b7c9
valkey-io/valkey,https://github.com/valkey-io/valkey,d16788e,Binbin,2025-11-27T02:39:42Z,"Fix discarded-qualifiers warnings reported by fedorarawhide (#2874)  fedorarawhide CI reports these warnings: ``` networking.c: In function 'afterErrorReply': networking.c:821:30: error: initialization discards 'const' qualifier from pointer target type [-Werror=discarded-qualifiers]   821 |             char *spaceloc = memchr(s, ' ', len < 32 ? len : 32); ```  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/d16788e52dfe1c80627975bb503d5e9ba6ae58ae
valkey-io/valkey,https://github.com/valkey-io/valkey,faac14a,Zhijun Liao,2025-11-26T13:52:17Z,"Cluster: Optimize slot bitmap iteration from per-bit to 64-bit word scan (#2781)  In functions `clusterSendFailoverAuthIfNeeded` and `clusterProcessPacket`, we iterate through **every slot bit** sequentially in the form of `for (int j = 0; j < CLUSTER_SLOTS; j++)`, performing 16384 checks even when only a few bits were set, and thus causing unnecessary loop overhead.  This is particularly wasteful in function `clusterSendFailoverAuthIfNeeded` where we need to ensure the sender's claimed slots all have up-to-date config epoch. Usually healthy senders would meet such condition, and thus we normally need to exhaust the for loop of 16384 checks.  The proposed new implementation loads 64 bits (8 byte word) at a time and skips empty words completely, therefore only performing 256 checks.  ---------  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/faac14ab9c8430057490f64ca979492057bb4d40
valkey-io/valkey,https://github.com/valkey-io/valkey,56ab3c4,Roshan Khatri,2025-11-26T13:19:53Z,"Adds HGETDEL Support to Valkey (#2851)  Fixes this: https://github.com/valkey-io/valkey/issues/2850 Adds support for HGETDEL to Valkey and aligns with Redis 8.0 feature. Maintains syntax compatibility Retrieves all the values, and null if fields dont exists and deletes once retrieved. ``` 127.0.0.1:6379> HGETDEL key FIELDS numfields field [ field ... ] ``` ``` 127.0.0.1:6379> HSET foo field1 bar1 field2 bar2 field3 bar3 (integer) 3 127.0.0.1:6379> HGETDEL foo FIELDS 1 field2 1) ""bar2"" 127.0.0.1:6379> HGETDEL foo FIELDS 1 field2 1) (nil) 127.0.0.1:6379> HGETALL foo 1) ""field1"" 2) ""bar1"" 3) ""field3"" 4) ""bar3"" 127.0.0.1:6379>  HGETDEL foo FIELDS 2 field2 field3 1) (nil) 2) ""bar3"" 127.0.0.1:6379> HGETALL foo 1) ""field1"" 2) ""bar1"" 127.0.0.1:6379> HGETDEL foo FIELDS 3 field1 non-exist-field (error) ERR syntax error 127.0.0.1:6379> HGETDEL foo FIELDS 2 field1 non-exist-field 1) ""bar1"" 2) (nil) 127.0.0.1:6379> HGETALL foo (empty array) 127.0.0.1:6379>  ```  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com> Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/56ab3c4a813564e50a00cb2fd80e1beaea4af506
valkey-io/valkey,https://github.com/valkey-io/valkey,9562bdc,Ran Shidlansik,2025-11-26T08:31:28Z,"Align the complexity description for all multi field HFE commands docs (#2875)  When we added the Hash Field Expiration feature in Valkey 9.0, some of the new command docs included complexity description of O(1) even tough they except multiple arguments. (see discussion in https://github.com/valkey-io/valkey/pull/2851#discussion_r2535684985) This PR does: 1. align all the commands to the same description 2. fix the complexity description of some commands (eg HSETEX and HGETEX)  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/9562bdc0ab185554d013e9406674aea1918dbc30
valkey-io/valkey,https://github.com/valkey-io/valkey,da3c43d,Zhijun Liao,2025-11-26T01:07:21Z,"Additional log information for cluster accept handler and message processing (#2815)  Enhance debugging for cluster logs  [1] Add human node names in cluster tests so that we can easily understand which nodes we are interacting with:  ``` pong packet received from: 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) from client: :0 node 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) announces that it is a primary in shard c6d1152caee49a5e70cb4b77d1549386078be603 Reconfiguring node 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) as primary for shard c6d1152caee49a5e70cb4b77d1549386078be603 Configuration change detected. Reconfiguring myself as a replica of node 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) in shard c6d1152caee49a5e70cb4b77d1549386078be603 ```    [2] Currently there are logs showing the address of incoming connections:  ``` Accepting cluster node connection from 127.0.0.1:59956 Accepting cluster node connection from 127.0.0.1:59957 Accepting cluster node connection from 127.0.0.1:59958 Accepting cluster node connection from 127.0.0.1:59959 ```  but we have no idea which nodes these connections refer to. I added a logging statement when the node is set to the inbound link connection.  ``` Bound cluster node 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) to connection of client 127.0.0.1:59956 ```    [3] Add a debug log when processing a packet to show the packet type, sender node name, and sender client port (this also has the benefit of telling us whether this is an inbound or outbound link).  ``` pong packet received from: 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) from client: :0 ping packet received from: 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) from client: 127.0.0.1:59973 fail packet received from: 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) from client: 127.0.0.1:59973 auth-req packet received from: 92a960ffd62f1bd04efeb260b30fe9ca6b9294ed (R4) from client: 127.0.0.1:59973 ```  ---------  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/da3c43d76bb8667df43e53227608e1b3344d0f1c
valkey-io/valkey,https://github.com/valkey-io/valkey,e5de417,Leon Anavi,2025-11-25T20:23:32Z,Fix build on 32-bit ARM by only using NEON on AArch64 (#2873)  Only enable `HAVE_ARM_NEON` on AArch64 because it supports vaddvq and all needed compiler intrinsics.  Fixes the following error when building for machine `qemuarm` using the Yocto Project and OpenEmbedded:  ``` | bitops.c: In function 'popcountNEON': | bitops.c:219:23: error: implicit declaration of function 'vaddvq_u16'; did you mean 'vaddq_u16'? [-Wimplicit-function-declaration] |   219 |         uint32_t t1 = vaddvq_u16(sc); |       |                       ^~~~~~~~~~ |       |                       vaddq_u16 | bitops.c:225:14: error: implicit declaration of function 'vaddvq_u8'; did you mean 'vaddq_u8'? [-Wimplicit-function-declaration] |   225 |         t += vaddvq_u8(vcntq_u8(vld1q_u8(p))); |       |              ^~~~~~~~~ |       |              vaddq_u8 ```  More details are available in the following log: https://errors.yoctoproject.org/Errors/Details/889836/  Signed-off-by: Leon Anavi <leon.anavi@konsulko.com>,https://github.com/valkey-io/valkey/commit/e5de417f1e8d2b2bb61257e842f21a74b9352746
valkey-io/valkey,https://github.com/valkey-io/valkey,dd2827a,jiegang0219,2025-11-25T11:25:39Z,"Add support for asynchronous release to replicaKeysWithExpire on writable replica (#2849)  ## Problem When executing `FLUSHALL ASYNC` on a **writable replica** that has a large number of expired keys directly written to it, the main thread gets blocked for an extended period while synchronously releasing the `replicaKeysWithExpire` dictionary.   ## Root Cause `FLUSHALL ASYNC` is designed for asynchronous lazy freeing of core data structures, but the release of `replicaKeysWithExpire` (a dictionary tracking expired keys on replicas) still happens synchronously in the main thread. This synchronous operation becomes a bottleneck when dealing with massive key volumes, as it cannot be offloaded to the lazyfree background thread.  This PR addresses the issue by moving the release of `replicaKeysWithExpire` to the lazyfree background thread, aligning it with the asynchronous design of `FLUSHALL ASYNC` and eliminating main thread blocking.  ## User scenarios In some operations, people often need to do primary-replica switches. One goal is to avoid noticeable impact on the business—like key loss or reduced availability (e.g., write failures).  Here is the process: First, temporarily switch traffic to writable replicas. Then we wait for the primary pending replication data to be fully synced (so primry and replicas are in sync), before finishing the switch. We don't usually need to do the flush in this case, but it's an optimization that can be done.  Signed-off-by: Scut-Corgis <512141203@qq.com> Signed-off-by: jiegang0219 <512141203@qq.com> Co-authored-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/dd2827a14ea183389e693255c244e1a7cad2acbb
valkey-io/valkey,https://github.com/valkey-io/valkey,8ea7f13,Binbin,2025-11-23T15:27:50Z,"Update dual channel replication conf to mention the local buffer is imited by COB (#2824)  After introducing the dual channel replication in #60, we decided in #915 not to add a new configuration item to limit the replica's local replication buffer, just use ""client-output-buffer-limit replica hard"" to limit it.  We need to document this behavior and mention that once the limit is reached, all future data will accumulate in the primary side.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/8ea7f1330cbc80fe016fc5110ec91efe2369ecee
valkey-io/valkey,https://github.com/valkey-io/valkey,8189fe5,Binbin,2025-11-21T10:31:31Z,"Add rdb_transmitted to replstateToString so that we can see it in INFO (#2833)  In dual channel replication, when the rdb channel client finish the RDB transfer, it will enter REPLICA_STATE_RDB_TRANSMITTED state. During this time, there will be a brief window that we are not able to see the connection in the INFO REPLICATION.  In the worst case, we might not see the connection for the DEFAULT_WAIT_BEFORE_RDB_CLIENT_FREE seconds. I guess there is no harm to list this state, showing connected_slaves but not showing the connection is bad when troubleshooting.  Note that this also affects the `valkey-cli --rdb` and `--functions-rdb` options. Before the client is in the `rdb_transmitted` state and is released, we will now see it in the info (see the example later).  Before, not showing the replica info ``` role:master connected_slaves:1 ```  After, for dual channel replication: ``` role:master connected_slaves:1 slave0:ip=xxx,port=xxx,state=rdb_transmitted,offset=0,lag=0,type=rdb-channel ```  After, for valkey-cli --rdb-only and --functions-rdb: ``` role:master connected_slaves:1 slave0:ip=xxx,port=xxx,state=rdb_transmitted,offset=0,lag=0,type=replica ```  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/8189fe5c42573f96229bea7d427b650a4354be31
valkey-io/valkey,https://github.com/valkey-io/valkey,05540af,Ricardo Dias,2025-11-20T10:23:00Z,"Add script function flags in the module API (#2836)  This commit adds script function flags to the module API, which allows function scripts to specify the function flags programmatically.  When the scripting engine compiles the script code can extract the flags from the code and set the flags on the compiled function objects.  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/05540af405b05382e700a594ae229ac34056a7bc
valkey-io/valkey,https://github.com/valkey-io/valkey,ed8856b,Hanxi Zhang,2025-11-20T07:07:16Z,"Fix cluster slot migration flaky test (#2756)  The original test code only checks:  The original test code only checks:  1. wait_for_cluster_size 4, which calls cluster_size_consistent for every node. Inside that function, for each node, cluster_size_consistent queries cluster_known_nodes, which is calculated as (unsigned long long)dictSize(server.cluster->nodes). However, when a new node is added to the cluster, it is first created in the HANDSHAKE state, and clusterAddNode adds it to the nodes hash table. Therefore, it is possible for the new node to still be in HANDSHAKE status (processed asynchronously) even though it appears that all nodes “know” there are 4 nodes in the cluster.  2. cluster_state for every node, but when a new node is added, server.cluster->state remains FAIL.   Some handshake processes may not have completed yet, which likely causes the flakiness. To address this, added a --cluster check to ensure that the config state is consistent.  Fixes #2693.  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com> Co-authored-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/ed8856bdfce07426b36a75b84cf9ee798024336f
valkey-io/valkey,https://github.com/valkey-io/valkey,e19ceb7,aradz44,2025-11-19T09:33:55Z,"deflake ""Hash field TTL and active expiry propagates correctly"" (#2856)  Fix a little miss in ""Hash field TTL and active expiry propagates correctly through chain replication"" test in `hashexpire.tcl`. The test did not wait for the initial sync of the chained replica and thus  made the test flakey  Signed-off-by: Arad Zilberstein <aradz@amazon.com>",https://github.com/valkey-io/valkey/commit/e19ceb7a6de207d049378a29406cb1763a6e1844
valkey-io/valkey,https://github.com/valkey-io/valkey,3c3a196,Venkat Pamulapati,2025-11-19T01:08:10Z,"Perform data cleanup during RDB load on successful version/signature validation (#2600)  Addresses: https://github.com/valkey-io/valkey/issues/2588  ## Overview Previously we call `emptyData()` during a fullSync before validating the RDB version is compatible.  This change adds an rdb flag that allows us to flush the database from within `rdbLoadRioWithLoadingCtx`. THhis provides the option to only flush the data if the rdb has a valid version and signature. In the case where we do have an invalid version and signature, we don't emptyData, so if a full sync fails for that reason a replica can still serve stale data instead of clients experiencing cache misses.  ## Changes - Added a new flag `RDBFLAGS_EMPTY_DATA` that signals to flush the database after rdb validation - Added logic to call `emptyData` in `rdbLoadRioWithLoadingCtx` in `rdb.c` - Added logic to not clear data if the RDB validation fails in `replication.c` using new return type `RDB_INCOMPATIBLE` - Modified the signature of `rdbLoadRioWithLoadingCtx` to return RDB success codes and updated all calling sites.  ## Testing Added a tcl test that uses the debug command `reload nosave` to load from an RDB that has a future version number. This triggers the same code path that full sync's will use, and verifies that we don't flush the data until after the validation is complete.  A test already exists that checks that the data is flushed: https://github.com/valkey-io/valkey/blob/unstable/tests/integration/replication.tcl#L1504  ---------  Signed-off-by: Venkat Pamulapati <pamuvenk@amazon.com> Signed-off-by: Venkat Pamulapati <33398322+ChiliPaneer@users.noreply.github.com> Co-authored-by: Venkat Pamulapati <pamuvenk@amazon.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>",https://github.com/valkey-io/valkey/commit/3c3a1966ec8fd32fb1cbffee4329a01528caf83a
valkey-io/valkey,https://github.com/valkey-io/valkey,5789266,yzc-yzc,2025-11-18T15:06:20Z,Fix SCAN consistency test to only test what we guarantee (#2853)  Test the SCAN consistency by alternating SCAN calls to primary and replica. We cannot rely on the exact order of the elements and the returned cursor number.  ---------  Signed-off-by: yzc-yzc <96833212+yzc-yzc@users.noreply.github.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>,https://github.com/valkey-io/valkey/commit/57892663bed81fe0d0b7041ec599f81ffc95f607
valkey-io/valkey,https://github.com/valkey-io/valkey,33bfac3,chzhoo,2025-11-18T13:27:15Z,"Optimize zset memory usage by embedding element in skiplist (#2508)  By default, when the number of elements in a zset exceeds 128, the underlying data structure adopts a skiplist. We can reduce memory usage by embedding elements into the skiplist nodes. Change the `zskiplistNode` memory layout as follows:  ``` Before                  +-------------+          +-----> | element-sds |          |       +-------------+          |  +------------------+-------+------------------+---------+-----+---------+  | element--pointer | score | backward-pointer | level-0 | ... | level-N |  +------------------+-------+------------------+---------+-----+---------+    After  +-------+------------------+---------+-----+---------+-------------+  + score | backward-pointer | level-0 | ... | level-N | element-sds |  +-------+------------------+---------+-----+---------+-------------+ ```  Before the embedded SDS representation, we include one byte representing the size of the SDS header, i.e. the offset into the SDS representation where that actual string starts.  The memory saving is therefore one pointer minus one byte = 7 bytes per element, regardless of other factors such as element size or number of elements.  ### Benchmark step  I generated the test data using the following lua script && cli command. And check memory usage using the `info` command.  **lua script** ``` local start_idx = tonumber(ARGV[1]) local end_idx = tonumber(ARGV[2]) local elem_count = tonumber(ARGV[3])  for i = start_idx, end_idx do     local key = ""zset:"" .. string.format(""%012d"", i)     local members = {}      for j = 0, elem_count - 1 do         table.insert(members, j)         table.insert(members, ""member:"" .. j)     end      redis.call(""ZADD"", key, unpack(members)) end  return ""OK: Created "" .. (end_idx - start_idx + 1) .. "" zsets"" ```  **valkey-cli command** `valkey-cli EVAL ""$(catcreate_zsets.lua)"" 0 0 100000 ${ZSET_ELEMENT_NUM}`  ### Benchmark result |number of elements in a zset | memory usage before optimization | memory usage after optimization | change | |-------|-------|-------|-------| | 129 | 1047MB | 943MB | -9.9% | | 256 |  2010MB|  1803MB| -10.3%| | 512 |  3904MB|3483MB| -10.8%|  ---------  Signed-off-by: chzhoo <czawyx@163.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/33bfac37bab7b754604c3fd8a5563aa1398c651d
valkey-io/valkey,https://github.com/valkey-io/valkey,616fccb,Roshan Khatri,2025-11-17T20:26:12Z,"Fix the failing warmup and duration are cumulative (#2854)  We need to verify total duration was at least 2 seconds, elapsed time can be quite variable to check upper-bound  Fixes https://github.com/valkey-io/valkey/issues/2843  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>",https://github.com/valkey-io/valkey/commit/616fccb4c5cdb0d7f2085051dc277e262a65fd38
valkey-io/valkey,https://github.com/valkey-io/valkey,aef56e5,Binbin,2025-11-17T09:25:19Z,"Fix timing issue in dual channel replication COB test (#2847)  After #2829, valgrind report a test failure, it seems that the time is not enough to generate a COB limit in valgrind.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/aef56e52f5e9a32aa115475118c9aca1bb27609f
valkey-io/valkey,https://github.com/valkey-io/valkey,a06cf15,Binbin,2025-11-15T04:57:27Z,"Allow dual channel full sync in plain failover (#2659)  PSYNC_FULLRESYNC_DUAL_CHANNEL is also a full sync, as the comment says, we need to allow it. While we have not yet identified the exact edge case that leads to this line, but during a failover, there should be no difference between different sync strategies.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/a06cf15b20cdbd7ba91b03f826b0d512d56d618b
valkey-io/valkey,https://github.com/valkey-io/valkey,86db609,Harkrishn Patro,2025-11-14T22:33:16Z,Print node name on a best effort basis if light weight message is received before link stabilization (#2825)  fixes: #2803  ---------  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com> Signed-off-by: Harkrishn Patro <bunty.hari@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/86db6092198fa42acf75cad2481bd1881cfd3165
valkey-io/valkey,https://github.com/valkey-io/valkey,b93cfcc,yzc-yzc,2025-11-14T09:55:05Z,Attempt to fix flaky SCAN consistency test (#2834)  Related test failures:  https://github.com/valkey-io/valkey/actions/runs/19282092345/job/55135193394  https://github.com/valkey-io/valkey/actions/runs/19200556305/job/54887767594  > *** [err]: scan family consistency with configured hash seed in tests/integration/scan-family-consistency.tcl > Expected '5 {k:1 k:25 z k:11 k:18 k:27 k:45 k:7 k:12 k:19 k:29 k:40 k:41 k:43}' to be equal to '5 {k:1 k:25 k:11 z k:18 k:27 k:45 k:7 k:12 k:19 k:29 k:40 k:41 k:43}' (context: type eval line 26 cmd {assert_equal $primary_cursor_next $replica_cursor_next} proc ::start_server)  The reason is that the RDB part of the primary-replica synchronization affects the resize policy of the hashtable. See https://github.com/valkey-io/valkey/blob/b835463a73d01f2d8a041dfc6b754db6952bcbb8/src/server.c#L807-L818  Signed-off-by: yzc-yzc <96833212+yzc-yzc@users.noreply.github.com>,https://github.com/valkey-io/valkey/commit/b93cfcc33277327f929c441a0cd98f02343b568e
valkey-io/valkey,https://github.com/valkey-io/valkey,331a852,Binbin,2025-11-14T03:32:29Z,"Change DEFAULT_WAIT_BEFORE_RDB_CLIENT_FREE from 60s to 5s (#2829)  Consider this scenario: 1. Replica starts loading the RDB using the rdb connection 2. Replica finishes loading the RDB before the replica main connection has    initiated the PSYNC request 3. Replica stops replicating after receiving replicaof no one 4. Primary can't know that the replica main connection will never ask for    PSYNC, so it keeps the reference to the replica's replication buffer block 5. Primary has a shutdown-timeout configured and requires to wait for the rdb    connection to close before it can shut down.  The current 60-second wait time (DEFAULT_WAIT_BEFORE_RDB_CLIENT_FREE) is excessive and leads to prolonged resource retention in edge cases. Reducing this timeout to 5 seconds would provide adequate time for legitimate PSYNC requests while mitigating the issue described above.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/331a85282152070113353fa3b287c3b9186b2871
valkey-io/valkey,https://github.com/valkey-io/valkey,8e0b375,Ricardo Dias,2025-11-13T20:05:52Z,"Fix cluster slot stats for scripts with cross-slot keys (#2835)  This commit fixes the cluster slot stats for scripts executed by scripting engines when the scripts access cross-slot keys.  This was not a bug in Lua scripting engine, but `VM_Call` was missing a call to invalidate the script caller client slot to prevent the accumulation of stats.  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/8e0b375da4f9096c5eafa49a9ad6b8c49322fb48
valkey-io/valkey,https://github.com/valkey-io/valkey,01a7657,Rain Valentine,2025-11-13T11:57:46Z,"Add --warmup and --duration parameters to valkey-benchmark (#2581)  It's handy to be able to automatically do a warmup and/or test by duration rather than request count. 🙂  I changed the real-time output a bit - not sure if that's wanted or not. (Like, would it break people's weird scripts? It'll break my weird scripts, but I know the price of writing weird fragile scripts.)  ``` Prepended ""Warming up "" when in warmup phase: Warming up SET: rps=69211.2 (overall: 69747.5) avg_msec=0.425 (overall: 0.393) 3.8 seconds ^^^^^^^^^^  Appended running request counter when based on -n: SET: rps=70892.0 (overall: 69878.1) avg_msec=0.385 (overall: 0.398) 612482 requests                                                                     ^^^^^^^^^^^^^^^  Appended running second counter when in warmup or based on --duration: SET: rps=61508.0 (overall: 61764.2) avg_msec=0.430 (overall: 0.426) 4.8 seconds                                                                     ^^^^^^^^^^^ ```  To be clear, the report at the end remains unchanged.  ---------  Signed-off-by: Rain Valentine <rsg000@gmail.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/01a7657b83a8a08a1c87a8677a4d72c6b35ffc08
valkey-io/valkey,https://github.com/valkey-io/valkey,b835463,Sarthak Aggarwal,2025-11-13T07:24:37Z,"Fixes test-freebsd workflow in daily (package lang/tclX) (#2832)  This PR fixes the freebsd daily job that has been failing consistently for the last days with the error ""pkg: No packages available to install matching 'lang/tclx' have been found in the repositories"".  The package name is corrected from `lang/tclx` to `lang/tclX`. The lowercase version worked previously but appears to have stopped working in an update of freebsd's pkg tool to 2.4.x.  Example of failed job:  https://github.com/valkey-io/valkey/actions/runs/19282092345/job/55135193499  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/b835463a73d01f2d8a041dfc6b754db6952bcbb8
valkey-io/valkey,https://github.com/valkey-io/valkey,7ffe4dc,Binbin,2025-11-12T12:32:13Z,"Remove the EXAT and PXAT from some HFE notifications tests (#2831)  As we can see, we expected to get hexpired, but we got hexpire instead, this means tht the expiration time has expired during execution. ``` *** [err]: HGETEX EXAT keyspace notifications for active expiry in tests/unit/hashexpire.tcl Expected 'pmessage __keyevent@* __keyevent@9__:hexpired myhash' to match 'pmessage __keyevent@* __keyevent@*:hexpire myhash' ```  We should remove the EXAT and PXAT from these fixtures. And we indeed have the dedicated tests that verify that we get 'expired' when EX,PX are set to 0 or EXAT,PXAT are in the past.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/7ffe4dcec4e9d03d484e61b106b43000f841d246
valkey-io/valkey,https://github.com/valkey-io/valkey,1b0b5c0,eifrah-aws,2025-11-12T08:51:58Z,"New module API to perform prefix‑aware ACL permission check (#2796)  ## Description  This change introduces the ability for modules to check ACL permissions against key prefix. The update adds a dedicated `prefixmatchlen` helper and extends the core ACL selector logic to support a prefix‑matching mode.  The new API `ValkeyModule_ACLCheckPrefixPermissions` is registered and exposed to modules, and a corresponding implementation is added in `module.c`. Existing internal callers that already perform prefix checks (e.g., `VM_ACLCheckKeyPermissions`) are updated to use the new flag, while all legacy paths remain unchanged.  The change also modifies the `aclcheck§ test module that exercises the new prefix‑checking API, ensuring that read/write operations are correctly allowed or denied based on the ACL configuration.  Key areas touched:  * ACL logic * Module API * Testing  # Motivation  The search module presently makes costly calls to verify index permissions (see https://github.com/valkey-io/valkey-search/blob/main/src/acl.cc#L295). This PR introduces a more efficient approach for that.  ---------  Signed-off-by: Eran Ifrah <eifrah@amazon.com> Signed-off-by: Madelyn Olson <madelyneolson@gmail.com> Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/1b0b5c0cfd7fb31d7c957cbe533d95ad693499c0
valkey-io/valkey,https://github.com/valkey-io/valkey,3c37886,Daniil Kashapov,2025-11-12T04:03:24Z,"Cluster: Avoid usage of light weight messages to nodes with not ready bidirectional links (#2817)  After network failure nodes that come back to cluster do not always send and/or receive messages from other nodes in shard, this fix avoids usage of light weight messages to nodes with not ready bidirectional links. When a light message comes before any normal message, freeing of cluster link is happening because on the just established connection link->node is not assigned yet. It is assigned in getNodeFromLinkAndMsg right after the condition if (is_light). So on a cluster with heavy pubsub load a long loop of disconnects is possible, and we got this. 1. node A establishes cluster link to node B 2. node A propagates PUBLISH to node B 3. node B frees cluster link because of link->node == null as it has not received non-light messages yet 4. go to 1. During this loop subscribers of node B does not receive any messages published to node A.  So here we want to make sure that PING was sent (and link->node was initialized) on this connection before using lightweight messages.  ---------  Signed-off-by: Daniil Kashapov <daniil.kashapov.ykt@gmail.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>",https://github.com/valkey-io/valkey/commit/3c378862c3a1f4b3693cec1f86d873b562b46a56
valkey-io/valkey,https://github.com/valkey-io/valkey,047080a,Jim Brunner,2025-11-11T23:26:53Z,"shared zadd for geoadd (#2828)  GEOADD is allocating/destroying a string object for ""ZADD"" each time it is called. Created a shared string instead.  Signed-off-by: Jim Brunner <brunnerj@amazon.com>",https://github.com/valkey-io/valkey/commit/047080a62259efb5ade83a1781c7f647c8807787
valkey-io/valkey,https://github.com/valkey-io/valkey,b7a3fc9,Roshan Khatri,2025-11-11T23:03:50Z,"Fix Test dual-channel: primary tracking replica backlog refcount (#2827)  This increases the times we check for the logs from 20 to 40.  I found that every `wait-for` check takes about 1.5 to 1.57 milliseconds so when we were checking 2000 times after 1ms we were actually spending (2000 * 1) + (2000 *1.75) = 5500ms time waiting. this can be founds under: for 10 checks we took 35 ms more so thats around 1.75 ms per check ``` Execution time: 2034 ms (failed) [err]: 20 100 - Test dual-channel: primary tracking replica backlog refcount - start with empty backlog in tests/integration/dual-channel-replication-flaky.tcl ```  That is why increasing it to 40 100 will check for approx 4,070 ms which is still less than the original 5500ms but should passes every single time here: https://github.com/roshkhatri/valkey/actions/runs/19279424967/job/55126976882  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>",https://github.com/valkey-io/valkey/commit/b7a3fc988a8e92b7b0c326bbbf28e87fe1092e89
valkey-io/valkey,https://github.com/valkey-io/valkey,2da21d9,Arthur Lee,2025-11-11T11:41:27Z,"Allow partial sync after loading AOF with preamble (#2366)  The AOF preamble mechanism replaces the traditional AOF base file with an RDB snapshot during rewrite operations, which reduces I/O overhead and improves loading performance. However, when valkey loads the RDB-formatted preamble from the base AOF file, it does not process the replication ID (replid) information within the RDB AUX fields. This omission has two limitations:  * On a primary, it prevents the primary from accepting PSYNC continue   requests after restarting with a preamble-enabled AOF file. * On a replica, it prevents the replica from successfully performing   partial sync requests (avoiding full sync) after restarting with a   preamble-enabled AOF file.  To resolve this, this commit aligns the AOF preamble handling with the logic used for standalone RDB files, by storing the replication ID and replication offset in the AOF preamble and restoring them when loading the AOF file.  Resolves #2677  ---------  Signed-off-by: arthur.lee <liziang.arthur@bytedance.com> Signed-off-by: Arthur Lee <arthurkiller@users.noreply.github.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/2da21d9def303fe77c42a1dfafa83e6d0722b1f4
valkey-io/valkey,https://github.com/valkey-io/valkey,7fbd4cb,Ricardo Dias,2025-11-10T15:05:26Z,"Expose SIMPLE_STRING and ARRAY_NULL reply type to the Module API (#2804)  This commit extends the Module API to expose the `SIMPLE_STRING` and `ARRAY_NULL` reply types to modules, by passing the new flag `X` to the `ValkeyModule_Call` function.  By only exposing the new reply types behind a flag we keep the backward compatibility with existing module implementations and allow new modules to working with these reply type, which are required for scripts to process correctly the reply type of commands called inside scripts.  Before this change, commands like `PING` or `SET`, which return `""OK""` as a simple string reply, would be returned as string replies to scripts. To allow the support of the Lua engine as an external module, we need to distinguish between simple string and string replies to keep backward compatibility.  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/7fbd4cb2603bca713dea566eda4c9f6666edd7b4
valkey-io/valkey,https://github.com/valkey-io/valkey,bb8989c,Ricardo Dias,2025-11-10T10:29:40Z,Adds new module context flag `VALKEYMODULE_CTX_SCRIPT_EXECUTION` (#2818)  The new module context flag `VALKEYMODULE_CTX_SCRIPT_EXECUTION` denotes that the module API function is being called in the context of a scripting engine execution.  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>,https://github.com/valkey-io/valkey/commit/bb8989cfdedd31ff01b76ea277006cb917a661e0
valkey-io/valkey,https://github.com/valkey-io/valkey,65ab07d,Vadym Khoptynets,2025-11-09T18:46:27Z,Leverage zfree_with_size for client reply blocks (#2624)  clientReplyBlock stores the size of the actual allocation in it size field (minus the header size). This can be used for more effective deallocation with zfree_with_size.  Signed-off-by: Vadym Khoptynets <vadymkh@amazon.com>,https://github.com/valkey-io/valkey/commit/65ab07dde7a18e22f9f65e7c3d6dedd3a8727793
valkey-io/valkey,https://github.com/valkey-io/valkey,2288657,Roshan Khatri,2025-11-07T23:11:37Z,"[DEFLAKE] Psync established after rdb load - beyond grace period (#2748)  Resolves: https://github.com/valkey-io/valkey/issues/2695  Increase the wait time for periodic log check for rdb load time. Also, increases the delay of log check frequency.  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com> Signed-off-by: Roshan Khatri <117414976+roshkhatri@users.noreply.github.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>",https://github.com/valkey-io/valkey/commit/2288657a058ba48d760c6cdd3ffe905135883f32
valkey-io/valkey,https://github.com/valkey-io/valkey,7f8c5b6,Harkrishn Patro,2025-11-07T00:14:45Z,[flaky-failure-fix] Increase the cluster-node-timeout to have longer delay between failover of each shard (#2793),https://github.com/valkey-io/valkey/commit/7f8c5b6f0c260698a16d18dde1105cdd61e05976
valkey-io/valkey,https://github.com/valkey-io/valkey,37d08d3,yzc-yzc,2025-11-06T17:02:27Z,"Fix flaky DBSIZE test for atomic slot migration (#2805)  Related test failures:       *** [err]: Replica importing key containment (slot 0 from node 0 to 2) - DBSIZE command excludes importing keys in tests/unit/cluster/cluster-migrateslots.tcl     Expected '1' to match '0' (context: type eval line 2 cmd {assert_match ""0"" [R $node_idx DBSIZE]} proc ::test)  The reason is that we don't wait for the primary-replica synchronization to complete before starting the next testcase.  ---------  Signed-off-by: yzc-yzc <96833212+yzc-yzc@users.noreply.github.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/37d08d386667f3285d2641250c7d3c36e032f050
valkey-io/valkey,https://github.com/valkey-io/valkey,7a1d989,Ricardo Dias,2025-11-06T09:46:22Z,"Add ""script"" context to  ACL log entries (#2798)  In this commit we add a new context for the ACL log entries that is used to log ACL failures that occur during scripts execution. To maintain backward compatibility we still maintain the ""lua"" context for failures that happen when running Lua scripts. For other scripting engines the context description will be just ""script"".  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/7a1d989696b0f7854723d639743ba64747bf447e
valkey-io/valkey,https://github.com/valkey-io/valkey,cf7a628,hieu2102,2025-11-06T09:45:12Z,"Add instruction to build Valkey with fast_float (#2810)  The `README.md` file is currently missing a section to build Valkey with `fast_float`, which was introduced in Valkey 8.1 as an optional dependency (#1260)  Signed-off-by: hieu2102 <hieund2102@gmail.com>",https://github.com/valkey-io/valkey/commit/cf7a628ada230af8ee69408d74080bfd40e1e091
valkey-io/valkey,https://github.com/valkey-io/valkey,32844b8,Sarthak Aggarwal,2025-11-05T16:45:52Z,Configurable DB hash seed for SCAN family commands consistency (#2608)  Introduce a new config `hash-seed` which can be set only at startup and controls the hash seed for the server. This includes all hash tables. This change makes it so that both primaries and replicas will return the same results for SCAN/HSCAN/ZSCAN/SSCAN cursors. This is useful in order to make sure SCAN behaves correctly after a failover.  Resolves #4  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com> Signed-off-by: Sarthak Aggarwal <sarthakaggarwal97@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>,https://github.com/valkey-io/valkey/commit/32844b8b0a8f598e8d849e2b85f204f0cbd60fb6
valkey-io/valkey,https://github.com/valkey-io/valkey,c88c94e,xbasel,2025-11-04T19:28:39Z,Reuse dbHasNoKeys() inside dbsHaveNoKeys() to remove duplicate logic (#2800)  Signed-off-by: xbasel <103044017+xbasel@users.noreply.github.com>,https://github.com/valkey-io/valkey/commit/c88c94e32625ab8b7eef0df9df8e3128821055d6
valkey-io/valkey,https://github.com/valkey-io/valkey,a49d469,Sarthak Aggarwal,2025-11-04T18:07:57Z,Reverts hashHashtableTypeValidate signature (#2799)  Fixes https://github.com/valkey-io/valkey/actions/runs/19053371057/job/54418411647#step:6:202  Matched hashHashtableTypeValidate to the [generic hashtable callback signature ](https://github.com/valkey-io/valkey/blob/unstable/src/hashtable.h#L62)and performed the entry cast internally to preserve expiry checks.  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com> Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Jim Brunner <brunnerj@amazon.com>,https://github.com/valkey-io/valkey/commit/a49d469f483b2d8f0624790a0a40ec876b6bfa95
valkey-io/valkey,https://github.com/valkey-io/valkey,a99c636,Jim Brunner,2025-11-03T17:39:36Z,"Improve header comment and strengthen type checking for entry (#2794)  In `entry.c`, the `entry` is a block of memory with variable contents. The structure can be difficult to understand. A new header comment more clearly documents the contents/layout of the `entry`.  Also, in `entry.h`, the `entry` was defined by `typedef void entry`. This allows blind casting to the `entry` type. It defeats compiler type checking.  Even though the `entry` has a variable definition, we can define entry as a legitimate type which allows the compiler to perform type checking. By performing `typedef struct _entry entry`, now the `entry` is understood to be a pointer to some type of undefined structure. We can pass a pointer and the compiler can typecheck the pointer. (Of course we can't dereference it, because we haven't actually defined the struct.)  Signed-off-by: Jim Brunner <brunnerj@amazon.com>",https://github.com/valkey-io/valkey/commit/a99c63632109d17bb06f1153f195658ae3ba2e2c
valkey-io/valkey,https://github.com/valkey-io/valkey,4d78d36,Hanxi Zhang,2025-11-03T07:43:48Z,"HSETEX: Support NX/XX Flags (#2668)  ### Summary Addresses https://github.com/valkey-io/valkey/issues/2619.   This PR extends the `HSETEX` command to support optional key-level `NX` and `XX` flags, allowing operations conditional on the existence of the hash key.  ### Changes - Updated `hsetex.json` and regenerated `commands.def`. - Extended argument parsing for NX/XX. - Added key-level `NX`/`XX` support in `HSETEX`. - Added tests covering all four NX/XX scenarios.  ---------  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/4d78d36bff27c6345be7127cc50776b2fb34a745
valkey-io/valkey,https://github.com/valkey-io/valkey,6cbc1a3,Simon Baatz,2025-10-31T18:46:53Z,"Sentinel: fix regression requiring ""+failover"" ACL in failover path (#2780)  Since Valkey Sentinel 9.0, sentinel tries to abort an ongoing failover when changing the role of a monitored instance. Since the result of the command is ignored, the ""FAILOVER ABORT"" command is sent irrespective of the actual failover status.  However, when using the documented pre 9.0 ACLs for a dedicated sentinel user, the FAILOVER command is not allowed and _all_ failover cases fail. (Additionally, the necessary ACL adaptation was not communicated well.)  Address this by:  - Updating the documentation in ""sentinel.conf"" to reflect the need for an adapted ACL  - Only abort a failover when sentinel detected an ongoing (probably stuck) failover. This means that standard failover and manual failover continue to work with unchanged pre 9.0 ACLs. Only the new ""SENTINEL FAILOVER COORDINATED"" requires to adapt the ACL on all Valkey nodes.  - Actually use a dedicated sentinel user and ACLs when testing standard failover, manual failover, and manual coordinated failover.  Fixes #2779  Signed-off-by: Simon Baatz <gmbnomis@gmail.com>",https://github.com/valkey-io/valkey/commit/6cbc1a31d7430cfd531b3b872b7378106c313d03
valkey-io/valkey,https://github.com/valkey-io/valkey,189c69e,harrylin98,2025-10-31T18:46:36Z,"Fix: ltrim should not call signalModifiedKey when no elements are removed (#2787)  There’s an issue with the LTRIM command. When LTRIM does not actually modify the key — for example, with `LTRIM key 0 -1` — the server.dirty counter is not updated because both ltrim and rtrim values are 0. As a result, the command is not propagated. However, `signalModifiedKey` is still called regardless of whether server.dirty changes. This behavior is unexpected and can cause a mismatch between the source and target during propagation, since the LTRIM command is not sent.  Signed-off-by: Harry Lin <harrylhl@amazon.com> Co-authored-by: Harry Lin <harrylhl@amazon.com>",https://github.com/valkey-io/valkey/commit/189c69e315cae23c2e6dcd125317e4bccfdccb51
valkey-io/valkey,https://github.com/valkey-io/valkey,43ee46d,Jacob Murphy,2025-10-31T17:57:05Z,"Authenticate slot migration client on source node to internal user (#2785)  Just setting the authenticated flag actually authenticates to the default user in this case. The default user may be granted no permission to use CLUSTER SYNCSLOTS.  Instaed, we now authenticate to the NULL/internal user, which grants access to all commands. This is the same as what we do for replication:   https://github.com/valkey-io/valkey/blob/864de555ced5354976ae4f97f44977041556115f/src/replication.c#L4717  Add a test for this case as well.  Closes #2783  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/43ee46da339d598a588b621a7ccfa7907a8cde86
valkey-io/valkey,https://github.com/valkey-io/valkey,84eb459,Ricardo Dias,2025-10-31T16:02:27Z,"Add ValkeyModule_ReplyWithCustomErrorFormat to module API (#2791)  Note: these changes are part of the effort to run Lua engine as an external scripting engine module.  The new function `ValkeyModule_ReplyWithCustomErrorFormat` is being added to the module API to allow scripting engines to return errors that originated from running commands within the script code, without counting twice in the error stats counters.  More details on why this is needed by scripting engines can be read in an older commit aa856b39f2ca65dbcc0eaae2d2c52f7a35291bbf messsage.  This PR also adds a new test to ensure the correctness of the newly added function.  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/84eb459cd4e7c3b9c529d152d68a4d83613faa28
valkey-io/valkey,https://github.com/valkey-io/valkey,f54818c,xbasel,2025-10-30T20:51:01Z,"Bug fix: reset io_last_written on c->buf resize to prevent stale pointers (#2786)  Fixes an assert crash in _writeToClient():      serverAssert(c->io_last_written.data_len == 0 ||                  c->io_last_written.buf == c->buf);  The issue occurs when clientsCronResizeOutputBuffer() grows or reallocates c->buf while io_last_written still points to the old buffer and data_len is non-zero. On the next write, both conditions in the assertion become false.  Reset io_last_written when resizing the output buffer to prevent stale pointers and keep state consistent.  fixes https://github.com/valkey-io/valkey/issues/2769  Signed-off-by: xbasel <103044017+xbasel@users.noreply.github.com>",https://github.com/valkey-io/valkey/commit/f54818cc60597e9fe5dc03a52fd39ab944cd4932
valkey-io/valkey,https://github.com/valkey-io/valkey,864de55,Ricardo Dias,2025-10-30T16:19:46Z,"Make ValkeyModule_Call compatible with calling commands from scripting engines (#2782)  Note: these changes are another step towards being able to run Lua engine as an external scripting engine module.  In this commit we improve the `ValkeyModule_Call` API function code to match the validations and behavior of the `scriptCall` function, currently used by the Lua engine to run commands using `server.call` Lua Valkey API.  The changes made are backward compatible. The new behavior/validations are only enabled when calling `ValkeyModule_Call` while running a script using `EVAL` or `FCALL`.  To test these changes, we improved the `HELLO` dummy scripting engine module to support calling commands, and compare the behavior with calling the same command from a Lua script.  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/864de555ced5354976ae4f97f44977041556115f
valkey-io/valkey,https://github.com/valkey-io/valkey,ea103da,Ricardo Dias,2025-10-30T16:18:01Z,"New INFO section for scripting engines (#2738)  This commit adds a new `INFO` section called ""Scripting Engines"" that shows the information of the current scripting engines available in the server.  Here's an output example:  ``` > info scriptingengines # Scripting Engines engines_count:2 engines_total_used_memory:68608 engines_total_memory_overhead:56 engine_0:name=LUA,module=built-in,abi_version=4,used_memory=68608,memory_overhead=16 engine_1:name=HELLO,module=helloengine,abi_version=4,used_memory=0,memory_overhead=40 ```  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/ea103da5d6e1ed8cd9993547a28a69fd26c04ffc
valkey-io/valkey,https://github.com/valkey-io/valkey,e381182,Diego Ciciani,2025-10-30T10:20:56Z,"Add IPv6 availability check to skip tests when unavailable (#2674)  Skip IPv6 tests automatically when IPv6 is not available.  This fixes the problem that tests fail when IPv6 is not available on the system, which can worry users when they run `make test`.  IPv6 availibility is detected by opening a dummy server socket and trying to connect to it using a client socket over IPv6.  Fixes #2643  ---------  Signed-off-by: diego-ciciani01 <diego.ciciani@gmail.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/e381182297c7a7cc88f6aa5e9f6a38884c8a5a10
valkey-io/valkey,https://github.com/valkey-io/valkey,10281be,Sarthak Aggarwal,2025-10-29T20:36:37Z,"Adds a summary for tests  (#2745)  ``` Test Summary: 100 passed, 2 failed  !!! WARNING The following tests failed: ... ````  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/10281becafff74b6f4a29c9d41e68f7c26a0e4d3
valkey-io/valkey,https://github.com/valkey-io/valkey,f3b2dee,Ken,2025-10-28T20:20:12Z,"Add monotonic clock calibration handling if clock speed is not found (#2776)  Currently, monotonic clock initialization relies on the model name field from /proc/cpuinfo to retrieve the clock speed. However, this is not always present. In case it is not present, measure the clock tick and use it instead.  Before fix: ``` monotonic: x86 linux, unable to determine clock rate ```  After fix: ``` 21695:M 25 Oct 2025 20:16:23.168 * monotonic clock: X86 TSC @ 2649 ticks/us ```  Fixes #2774  ---------  Signed-off-by: Ken Nam <otherscase@gmail.com> Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/f3b2dee3b7c99d0753d4fb02783be4ec9f086344
valkey-io/valkey,https://github.com/valkey-io/valkey,909d082,Ritoban Dutta,2025-10-28T09:36:23Z,"Reorder valkey.conf: move configs to correct sections (#2737)  - Moved `server-cpulist`, `bio-cpulist`, `aof-rewrite-cpulist`,   `bgsave-cpulist` configurations to ADVANCED CONFIG. - Moved `ignore-warnings` configuration to ADVANCED CONFIG. - Moved `availability-zone` configuration to GENERAL.  These configs were incorrectly placed at the end of the file in the ACTIVE DEFRAGMENTATION section.  Fixes #2736  ---------  Signed-off-by: ritoban23 <ankudutt101@gmail.com>",https://github.com/valkey-io/valkey/commit/909d082cd04d9e01d1fab781cfafaa15dd72aff5
valkey-io/valkey,https://github.com/valkey-io/valkey,2c92a60,Sarthak Aggarwal,2025-10-27T20:08:40Z,Reverts rdb-key-save-delay value to fix dual channel replication test in macos (#2771)  Resolves #2696   Set `rdb-key-save-delay` to 200 microseconds to reduce the overall RDB load time.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/2c92a6072d5827474ac8a93fc31ac14ddd4a0a1b
valkey-io/valkey,https://github.com/valkey-io/valkey,861d079,Zhijun Liao,2025-10-24T20:15:54Z,Sentinel: Skip IS-PRIMARY-DOWN-BY-ADDR requests when primary not SDOWN (#2763)  A super tiny change to optimize the function `sentinelAskPrimaryStateToOtherSentinels` to early return when the sentinel does not observe the primary as subjectively down.  Signed-off-by: Zhijun <dszhijun@gmail.com>,https://github.com/valkey-io/valkey/commit/861d0794b7bdf2237d98502a5b405faf19db24dc
valkey-io/valkey,https://github.com/valkey-io/valkey,baf2d57,Zhijun Liao,2025-10-23T11:29:50Z,"Ensure the server executable exists before running tests (#2762)  Previously, running ./runtest without src/valkey-server would hang, now it throws an error.  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/baf2d572f7c3016c25168928c6de039028f1ddcc
valkey-io/valkey,https://github.com/valkey-io/valkey,7043c0f,Ricardo Dias,2025-10-23T09:58:32Z,"Scripting Engine Debugger Support (#1701)  This PR introduces the support for implementing remote debuggers in scripting engines modules.  The module API is extended with scripting engines callbacks and new functions that can be used by scripting engine modules to implement a remote debugger.  Most of the code that was used to implement the Lua debugger, was refactored and moved to the `scripting_engine.c` file, and only the code specific to the Lua engine, remained in the `debug_lua.c` file.  The `SCRIPT DEBUG (YES|NO|SYNC)` command was extend with an optional parameter that can be used to specify the engine name, where we want to enable the debugger. If no engine name is specified, the Lua engine is used to keep backwards compatibility.  In [src/valkeymodule.h](https://github.com/valkey-io/valkey/pull/1701/files#diff-b91520205c29a3a5a940786e509b2f13a5e73a1ac2016be773e62ea64c7efb28) we see the module API changes. And in the `helloscripting.c` file we can see how to implement a simple debugger for the dummy HELLO scripting engine.  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/7043c0f5432699ba5b6643ef01bf6b19ab07512c
valkey-io/valkey,https://github.com/valkey-io/valkey,f1270a8,Viktor Söderqvist,2025-10-23T07:48:08Z,"Adjust test runners to the number of tests to run (#2759)  This is fixing a minor annoyance when running single tests. With this change, the runtest script doesn't start more runners than the total number of tests to run. These are seen in the printouts like `[ready]: 68359`.  Screenshot before:  ``` $ ./runtest --single tests/unit/limits.tcl  Cleanup: may take some time... OK Starting test server at port 21079 [ready]: 68359 Testing unit/limits [ready]: 68355 [ready]: 68362 [ready]: 68356 [ready]: 68361 [ready]: 68358 [ready]: 68364 [ready]: 68366 [ready]: 68367 [ready]: 68368 [ready]: 68357 [ready]: 68360 [ready]: 68363 [ready]: 68365 [ready]: 68369 [ready]: 68370 [ok]: Check if maxclients works refusing connections (906 ms) [1/1 done]: unit/limits (1 seconds)                     The End  Execution time of different units:   1 seconds - unit/limits  \o/ All tests passed without errors!  Cleanup: may take some time... OK ```  Screenshot after:  ``` $ ./runtest --single tests/unit/limits.tcl  Cleanup: may take some time... OK Starting test server at port 21079 [ready]: 68439 Testing unit/limits [ok]: Check if maxclients works refusing connections (906 ms) [1/1 done]: unit/limits (1 seconds)                     The End  Execution time of different units:   1 seconds - unit/limits  \o/ All tests passed without errors!  Cleanup: may take some time... OK ```  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/f1270a851f6d488081a556a7f098a564c2b6d578
valkey-io/valkey,https://github.com/valkey-io/valkey,746d9ec,Zhijun Liao,2025-10-23T07:41:29Z,Use the fetched TLS and TCP ports in clusterProcessGossipSection (#2761)  The TLS and TCP ports have been fetched and should be used. This can improve code readability.  Signed-off-by: Zhijun <dszhijun@gmail.com>,https://github.com/valkey-io/valkey/commit/746d9eca9e139af501f21944f200a707b2c8e394
valkey-io/valkey,https://github.com/valkey-io/valkey,7e0b3bb,Hanxi Zhang,2025-10-22T09:35:53Z,"Show RPS histogram in valkey-benchmark (#2471)  When benchmarking with the a target thoughput using the `--rps` flag, display an RPS histogram in the benchmark report. This can help identify if there is a bottleneck.  Related to #2219.  ---------  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com>",https://github.com/valkey-io/valkey/commit/7e0b3bbd5215953ec1e634a91107f8541869cf6c
valkey-io/valkey,https://github.com/valkey-io/valkey,0e5477f,Jacob Murphy,2025-10-22T03:28:55Z,Fix atomic slot migration module notification comment (#2758)  Signed-off-by: Jacob Murphy <jkmurphy@google.com>,https://github.com/valkey-io/valkey/commit/0e5477fb9bdfdb4b615a097387907f92345474b8
valkey-io/valkey,https://github.com/valkey-io/valkey,35b4e2f,Madelyn Olson,2025-10-22T03:28:40Z,"Update module api generation and format module.c (#2757)  This change makes it so that the module API reference can be cleanly generated from the module.c file. Most of this seems to be because of the code formatting work we did. There are two parts: 1. Updated some of the odd corner cases in module.c so they can be handled. For example, there was a method that had none of the method on the first line, which was unhandled. None of these are functional and I think format should be OK with them. 2. Better handle multi-line function prototypes in the ruby code. Before we just relied on the function to be on a single line, now we handle it on multiple lines. This feels pretty hacked in, but I don't really understand the rest of the code but it does work.  Generated this PR: https://github.com/valkey-io/valkey-doc/pull/374/files.  ---------  Signed-off-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/35b4e2f1ab84eb609162cca64bc2d29bd765ae7a
valkey-io/valkey,https://github.com/valkey-io/valkey,9acea36,Binbin,2025-10-21T02:18:41Z,"Fix outdated comment around clusterLink->flags (#2752)  This clusterLink->flags was added in #2310, during the review, we at the end chose to add a new CLUSTER_LINK_XXX flag instead of sharing the old CLUSTER_NODE_XXX flag.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/9acea36841903eb08fb9e12a5febbf112ab8200d
valkey-io/valkey,https://github.com/valkey-io/valkey,1cf0df9,Jacob Murphy,2025-10-20T20:23:29Z,"Fix invalid memory address caused by hashtable shrinking during safe iteration (#2753)  Safe iterators pause rehashing, but don't pause auto shrinking. This allows stale bucket references which then cause use after free (in this case, via compactBucketChain on a deleted bucket).  This problem is easily reproducible via atomic slot migration, where we call delKeysInSlot which relies on calling delete within a safe iterator. After the fix, it no longer causes a crash.  Since all cases where rehashing is paused expect auto shrinking to also be paused, I am making this happen automatically as part of pausing reshashing.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/1cf0df9fc3a2d6ceb02c7e69ebfacc7ee5b06186
valkey-io/valkey,https://github.com/valkey-io/valkey,5d3cb3d,Binbin,2025-10-20T09:17:05Z,Initialize the lua attributes of the luaFunction script (#2750)  This was introduced in #1826. This create an `Uninitialised value was created by a heap allocation` in the CI.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/5d3cb3d04c100c938f5859f12bdc3a76dc86900f
valkey-io/valkey,https://github.com/valkey-io/valkey,2a914aa,Jacob Murphy,2025-10-18T17:20:18Z,"Fix incorrect kvstore size and BIT accounting after completed migration (#2749)  When working on #2635 I errorneously duplicated the setSlotImportingStateInAllDbs call for successful imports. This resulted in us doubling the key count in the kvstore. This results in DBSIZE reporting an incorrect sum, and also causes BIT corruption that can eventually result in a crash.  The solution is:  1. Only call setSlotImportingStateInAllDbs once (in our finishSlotMigrationJob function) 2. Make setSlotImportingStateInAllDbs idempotent by checking if the delete from the kvstore importing hashtable is a no-op  This also fixes a bug where the number of importing keys is not lowered after the migration, but this is less critical since it is only used when resizing the dictionary on RDB load. However, it could result in un-loadable RDBs if the importing key count gets large enough.  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/2a914aa5214d166572e82689d33277a6fe2f1cdf
valkey-io/valkey,https://github.com/valkey-io/valkey,b4c93cc,Binbin,2025-10-17T14:25:17Z,"FUNCTION FLUSH re-create lua VM, fix flush not gc, fix flush async + load crash (#1826)  There will be two issues in this test: ``` test {FUNCTION - test function flush} {     for {set i 0} {$i < 10000} {incr i} {         r function load [get_function_code LUA test_$i test_$i {return 'hello'}]     }     set before_flush_memory [s used_memory_vm_functions]     r function flush sync     set after_flush_memory [s used_memory_vm_functions]     puts ""flush sync, before_flush_memory: $before_flush_memory, after_flush_memory: $after_flush_memory""      for {set i 0} {$i < 10000} {incr i} {         r function load [get_function_code LUA test_$i test_$i {return 'hello'}]     }     set before_flush_memory [s used_memory_vm_functions]     r function flush async     set after_flush_memory [s used_memory_vm_functions]     puts ""flush async, before_flush_memory: $before_flush_memory, after_flush_memory: $after_flush_memory""      for {set i 0} {$i < 10000} {incr i} {         r function load [get_function_code LUA test_$i test_$i {return 'hello'}]     }     puts ""Test done"" } ```  The first one is the test output, we can see that after executing FUNCTION FLUSH, used_memory_vm_functions has not changed at all: ``` flush sync, before_flush_memory: 2962432, after_flush_memory: 2962432 flush async, before_flush_memory: 4504576, after_flush_memory: 4504576 ```  The second one is there is a crash when loading the functions during the async flush: ``` === VALKEY BUG REPORT START: Cut & paste starting from here ===  # valkey 255.255.255 crashed by signal: 11, si_code: 2  # Accessing address: 0xe0429b7100000a3c  # Crashed running the instruction at: 0x102e0b09c  ------ STACK TRACE ------ EIP: 0   valkey-server                       0x0000000102e0b09c luaH_getstr + 52  Backtrace: 0   libsystem_platform.dylib            0x000000018b066584 _sigtramp + 56 1   valkey-server                       0x0000000102e01054 luaD_precall + 96 2   valkey-server                       0x0000000102e01b10 luaD_call + 104 3   valkey-server                       0x0000000102e00d1c luaD_rawrunprotected + 76 4   valkey-server                       0x0000000102e01e3c luaD_pcall + 60 5   valkey-server                       0x0000000102dfc630 lua_pcall + 300 6   valkey-server                       0x0000000102f77770 luaEngineCompileCode + 708 7   valkey-server                       0x0000000102f71f50 scriptingEngineCallCompileCode + 104 8   valkey-server                       0x0000000102f700b0 functionsCreateWithLibraryCtx + 2088 9   valkey-server                       0x0000000102f70898 functionLoadCommand + 312 10  valkey-server                       0x0000000102e3978c call + 416 11  valkey-server                       0x0000000102e3b5b8 processCommand + 3340 12  valkey-server                       0x0000000102e563cc processInputBuffer + 520 13  valkey-server                       0x0000000102e55808 readQueryFromClient + 92 14  valkey-server                       0x0000000102f696e0 connSocketEventHandler + 180 15  valkey-server                       0x0000000102e20480 aeProcessEvents + 372 16  valkey-server                       0x0000000102e4aad0 main + 26412 17  dyld                                0x000000018acab154 start + 2476  ------ STACK TRACE DONE ------ ```  The reason is that, in the old implementation (introduced in 7.0), FUNCTION FLUSH use lua_unref to remove the script from lua VM. lua_unref does not trigger the gc, it causes us to not be able to effectively reclaim memory after the FUNCTION FLUSH.  The other issue is that, since we don't re-create the lua VM in FUNCTION FLUSH, loading the functions during a FUNCTION FLUSH ASYNC will result a crash because lua engine state is not thread-safe.  The correct solution is to re-create a new Lua VM to use, just like SCRIPT FLUSH.  ---------  Signed-off-by: Binbin <binloveplay1314@qq.com> Signed-off-by: Ricardo Dias <ricardo.dias@percona.com> Co-authored-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/b4c93cc9c25e08d2da9c12cb7e109a176e3e885c
valkey-io/valkey,https://github.com/valkey-io/valkey,95154fe,Harkrishn Patro,2025-10-17T05:43:19Z,Bump old engine version(s) for compatibility test (#2741)  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com>,https://github.com/valkey-io/valkey/commit/95154feaa122f867ffd91c65b5ceb0a44dc7c0ef
valkey-io/valkey,https://github.com/valkey-io/valkey,898172b,Roshan Khatri,2025-10-17T02:50:48Z,Deflake Psync established within grace period (#2743)  increased the wait time to a total of 10 seconds where we check the log for `Done loading RDB` message  Fixes https://github.com/valkey-io/valkey/issues/2694  CI run (100 times): https://github.com/roshkhatri/valkey/actions/runs/18576201712/job/52961907806  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>,https://github.com/valkey-io/valkey/commit/898172bc9c7c10a174a4b1072fdf81111a8a01af
valkey-io/valkey,https://github.com/valkey-io/valkey,af45fee,Binbin,2025-10-17T02:24:43Z,"Remove the outupdated unknown key/value pairs comment in CLUSTER SYNCSLOTS ESTABLISH (#2498)  We now have #2688 SYNCSLOTS CAPA, remove the outupdated comment.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/af45feea12bb7ec852f2265582dd4e9250724ec1
valkey-io/valkey,https://github.com/valkey-io/valkey,981b8fe,Sarthak Aggarwal,2025-10-16T02:07:52Z,"Deflakes Primary COB growth with inactive replica (#2715)  Resolves #2696   The primary issue was that with sanitizer mode, the test needed more time for primary’s replication buffers grow beyond `2 × backlog_size`. Increasing the threshold of `repl-timeout` to 30s, ensures that the inactive replica is not disconnected while the full sync is proceeding. `rdb-key-save-delay` controls or throttles the data written to the client output buffer, and in this case, we are deterministically able to perform the fullsync within 10s (10000 keys * 0.001s).  Increasing the `wait_for_condition` gives it enough retries to verify that `mem_total_replication_buffers` reaches the required `2 × backlog_size`.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/981b8fe1bdd1a58e1a06eb80186cd890b557f98a
valkey-io/valkey,https://github.com/valkey-io/valkey,54da834,Viktor Söderqvist,2025-10-14T15:44:17Z,"Fix double MOVED reply on unblock at failover (#2734)  #2329 intoduced a bug that causes a blocked client in cluster mode to receive two MOVED redirects instead of one. This was not seen in tests, except in the reply schema validator.  The fix makes sure the client's pending command is cleared after sending the MOVED redirect, to prevent if from being reprocessed.  Fixes #2676.  ---------  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/54da8344c1a923aeb54022dae2b19b111841c590
valkey-io/valkey,https://github.com/valkey-io/valkey,ccf6fca,Binbin,2025-10-14T04:56:36Z,Add `Slot migration is ok when the replicas are down test` back (#2727)  The test was accidentally removed in PR #1671.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/ccf6fca5f426d3deebbcd45b3c48b11c09a66a72
valkey-io/valkey,https://github.com/valkey-io/valkey,28e5dcc,Jacob Murphy,2025-10-13T15:18:13Z,"Fix crash that occurs sometimes when aborting a slot migration while child snapshot is active (#2721)  The race condition causes the client to be used and subsequently double freed by the slot migration read pipe handler. The order of events is:  1. We kill the slot migration child process during CANCELSLOTMIGRATIONS 1. We then free the associated client to the target node 1. Although we kill the child process, it is not guaranteed that the pipe will be empty from child to parent 1. If the pipe is not empty, we later will read that out in the slotMigrationPipeReadHandler 1. In the pipe read handler, we attempt to write to the connection. If writing to the connection fails, we will attempt to free the client 1. However, the client was already freed, so this a double free  Notably, the slot migration being aborted doesn't need to be triggered by `CANCELSLOTMIGRATIONS`, it can be any failure.  To solve this, we simply:  1. Set the slot migration pipe connection to NULL whenever it is unlinked 2. Bail out early in slot migration pipe read handler if the connection is NULL  I also consolidate the killSlotMigrationChild call to one code path, which is executed on client unlink. Before, there were two code paths that would do this twice (once on slot migration job finish, and once on client unlink). Sending the signal twice is fine, but inefficient.  Also, add a test to cancel during the slot migration snapshot to make sure this case is covered (we only caught it during the module test).  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/28e5dcce2caafc7680460810a3daca4df77ca10e
valkey-io/valkey,https://github.com/valkey-io/valkey,19474c8,Jacob Murphy,2025-10-13T15:17:59Z,"Deflake atomic slot migration client flag test (#2720)  This test was failing, and causing the next test to throw an exception. It is failing since we never waited for the slot migration to connect before proceeding.  Fixes #2692  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/19474c867a67bde06e20335872ad9d6e0b2eb83f
valkey-io/valkey,https://github.com/valkey-io/valkey,dbcf022,Jacob Murphy,2025-10-13T15:17:36Z,"Stop using DEBUG LOADAOF on replica in ASM tests (#2719)  DEBUG LOADAOF sometimes works but it results in -LOADING responses to the primary so there are lots of race conditions. It isn't something we should be doing anyways. To test, I just disconnect the replica before loading the AOF, then reconnect it.  Fixes #2712  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/dbcf0224806ed36acceb01332fbaa371bd6b185a
valkey-io/valkey,https://github.com/valkey-io/valkey,181ca48,Harkrishn Patro,2025-10-13T05:12:08Z,Bump CLUSTER SHARDS command update version to 9.1.0 (#2729),https://github.com/valkey-io/valkey/commit/181ca483b9d8d37ad49792de162516ab09b84f35
valkey-io/valkey,https://github.com/valkey-io/valkey,0d500c2,Kyle Kim (kimkyle@),2025-10-11T01:54:58Z,"Update the misleading zdiff() comment on empty first key handling. (#747)  Currently, zdiff() becomes a no-op in the case that the first key is empty.  The existing comment of ""Skip everything if the smallest input is empty"" is misleading, as qsort is bypassed for the case of ZDIFF. There's no guarantee that the first key holds the smallest cardinality.  The real reason behind such bypass is the following. ZDIFF computes the difference between the first and all successive input sorted sets. Meaning, if the first key is empty, we cannot reduce further from an already empty collection, and thus zdiff() becomes a no-op.  Signed-off-by: Kyle Kim <kimkyle@amazon.com>",https://github.com/valkey-io/valkey/commit/0d500c2cc13830f3fba2e039e584f921a229089f
valkey-io/valkey,https://github.com/valkey-io/valkey,d29d580,Viktor Söderqvist,2025-10-10T16:54:31Z,"Tests: Don't dump logs when skipping test using 'skip' (#2718)  When using `skip` inside a test to skip a test, when running with --dump-logs it causes the logs to be dumped. Introduced in #2342.  The reason is the ""skipped"" exception is caught in the start_server proc in tests/support/server.tcl. This is where the $::dump_logs variable is checked.  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/d29d5800679c6c49d993a5afcad421b7d447fc01
valkey-io/valkey,https://github.com/valkey-io/valkey,8182f4a,Ran Shidlansik,2025-10-10T09:30:08Z,HSETEX with FXX should not create an object if it does not exist (#2716)  When the hash object does not exist FXX should simply fail the check without creating the object while FNX should be trivial and succeed.  Note - also fix a potential compilation warning on some COMPILERS doing constant folding of variable length array when size is const expression.  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/8182f4a0b9c92639f7528f4ae412e957c7600bb4
valkey-io/valkey,https://github.com/valkey-io/valkey,18214be,Harkrishn Patro,2025-10-10T00:00:10Z,Add compatibility test with Valkey 7.2/8.0 (#2342)  * Add cross version compatibility test to run with Valkey 7.2 and 8.0 * Add mechanism in TCL test to skip tests dynamically - #2711  ---------  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com> Signed-off-by: Harkrishn Patro <bunty.hari@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>,https://github.com/valkey-io/valkey/commit/18214be4902cb4c3792d27567a00db5365643fc9
valkey-io/valkey,https://github.com/valkey-io/valkey,f598d11,Sarthak Aggarwal,2025-10-09T23:03:53Z,Deflake replica selection test by relaxing cluster configurations (#2672)  We have relaxed the `cluster-ping-interval` and `cluster-node-timeout` so that cluster has enough time to stabilize and propagate changes.  Fixes this test occasional failure when running with valgrind:      [err]: Node #10 should eventually replicate node #5 in tests/unit/cluster/slave-selection.tcl     #10 didn't became slave of #5  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/f598d11a4bd3465c6f1b020906054161bef60890
valkey-io/valkey,https://github.com/valkey-io/valkey,f7c9527,Harkrishn Patro,2025-10-09T20:11:31Z,Add invalid RDB signature to log statement (#2710)  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com>,https://github.com/valkey-io/valkey/commit/f7c95277dac5433af7a9c1c3106b23002e82648f
valkey-io/valkey,https://github.com/valkey-io/valkey,155b0bb,Harkrishn Patro,2025-10-08T23:04:47Z,"Fix memory leak with CLIENT LIST/KILL duplicate filters (#2362)  With #1401, we introduced additional filters to CLIENT LIST/KILL subcommand. The intended behavior was to pick the last value of the filter. However, we introduced memory leak for all the preceding filters.  Before this change: ``` > CLIENT LIST IP 127.0.0.1 IP 127.0.0.1 id=4 addr=127.0.0.1:37866 laddr=127.0.0.1:6379 fd=10 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=0 argv-mem=21 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=16989 events=r cmd=client|list user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=49 tot-net-out=0 tot-cmds=0 ``` Leak: ``` Direct leak of 11 byte(s) in 1 object(s) allocated from:     #0 0x7f2901aa557d in malloc (/lib64/libasan.so.4+0xd857d)     #1 0x76db76 in ztrymalloc_usable_internal /workplace/harkrisp/valkey/src/zmalloc.c:156     #2 0x76db76 in zmalloc_usable /workplace/harkrisp/valkey/src/zmalloc.c:200     #3 0x4c4121 in _sdsnewlen.constprop.230 /workplace/harkrisp/valkey/src/sds.c:113     #4 0x4dc456 in parseClientFiltersOrReply.constprop.63 /workplace/harkrisp/valkey/src/networking.c:4264     #5 0x4bb9f7 in clientListCommand /workplace/harkrisp/valkey/src/networking.c:4600     #6 0x641159 in call /workplace/harkrisp/valkey/src/server.c:3772     #7 0x6431a6 in processCommand /workplace/harkrisp/valkey/src/server.c:4434     #8 0x4bfa9b in processCommandAndResetClient /workplace/harkrisp/valkey/src/networking.c:3571     #9 0x4bfa9b in processInputBuffer /workplace/harkrisp/valkey/src/networking.c:3702     #10 0x4bffa3 in readQueryFromClient /workplace/harkrisp/valkey/src/networking.c:3812     #11 0x481015 in callHandler /workplace/harkrisp/valkey/src/connhelpers.h:79     #12 0x481015 in connSocketEventHandler.lto_priv.394 /workplace/harkrisp/valkey/src/socket.c:301     #13 0x7d3fb3 in aeProcessEvents /workplace/harkrisp/valkey/src/ae.c:486     #14 0x7d4d44 in aeMain /workplace/harkrisp/valkey/src/ae.c:543     #15 0x453925 in main /workplace/harkrisp/valkey/src/server.c:7319     #16 0x7f2900cd7139 in __libc_start_main (/lib64/libc.so.6+0x21139) ```  Note: For filter ID / NOT-ID we group all the option and perform filtering whereas for remaining filters we only pick the last filter option.  ---------  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com>",https://github.com/valkey-io/valkey/commit/155b0bb82196c8fc70245823856a8e966525d55a
valkey-io/valkey,https://github.com/valkey-io/valkey,5bbbc6b,Satheesha CH Gowda,2025-10-08T19:14:05Z,"Add shard id field to CLUSTER SHARDS response (#2568)  This change exposes an existing, persistent (in nodes.conf) unique shard identifier for each shard in the cluster as part of the `CLUSTER SHARDS` command response.  ``` 1) 1) ""slots""    2) 1) (integer) 0       2) (integer) 999       3) (integer) 2001       4) (integer) 3999       5) (integer) 4501       6) (integer) 5460    3) ""nodes""    4) 1)  1) ""id""           2) ""6e76043bed00e716e85035107866ea16e9a5f700""           3) ""port""           4) (integer) 6385           5) ""ip""           6) ""127.0.0.1""           7) ""endpoint""           8) ""127.0.0.1""           9) ""role""          10) ""replica""          11) ""replication-offset""          12) (integer) 8092          13) ""health""          14) ""online""       2)  1) ""id""           2) ""b2f8c841707b2246ec2a641c37f16e88fe0bb700""           3) ""port""           4) (integer) 6380           5) ""ip""           6) ""127.0.0.1""           7) ""endpoint""           8) ""127.0.0.1""           9) ""role""          10) ""master""          11) ""replication-offset""          12) (integer) 8092          13) ""health""          14) ""online""    5) ""id""    6) ""3f2a7bb7bbd5fc2a331fe9bf95f5e02bcca02430"" ```  ---------  Signed-off-by: Satheesha Chattenahalli Hanume Gowda <satheesha@apple.com> Co-authored-by: Satheesha Chattenahalli Hanume Gowda <satheesha@apple.com>",https://github.com/valkey-io/valkey/commit/5bbbc6bd9a3ec44c9a47b0cbb91219370e798088
valkey-io/valkey,https://github.com/valkey-io/valkey,22247f6,Jacob Murphy,2025-10-08T10:52:36Z,"Reduce flakiness of atomic slot migration AOF test (#2705)  If we don't wait for the replica to resync, the migration may be cancelled by the time the replica resyncs, resulting in a test failure when we can't find the migration on the replica.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/22247f6119526c41cb59890abff3f07e9b4df366
valkey-io/valkey,https://github.com/valkey-io/valkey,3390b1e,Viktor Söderqvist,2025-10-08T09:37:15Z,"Allow TCL 9.0 for tests (#1673)  Makes our tests possible to run with TCL 9.  The latest Fedora now has TCL 9.0 and it's working now, including the TCL TLS package. (This wasn't working earlier due to some packaging errors for TCL packages in Fedora, which have been fixed now.)  This PR also removes the custom compilation of TCL 8 used in our Daily jobs and uses the system default TCL version instead. The TCL version depends on the OS. For the latest Fedora, you get 9.0, for macOS you get 8.5 and for most other OSes you get 8.6.  The checks for TCL 8.7 are removed, because 8.7 doesn't exist. It was never released.  ---------  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/3390b1e608f2cf39c00cf66a2e975b756c5e8b02
valkey-io/valkey,https://github.com/valkey-io/valkey,b3da88e,Jacob Murphy,2025-10-07T22:42:56Z,"Use correct arguments in LOLWUT test (#2708)  Seeing test failures due to this on the 9.0.0 branch:  ``` [exception]: Executing test client: ERR Syntax error. Use: LOLWUT [columns rows] [real imaginary]. ERR Syntax error. Use: LOLWUT [columns rows] [real imaginary] ```  It turns out we are just providing the version as an argument, instead of specifying which version to run on  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/b3da88e94dbc88080cca808a831841f58e421ad2
valkey-io/valkey,https://github.com/valkey-io/valkey,a4317e9,Jacob Murphy,2025-10-07T17:19:36Z,"Introduce SYNCSLOTS CAPA for forwards compatibility (#2688)  For now, introduce this and have it do nothing. Eventually, we can use this to negotiate supported capabilities on either end. Right now, there is nothing to send or support, so it just accepts it and doesn't reply.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/a4317e91159cde7ce0aea06402fc783087bdf5ca
valkey-io/valkey,https://github.com/valkey-io/valkey,383ffe4,Jacob Murphy,2025-10-07T16:17:07Z,"Prevent exposure of importing keys on replicas during atomic slot migration (#2635)  # Problem  In the current slot migration design, replicas are completely unaware of the slot migration. Because of this, they do not know to hide importing keys, which results in exposure of these keys to commands like KEYS, SCAN, RANDOMKEY, and DBSIZE.  # Design  The main part of the design is that we will now listen for and process the `SYNCSLOTS ESTABLISH` command on the replica. When a `SYNCSLOTS ESTABLISH` command is received from the primary, we begin tracking a new slot import in a special `SLOT_IMPORT_OCCURRING_ON_PRIMARY` state. Replicas use this state to track the import, and await for a future `SYNCSLOTS FINISH` message that tells them the import is successful/failed.  ## Success Case  ```      Source                                          Target                         Target Replica        |                                                |                                 |        |------------ SYNCSLOTS ESTABLISH -------------->|                                 |        |                                                |----- SYNCSLOTS ESTABLISH ------>|        |<-------------------- +OK ----------------------|                                 |        |                                                |                                 |        |~~~~~~~~~~~~~~ snapshot as AOF ~~~~~~~~~~~~~~~~>|                                 |        |                                                |~~~~~~ forward snapshot ~~~~~~~~>|        |----------- SYNCSLOTS SNAPSHOT-EOF ------------>|                                 |        |                                                |                                 |        |<----------- SYNCSLOTS REQUEST-PAUSE -----------|                                 |        |                                                |                                 |        |~~~~~~~~~~~~ incremental changes ~~~~~~~~~~~~~~>|                                 |        |                                                |~~~~~~ forward changes ~~~~~~~~~>|        |--------------- SYNCSLOTS PAUSED -------------->|                                 |        |                                                |                                 |        |<---------- SYNCSLOTS REQUEST-FAILOVER ---------|                                 |        |                                                |                                 |        |---------- SYNCSLOTS FAILOVER-GRANTED --------->|                                 |        |                                                |                                 |        |                                            (performs takeover &                  |        |                                             propagates topology)                 |        |                                                |                                 |        |                                                |------- SYNCSLOTS FINISH ------->|  (finds out about topology                              |                                 |   change & marks migration done)                        |                                 |        |                                                |                                 | ```  ## Failure Case ```      Source                                          Target                         Target Replica        |                                                |                                 |        |------------ SYNCSLOTS ESTABLISH -------------->|                                 |        |                                                |----- SYNCSLOTS ESTABLISH ------>|        |<-------------------- +OK ----------------------|                                 |      ...                                              ...                               ...        |                                                |                                 |        |                                             <FAILURE>                            |        |                                                |                                 |        |                                      (performs cleanup)                          |        |                                                | ~~~~~~ UNLINK <key> ... ~~~~~~~>|        |                                                |                                 |        |                                                | ------ SYNCSLOTS FINISH ------->|        |                                                |                                 | ```  ## Full Sync, Partial Sync, and RDB  In order to ensure replicas that resync during the import are still aware of the import, the slot import is serialized to a new `cluster-slot-imports` aux field. The encoding includes the job name, the source node name, and the slot ranges being imported. Upon loading an RDB with the `cluster-slot-imports` aux field, replicas will add a new migration in the `SLOT_IMPORT_OCCURRING_ON_PRIMARY` state.  It's important to note that a previously saved RDB file can be used as the basis for partial sync with a primary. Because of this, whenever we load an RDB file with the `cluster-slot-imports` aux field, even from disk, we will still add a new migration to track the import. If after loading the RDB, the Valkey node is a primary, it will cancel the slot migration. Having this tracking state loaded on primaries will ensure that replicas partial syncing to a restarted primary still get their `SYNCSLOTS FINISH` message in the replication stream.  ## AOF  Since AOF cannot be used as the basis for a partial sync, we don't necessarily need to persist the `SYNCSLOTS ESTABLISH` and `FINISH` commands to the AOF.  However, considering there is work to change this (#59 #1901) this design doesn't make any assumptions about this.  We will propagate the `ESTABLISH` and `FINISH` commands to the AOF, and ensure that they can be properly replayed on AOF load to get to the right state. Similar to RDB, if there are any pending ""ESTABLISH"" commands that don't have a ""FINISH"" afterwards upon becoming primary, we will make sure to fail those in `verifyClusterConfigWithData`.  Additionally, there was a bug in the existing slot migration where slot import clients were not having their commands persisted to AOF. This has been fixed by ensuring we still propagate to AOF even for slot import clients.  ## Promotion & Demotion  Since the primary is solely responsible for cleaning up unowned slots, primaries that are demoted will not clean up previously active slot imports. The promoted replica will be responsible for both cleaning up the slot (`verifyClusterConifgWithData`) and sending a `SYNCSLOTS FINISH`.  # Other Options Considered  I also considered tracking ""dirty"" slots rather than using the slot import state machine. In this setup, primaries and replicas would simply mark each slot's hashtable in the kvstore as dirty when something is written to it and we do not currently own that slot.  This approach is simpler, but has a problem in that modules loaded on the replica would still not get slot migration start/end notifications. If the modules on the replica do not get such notifications, they will not be able to properly contain these dirty keys during slot migration events.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/383ffe4874d5062602a68d40cbe8a08359c1879a
valkey-io/valkey,https://github.com/valkey-io/valkey,0646749,Madelyn Olson,2025-10-03T17:26:28Z,Fix format issues with CVE fix (#2679)  The CVE fixes had a formatting and external test issue that wasn't caught because private branches don't run those CI steps.  Signed-off-by: Madelyn Olson <madelyneolson@gmail.com>,https://github.com/valkey-io/valkey/commit/064674945d6c1667b85103be514facf88f5a10c4
valkey-io/valkey,https://github.com/valkey-io/valkey,6dd003e,Madelyn Olson,2025-10-03T13:32:24Z,Merge commit from fork  Signed-off-by: Madelyn Olson <madelyneolson@gmail.com>,https://github.com/valkey-io/valkey/commit/6dd003e88feace83e55491f32376f6927896e31e
valkey-io/valkey,https://github.com/valkey-io/valkey,d5bb986,Jacob Murphy,2025-10-02T19:12:34Z,"Add slot migration client flags and module context flags (#2639)  New client flags in reported by CLIENT INFO and CLIENT LIST:  * `i` for atomic slot migration importing client * `E` for atomic slot migration exporting client  New flags in return value of `ValkeyModule_GetContextFlags`:  * `VALKEYMODULE_CTX_FLAGS_SLOT_IMPORT_CLIENT`: Indicate the that client attached to this context is the slot import client. * `VALKEYMODULE_CTX_FLAGS_SLOT_EXPORT_CLIENT`: Indicate the that client attached to this context is the slot export client.  Users could use this to monitor the underlying client info of the slot migration, and more clearly understand why they see extra clients during the migration.  Modules can use these to detect keyspace notifications on import clients. I am also adding export flags for symmetry, although there should not be keyspace notifications. But they would potentially be visible in command filters or in server events triggered by that client.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/d5bb986fd592733330ff4042c011f7c64da543ec
valkey-io/valkey,https://github.com/valkey-io/valkey,3073979,Alina Liu,2025-10-02T03:37:15Z,"Defrag if slab 1/8 full to fix defrag didn't stop issue (#2656)  **Issue History:** 1. The flaky test issue ""defrag didn't stop"" was originally detected in February 2025: https://github.com/valkey-io/valkey/issues/1746 Solution for 1746: https://github.com/valkey-io/valkey/pull/1762 2. Similar issue occurred recently: https://github.com/valkey-io/valkey/actions/runs/16585350083/job/46909359496#step:5:7640  **Investigation:**  1. First, the issue occurs specifically to Active Defrag stream in cluster mode. 2. After investigating `test_stream` in `memefficiency.tcl`, I found the root cause is in defrag logic rather than the test itself - There are still failed tests with the same error even if I tried different parameters for the test. 3. Then I looked at malloc-stats and identified potential defrag issues, particularly in the 80B bin where utilization only reaches ~75% after defrag instead of the expected near 100%, while other bins show proper defrag behavior - 80B actually is the size of a new stream(confirmed in `t_stream.c`) that we add during test. 4. For 80B, after adding 200000 streams and fragmenting, `curregs `= 100030, after a lot of defrag cycles, there are still 122 nonfull-slabs/511 slabs with the remaining 446 items not defragged (average 4/nonfull-slab).  **Detailed malloc-stats:** - Total slabs: 511 - Non-full slabs: 122 - Full slabs: 511-122=389 - Theoretical maximum per slab: 256 items - Allocated items in non-full slabs: 100030-389*256=446 - Average items per non-full slab: 446/122=3.66  **Root Cause:**  **There are some immovable items which  prevent complete defrag**  **Problems in old defrag logic:** 1. The previous condition (we don't defrag if slab utilization > 'avg utilization' * 1.125), the 12.5% threshold doesn’t work well with low utilizations.  - Let's imagine we have 446 items in 122 nonfull-slabs (avg 3.66 items/nonfull-slab), let's say, e.g. we have 81 slabs with 5 items each +41 slabs with 1 item each) - 12.5% threshold: 3.66*1.125=4.11 - If those 41 single items are immovable, they actually lower the average, so the rest 81 slabs will be above the threshold (5>4.11) and will not be defragged - defrag didn't stop.  2. Distribution of immovable items across slabs was causing inconsistent defragmentation and flaky test outcome.  - If those 41 single items are movable, they will be moved and the avg will be 5, then 12.5% threshold: 5*1.125=5.625, so the rest 81 slabs will fall below the threshold (5<5.625) and will be defragged - defrag success. - This can explain why we got flaky defrag tests.   **Final solution :**  1. Add one more condition before the old logic in `makeDefragDecision `to trigger defragmentation when slab is less than 1/8 full (1/8 threshold (12.5%) chosen to align with existing utilization threshold factor) - Ensures no low-utilization slabs left without defragged, and stabilize the defrag behavior. 2. The reason why we have immovable items and how to handle them is going to be investigate later. 3. Be sure to rebuild Valkey before testing it.   **Local test result:** - Before fix:  pass rate 80.8% (63/78) - After fix: Test only stream: pass rate 100% (200/200) Test the whole memefficiency.tcl: pass rate 100% (100/100)  Resolves #2398 , the ""defrag didn't stop"" issue, with help from @JimB123 @madolson  ---------  Signed-off-by: Alina Liu <liusalisa6363@gmail.com> Signed-off-by: asagegeLiu <liusalisa6363@gmail.com> Signed-off-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/307397904fe0ec7a31e6fe15cd3a6723e93a9b4b
valkey-io/valkey,https://github.com/valkey-io/valkey,a9a65ab,Madelyn Olson,2025-09-30T06:25:53Z,"Implement a lolwut for version 9 (#2646)  As requested, here is a version of lolwut for 9 that visualizes a Julia set with ASCII art.  Example: ``` 127.0.0.1:6379> lolwut version 9                                                                                                                                                                                                                                                                                                                                                                                                                                                           .............                                                                ......................                                                        ............................                                                  ......:::--:::::::::::::::.......                                              .....:::=+*@@@=--------=+===--::....                                            ....:::-+@@@@&*+=====+%@@@@@@@@=-::....                                        .....:::-=+@@@@@%%*++*@@@@@@@@@&*=--::....                                      .....::--=++#@@@@@@@@##@@@@@@@@@@@@@@=::....                                    ......:-=@&#&@@@@@@@@@@@@@@@@@@@@@@@@@%-::...                                   ......::-+@@@@@@@@@@@@@@@@@@&&@@@#%#&@@@-::....                                 .......::-=+%@@@@@@@@@@@@@@@@#%%*+++++%@+-:.....                                 .......::-=@&@@@@@@@@@@@@@@@@&*++=====---::.....                                .......:::--*@@@@@@@@@@@@@@@@@%++===----::::.....                               ........::::-=+*%&@@@@@@@@@&&&%*+==----:::::......                               ........::::--=+@@@@@@@@@@&##%*++==---:::::.......                               .......:::::---=+#@@@@@@@@&&&#%*+==---:::::.......                              ........:::::---=++*%%#&&@@@@@@@@@+=---::::........                              .......:::::----=++*%##&@@@@@@@@@@%+=--::::.......                               ......::::-----==++#@@@@@@@@@@@@@&%*+=-:::........                               ......:::---====++*@@@@@@@@@@@@@@@@@@+-:::.......                                .....::-=++==+++**%@@@@@@@@@@@@@@@@#*=--::.......                                 ....:-%@@%****%###&@@@@@@@@@@@@@@@@&+--:.......                                  ....:-=@@@@@&@@@@@@@@@@@@@@@@@@@@@@@@=::......                                    ...::+@@@@@@@@@@@@@@@&&@@@@@@@@%**@+-::.....                                     ....::-=+%#@@@@@@@@@&%%%&@@@@@@*==-:::.....                                       ....::--+%@@@@@@@%++==++*#@@@@&=-:::....                                          ....:::-*@**@@+==----==*%@@@@+-:::....                                             .....:::---::::::::--=+@=--::.....                                                 .........::::::::::::::.......                                                     .........................                                                            ..................                                                                      ...                                                                                                                                                                                                                                                                                             Ascii representation of Julia set with constant 0.41 + 0.29i Don't forget to have fun! Valkey ver. 255.255.255 ```  You can pass in arbitrary rows and colums (it's best when rows is 2x number of columns) and an arbitrary julia constant so it is repeatable. Worst case it takes about ~100us on my m2 macbook, which should be fine to make sure it's not taking too many system resources.  ---------  Signed-off-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/a9a65abc85b396e6b1b2ebf68564dabc251bc06e
valkey-io/valkey,https://github.com/valkey-io/valkey,f39a809,Ran Shidlansik,2025-09-29T10:49:42Z,Fix module key memory usage accounting (#2661)  Make objectComputeSize account for the key size as well when the key is a module datatype  fixes: https://github.com/valkey-io/valkey/issues/2660  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/f39a809711ded971fb7abfc36dd294ea6183e34d
valkey-io/valkey,https://github.com/valkey-io/valkey,e99380f,Jacob Murphy,2025-09-29T10:42:25Z,"Fix atomic slot migration snapshot never proceeding with hz 1 (#2636)  The problem is that ACKs run on a set loop (once every second) and this will happen every loop with hz 1.  Instead, we can do the ACK after running the main logic. We can also do an additional optimization where we don't send an ACK from source to target if we already sent some data this cron loop, since the target will reset the ack timer on any data over the connection.  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/e99380f75c3f61f7a4762873202d52e24382f1c7
valkey-io/valkey,https://github.com/valkey-io/valkey,ae58b3d,cjx-zar,2025-09-29T09:13:06Z,"Redirect blocked clients after failover (#2329)  In standalone mode, after a switch over, the command that was originally blocking on primary returns -REDIRECT instead of -UNBLOCKED when the client has the redirect capability.  Similarly, in cluster mode, after a switch over, the blocked commands receive a -MOVED redirect instead of -UNBLOCKED.  After this fix, the handling of blocked connections during a switch over between standalone and cluster is nearly identical. This can be summarized as follows:  Standalone:   1. Client that has the redirect capability blocked on the key on the primary node will receive a -REDIRECT after the switch over completes instead of -UNBLOCKED. 2. Readonly clients blocked on the primary or replica node will remain blocked throughout the switch over.  Cluster:  1. Client blocked on the key served by the primary node will receive a -MOVED instead of a probabilistic -UNBLOCKED error. 2. Readonly clients blocked on the key served by primary or replica node will remain blocked throughout the switch over.  ---------  Signed-off-by: cjx-zar <56825069+cjx-zar@users.noreply.github.com> Co-authored-by: Simon Baatz <gmbnomis@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/ae58b3d5bee7c8bc4de529da3d89dd07a29a6e0a
valkey-io/valkey,https://github.com/valkey-io/valkey,80cec0a,Binbin,2025-09-28T11:50:34Z,Minor fix for dual rdb channel connection conn error log (#2658)  This should be server.repl_rdb_transfer_s  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/80cec0a18459af92cf0f613e5bbe4a52892ce15d
valkey-io/valkey,https://github.com/valkey-io/valkey,6c1bb73,Jacob Murphy,2025-09-26T02:25:41Z,"Add atomic slot migration test for unblock on migration complete (#2637)  This is already handled by `clusterRedirectBlockedClientIfNeeded`. With the work we are doing in #2329, it makes sense to have an explicit test here to prevent regression.  Signed-off-by: Jacob Murphy <jkmurphy@google.com> Signed-off-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/6c1bb73a57a04bd40ef6091ecaf19473601c57f4
valkey-io/valkey,https://github.com/valkey-io/valkey,ffdf222,Sarthak Aggarwal,2025-09-25T02:23:12Z,"Increasing retries to allow succcessful meet in Valgrind (#2644)  There is a daily test failure in valgrind, which looks like an issue related to slowness in valgrind mode.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com> Signed-off-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/ffdf2226942f89d6e170044661b923b612d3457e
valkey-io/valkey,https://github.com/valkey-io/valkey,d21d529,chzhoo,2025-09-22T12:11:49Z,"Optimize skiplist random level generation logic (#2631)  Each insertion of a skiplist node requires generating a random level (via the `zslRandomLevel` function), and some commands (such as `zunionstore`) call the `zslRandomLevel` function multiple times. Therefore, optimizing `zslRandomLevel` can significantly improve the performance of these commands.  The main optimization approach is as follows:  1. Original logic: Each iteration called the `random` function, with a 0.25 probability of continuing to call `random` again. In the worst-case scenario, it required up to 32 calls (though the probability of this occurring is extremely low). 2. Optimized logic: We only need to call the `genrand64_int64` function once. Each iteration uses only 2 bits of randomness, effectively achieving the equivalent of 32 iterations in the original algorithm. 3. Additionally, the introduction of `__builtin_clzll` significantly reduces CPU usage, which compiles into a single, highly efficient CPU instruction (e.g., LZCNT on x86, CLZ on ARM) on supported hardware platforms 4. Although I've explained a lot, the actual code changes are quite minimal, so just look at the code directly.  ---------  Signed-off-by: chzhoo <czawyx@163.com>",https://github.com/valkey-io/valkey/commit/d21d529851bef718ed666ab87d975b32a9c7ac5c
valkey-io/valkey,https://github.com/valkey-io/valkey,298f7da,korjeek,2025-09-21T15:34:30Z,"Adding unit tests for sha256 (#2632)  Adding comprehensive unit tests for SHA-256 implementation.    These tests verify:   1. Basic functionality with known test vectors (e.g., ""abc"")   2. Handling of large input data (4KB repeated 1000 times) 3. Edge case with repeated single-byte input (1 million 'a' characters)   The tests ensure compatibility with standard SHA-256 implementations and will help detect regressions during future code changes.",https://github.com/valkey-io/valkey/commit/298f7dae60386df154d272a496c7e9ac7dcfbd6c
valkey-io/valkey,https://github.com/valkey-io/valkey,8d562d2,Sarthak Aggarwal,2025-09-20T00:44:51Z,Fix closing slot migration pipe read (#2630)  We probably should close the correct `slot_migration_pipe_read`. It should resolve the valgrind errors.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/8d562d26df25cae9f354e0d447979d4b53f061e9
valkey-io/valkey,https://github.com/valkey-io/valkey,78060cb,Ricardo Dias,2025-09-19T18:37:09Z,"Fix test that checks `extended-redis-compatibility` config deprecation rules (#2629)  Following the decision in #2189, we need to fix this test because the `extended-redis-compatibility` config option is not going to be deprecated in 9.0.  This commit changes the test to postpone the deprecation of `extended-redis-compatibility` until 10.0 release.  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/78060cb675e734652888bb1b2a4c1b3fa5734589
valkey-io/valkey,https://github.com/valkey-io/valkey,ff1d017,Sarthak Aggarwal,2025-09-19T02:16:43Z,Fix flaky cluster flush slot test (#2626)  The reason is that the replication stream may not have yet reached the replica for execution. We could add a wait_for_condition. We decided to replace those assert calls with assert_replication_stream to verify the contents of the replication stream rather than the commandstats. ``` *** [err]: Flush slot command propagated to replica in tests/unit/cluster/cluster-flush-slot.tcl ```  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com> Signed-off-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/ff1d017958783904169e0b53fd80f76b9f7ef143
valkey-io/valkey,https://github.com/valkey-io/valkey,e53d7de,Roshan Khatri,2025-09-18T17:42:13Z,Update automated benchmarking configs (#2625)  reduce the req and warmup time to finish in 6 hrs as the github workflow times out after 6 hrs  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>,https://github.com/valkey-io/valkey/commit/e53d7de40e5a2aa8605601707ec992e790c47201
valkey-io/valkey,https://github.com/valkey-io/valkey,f6a0f8c,Binbin,2025-09-18T08:26:42Z,"Separate RDB snapshotting from atomic slot migration (#2533)  When we adding atomic slot migration in #1949, we reused a lot of rdb save code, it was an easier way to implement ASM in the first time, but it comes with some side effect. Like we are using CHILD_TYPE_RDB to do the fork, we use rdb.c/rdb.h function to save the snapshot, these mess up the logs (we will print some logs saying we are doing RDB stuff) and mess up the info fields (we will say we are rdb_bgsave_in_progress but actually we are doing slot migration).  In addition, it makes the code difficult to maintain. The rdb_save method uses a lot of rdb_* variables, but we are actually doing slot migration. If we want to support one fork with multiple target nodes, we need to rewrite these code for a better cleanup.  Note that the changes to rdb.c/rdb.h are reverting previous changes from when we was reusing this code for slot migration. The slot migration snapshot logic is similar to the previous diskless replication. We use pipe to transfer the snapshot data from the child process to the parent process.  Interface changes: - New slot_migration_fork_in_progress info field. - New cow_size field in CLUSTER GETSLOTMIGRATIONS command. - Also add slot migration fork to the cluster class trace latency.  Signed-off-by: Binbin <binloveplay1314@qq.com> Signed-off-by: Jacob Murphy <jkmurphy@google.com> Co-authored-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/f6a0f8cfc0079407d9df05ec50cedac8f9c684b6
valkey-io/valkey,https://github.com/valkey-io/valkey,80bbbcf,uriyage,2025-09-17T08:14:44Z,Fix memory leak in deferred reply buffer (#2615)  Set free method for deferred_reply list to properly clean up  ClientReplyValue objects when the list is destroyed  Signed-off-by: Uri Yagelnik <uriy@amazon.com>,https://github.com/valkey-io/valkey/commit/80bbbcf6fe321b513b95d68c15d270de4f18edf6
valkey-io/valkey,https://github.com/valkey-io/valkey,73d5b0e,Roshan Khatri,2025-09-16T21:09:39Z,"Adds io-threads configs to PR-perf tests (#2598)  - Adds io-thread enabled perf-tests for pr - changes the server and benchmark client cpu ranges so there are on separate NUMA nodes of the metal machine. - Also kill any servers that are active on the metal machine if anything fails. - Adds a benchmark wf to benchmark versions and publish on a issue id provided: <img width=""340"" height=""449"" alt=""Screenshot 2025-09-11 at 12 14 28 PM"" src=""https://github.com/user-attachments/assets/04f6a781-e163-4d6b-9b70-deedad15c9ef"" />  - Comments on the issue with the full comparison like this:   <img width=""936"" height=""1152"" alt=""Screenshot 2025-09-11 at 12 15 35 PM"" src=""https://github.com/user-attachments/assets/e1584c8e-25dc-433f-a4d4-5b08d7548ddf"" />  https://github.com/roshkhatri/valkey/pull/3#issuecomment-3282289440  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com>",https://github.com/valkey-io/valkey/commit/73d5b0ed9b2d860a895ab7c6d64b3063fd17fc86
valkey-io/valkey,https://github.com/valkey-io/valkey,fab2a12,Sarthak Aggarwal,2025-09-16T02:55:27Z,"Increase wait time condition for New Master down consecutively test (#2612)  With #2604 merged, the `Node #10 should eventually replicate node #5` started passing successfully with valgrind, but I guess we are seeing a new daily failure from a `New Master down consecutively` test that runs shortly after.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/fab2a12c510399a70b09ab3215f690e012863e34
valkey-io/valkey,https://github.com/valkey-io/valkey,93d7cca,Sarthak Aggarwal,2025-09-16T00:08:59Z,"Fix accounting for dual channel RDB bytes in replication stats (#2602)  Resolves #2545   Followed the steps to reproduce the issue, and was able to get non-zero `total_net_repl_output_bytes`.  ``` (base) ~/workspace/valkey git:[fix-bug-2545] src/valkey-cli INFO | grep total_net_repl_output_bytes total_net_repl_output_bytes:1788 ```  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/93d7ccab03779afe70762740129bd34b840e663f
valkey-io/valkey,https://github.com/valkey-io/valkey,a47e8fa,Vitali,2025-09-13T07:53:07Z,Expand wait condition time for slave selection test (#2604)  ## Summary - extend replication wait time in `slave-selection` test  ``` *** [err]: Node #10 should eventually replicate node #5 in tests/unit/cluster/slave-selection.tcl #10 didn't became slave of #5 ```  ## Testing - `./runtest --single unit/cluster/slave-selection` - `./runtest --single unit/cluster/slave-selection --valgrind`  Signed-off-by: Vitali Arbuzov <Vitali.Arbuzov@proton.me> Signed-off-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>,https://github.com/valkey-io/valkey/commit/a47e8fa1505578d78cef5c5e11da0972c3dae560
valkey-io/valkey,https://github.com/valkey-io/valkey,2b7d5f7,Jacob Murphy,2025-09-12T19:35:18Z,"Make modules opt-in to atomic slot migration and add server events (#2593)  As discussed in https://github.com/valkey-io/valkey/issues/2579  Notably, I am exposing this feature as ""Atomic Slot Migration"" to modules. If we want to call it something else, we should consider that now (e.g.. ""Replication-Based Slot Migration""?)  Also note: I am exposing both target and source node in the event. It is not guaranteed that either target or source would be the node the event fires on (e.g. replicas will fire the event after replica containment is introduced). Even though it could be potentially inferred from CLUSTER SLOTS, it should help modules parse it this way. Modules should be able to infer whether it is occurring on primary/replica from `ctx` flags, so not duplicating that here.  Closes #2579  ---------  Signed-off-by: Jacob Murphy <jkmurphy@google.com>",https://github.com/valkey-io/valkey/commit/2b7d5f77607d74f0c52212457bb84ab5f7fb5686
valkey-io/valkey,https://github.com/valkey-io/valkey,9b11d3d,Sarthak Aggarwal,2025-09-11T14:19:05Z,"Evict client only when limit is breached (#2596)  I believe we should evict the clients when the client eviction limit is breached instead of _at_ the breach. I came across this function in the failed [daily test](https://github.com/valkey-io/valkey/actions/runs/17521272806/job/49765359298#step:6:7770), which could possibly be related.  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/9b11d3d9edf6b1f1f18976305c0923c5aad60297
valkey-io/valkey,https://github.com/valkey-io/valkey,3213f48,Ran Shidlansik,2025-09-10T10:24:55Z,"Increase frequency of time check during fields active expiration (#2595)  When we introduced the new Hash fields expiration functionality, we decided to combine the current active expiration job between generic keys and hash fields. During that job we run a tight loop. In each loop iteration we scan over maximum of 20 keys (with default expire effort) and try to ""expire"" them. For hash fields expiration job, the ""expire"" of a hash key, means expiring maximum of 80 fields (with default expire effort). The problem is that we might do much more work per each iteration of hash fields expiration job. The current code is shared between the 2 jobs, and currently we only perform time check every 16 iterations. as a result the CPU of fields active expiration can spike and consume much higher CPU% than the current 25% bound allows.  Example:  Before this PR  | Scenario | AVG CPU | Time to expire all fields |  |----------------------------------------------------|---------|---------------------------| | Expiring 10M volatile fields from a single hash | 20.18% | 26 seconds | | Expiring 10M volatile fields from 10K hash objects | 32.72% | 7 seconds |   After this PR Scenario | AVG CPU | Time to expire all fields | Scenario | AVG CPU | Time to expire all fields |  |----------------------------------------------------|---------|---------------------------| | Expiring 10M volatile fields from a single hash | 20.23%. | 26 seconds | | Expiring 10M volatile fields from 10K hash objects | 20.76%. | 11 seconds |  *NOTE* The change introduced here make the field job check the time every iteration. We offer compile time option to use efficient time check using TSC (X86) or VCR (ARM) on most modern CPU, so the impact is expected to be low. Still, in order to avoid degradation for existing workloads, the code change was made so it will not impact the existing generic keys active expiration job.  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/3213f48fd694c201a1ba974bcad0ad7703b44510
valkey-io/valkey,https://github.com/valkey-io/valkey,cef8822,Zhijun Liao,2025-09-09T09:11:08Z,"valkey-cli: Add word-jump navigation (Alt/Option/Ctrl + ←/→) (#2583)  Interactive use of valkey-cli often involves working with long keys (e.g. MY:INCREDIBLY:LONG:keythattakesalongtimetotype). In shells like bash, zsh, or psql, users can quickly move the cursor word by word with **Alt/Option+Left/Right**, **Ctrl+Left/Right** or **Alt/Option+b/f**. This makes editing long commands much more efficient.  Until now, valkey-cli (via linenoise) only supported single-character cursor moves, which is painful for frequent key editing.  This patch adds such support, with simple code changes in linenoise. It now supports both the Meta (Alt/Option) style and CSI (control sequence introducer) style:  | | Meta style | CSI style (Ctrl) | CSI style (Alt) | | --------------- | ---------- | ---------------- | --------- | | move word left  | ESC b      | ESC [1;5D        | ESC [1;3D | | move word right | ESC f      | ESC [1;5C        | ESC [1;3C |  Notice that I handle these two styles differently since people have different preference on the definition of ""what is a word"". Specifically, I define: - ""sub-word"": just letters and digits. For example ""my:namespace:key"" has 3 sub-words. This is handled by Meta style. - ""big-word"": as any character that is not space. For example ""my:namespace:key"" is just one single big-word. This is handled by CSI style.   ## How I verified  I'm using MacOS default terminal (`$TERM = xterm-256color`). I customized the terminal keyboard setting to map option + left to `\033b` , and ctrl + left to `\033[1;5D` so that I can produce both the Meta style and CSI style. This code change should also work for Linux/BSD/other terminal users.  Now the valkey-cli works like the following. `|` shows where the cursor is currently at.  Press Alt + left (escape sequence `ESC b` ):  ``` set cache:item itemid                    |  set cache:item itemid                |  set cache:item itemid           |  set cache:item itemid     |  set cache:item itemid | ```  Press Ctrl + left (escape sequence `ESC [1;5D` ):  ``` set cache:item itemid                     |  set cache:item itemid                |  set cache:item itemid     |  set cache:item itemid | ```  Press Alt + right (escape sequence `ESC f` ):  ``` set cache:item itemid |  set cache:item itemid     |  set cache:item itemid           |	  set cache:item itemid                |  set cache:item itemid                      | ```  Press Ctrl + right  (escape sequence `ESC [1;5C` ):  ``` set cache:item itemid |  set cache:item itemid    |      set cache:item itemid               |      set cache:item itemid                      | ```  ---------  Signed-off-by: Zhijun <dszhijun@gmail.com>",https://github.com/valkey-io/valkey/commit/cef8822f60b6c6d34e05a92d42ed5b638dd7eb9a
valkey-io/valkey,https://github.com/valkey-io/valkey,3b13a7c,Marvin Rösch,2025-09-08T16:38:53Z,"Add cluster-announce-client-(port|tls-port) configs (#2429)  New config options:   * cluster-announce-client-port  * cluster-announce-client-tls-port  If enabled, clients will always get to see the configured port for a node instead of the internally announced port(s), the same way that `cluster-announce-client-ipv4` and `cluster-announce-client-ipv6` work. Cluster-internal communication uses the non-client variant of these options.  The configuration is propagated throughout the cluster using new ping extensions.  Closes #2377  ---------  Signed-off-by: Marvin Rösch <marvinroesch99@gmail.com> Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/3b13a7cd13c22771737fd12be4857797b5eb4d4d
valkey-io/valkey,https://github.com/valkey-io/valkey,5a9ee5b,Binbin,2025-09-08T11:31:51Z,Skip codeql-analysis ci on documentation changes as well (#2567)  Follow #2393.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/5a9ee5b944c6e7dac813e5f0eef6edf51d105317
valkey-io/valkey,https://github.com/valkey-io/valkey,d9382bd,Rain Valentine,2025-09-07T06:52:21Z,"ARM Neon SIMD optimization for hashtable findBucket() (#2573)  This PR resolves #2519. I worked with @ahmadbelb to get a pretty good result. 😁 For `hashtableFind()` I measured 58% speed improvement on a AWS t4g.2xlarge instance, and Ahmad measured 159% speed improvement on a M1 Mac.  I'm still working on valkey-benchmark results for GET and SET throughput.  I used Google Benchmark to make micro benchmarks that test 0% 50% and 100% hit rates for hashtableFind(). You can check out the test code in this branch: https://github.com/SoftlyRaining/valkey/tree/valkey-microbench  My AWS t4g.2xlarge micro benchmark results: ``` Scalar version: Running ./valkey-microbench Run on (8 X 243.75 MHz CPU s) CPU Caches:   L1 Data 64 KiB (x8)   L1 Instruction 64 KiB (x8)   L2 Unified 1024 KiB (x8)   L3 Unified 32768 KiB (x1) Load Average: 6.04, 2.10, 1.14 --------------------------------------------------------------------------------------------------- Benchmark                                                         Time             CPU   Iterations --------------------------------------------------------------------------------------------------- BM_HashtableFind_0Miss/min_time:5.000/repeats:5                50.6 ns         50.6 ns    138342333 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                50.4 ns         50.4 ns    138342333 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                50.7 ns         50.7 ns    138342333 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                50.4 ns         50.4 ns    138342333 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                50.5 ns         50.4 ns    138342333 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_mean           50.5 ns         50.5 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_median         50.5 ns         50.4 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_stddev        0.118 ns        0.118 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_cv             0.23 %          0.23 %             5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               56.6 ns         56.6 ns    123370046 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               56.8 ns         56.8 ns    123370046 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               55.8 ns         55.8 ns    123370046 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               56.4 ns         56.4 ns    123370046 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               56.3 ns         56.3 ns    123370046 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_mean          56.4 ns         56.4 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_median        56.4 ns         56.4 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_stddev       0.363 ns        0.363 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_cv            0.64 %          0.64 %             5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              50.5 ns         50.5 ns    138420288 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              50.4 ns         50.4 ns    138420288 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              50.4 ns         50.4 ns    138420288 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              50.5 ns         50.5 ns    138420288 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              50.4 ns         50.4 ns    138420288 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_mean         50.5 ns         50.4 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_median       50.4 ns         50.4 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_stddev      0.061 ns        0.062 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_cv           0.12 %          0.12 %             5  Neon version: Running ./valkey-microbench Run on (8 X 243.75 MHz CPU s) CPU Caches:   L1 Data 64 KiB (x8)   L1 Instruction 64 KiB (x8)   L2 Unified 1024 KiB (x8)   L3 Unified 32768 KiB (x1) Load Average: 0.35, 0.87, 0.72 --------------------------------------------------------------------------------------------------- Benchmark                                                         Time             CPU   Iterations --------------------------------------------------------------------------------------------------- BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.7 ns         30.7 ns    226597253 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.9 ns         30.9 ns    226597253 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.7 ns         30.6 ns    226597253 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.8 ns         30.8 ns    226597253 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.6 ns         30.6 ns    226597253 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_mean           30.7 ns         30.7 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_median         30.7 ns         30.7 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_stddev        0.118 ns        0.118 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_cv             0.38 %          0.38 %             5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               36.6 ns         36.6 ns    192568222 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               35.2 ns         35.2 ns    192568222 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               34.7 ns         34.7 ns    192568222 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               36.2 ns         36.2 ns    192568222 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               36.0 ns         36.0 ns    192568222 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_mean          35.7 ns         35.7 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_median        36.0 ns         36.0 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_stddev       0.790 ns        0.789 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_cv            2.21 %          2.21 %             5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              30.5 ns         30.5 ns    229190934 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              31.4 ns         31.4 ns    229190934 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              30.7 ns         30.7 ns    229190934 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              30.4 ns         30.4 ns    229190934 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              31.1 ns         31.1 ns    229190934 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_mean         30.8 ns         30.8 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_median       30.7 ns         30.7 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_stddev      0.415 ns        0.414 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_cv           1.35 %          1.34 %             5 ```  Ahmad's M1 Mac micro benchmark results: ``` Scalar version: Running ./src/valkey-microbench Run on (8 X 24 MHz CPU s) CPU Caches:   L1 Data 64 KiB   L1 Instruction 128 KiB   L2 Unified 4096 KiB (x8) Load Average: 4.84, 8.36, 8.53 --------------------------------------------------------------------------------------------------- Benchmark                                                         Time             CPU   Iterations --------------------------------------------------------------------------------------------------- BM_HashtableFind_0Miss/min_time:5.000/repeats:5                29.8 ns         29.5 ns    238219371 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                30.6 ns         29.9 ns    238219371 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                29.9 ns         29.6 ns    238219371 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                29.7 ns         29.4 ns    238219371 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                29.3 ns         29.3 ns    238219371 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_mean           29.8 ns         29.5 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_median         29.8 ns         29.5 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_stddev        0.468 ns        0.250 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_cv             1.57 %          0.85 %             5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               30.8 ns         30.7 ns    228068003 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               31.3 ns         31.0 ns    228068003 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               31.3 ns         31.0 ns    228068003 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               30.9 ns         30.8 ns    228068003 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               31.4 ns         31.1 ns    228068003 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_mean          31.1 ns         30.9 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_median        31.3 ns         31.0 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_stddev       0.288 ns        0.134 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_cv            0.92 %          0.43 %             5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              29.3 ns         29.3 ns    237946966 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              29.4 ns         29.4 ns    237946966 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              29.4 ns         29.4 ns    237946966 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              29.3 ns         29.3 ns    237946966 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              29.4 ns         29.4 ns    237946966 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_mean         29.4 ns         29.4 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_median       29.4 ns         29.4 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_stddev      0.058 ns        0.061 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_cv           0.20 %          0.21 %             5  NEON version: Running ./src/valkey-microbench Run on (8 X 24 MHz CPU s) CPU Caches:   L1 Data 64 KiB   L1 Instruction 128 KiB   L2 Unified 4096 KiB (x8) Load Average: 4.56, 5.43, 7.09 --------------------------------------------------------------------------------------------------- Benchmark                                                         Time             CPU   Iterations --------------------------------------------------------------------------------------------------- BM_HashtableFind_0Miss/min_time:5.000/repeats:5                11.6 ns         11.6 ns    596879005 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                11.9 ns         11.7 ns    596879005 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                11.9 ns         11.8 ns    596879005 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                11.7 ns         11.7 ns    596879005 BM_HashtableFind_0Miss/min_time:5.000/repeats:5                11.7 ns         11.7 ns    596879005 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_mean           11.8 ns         11.7 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_median         11.7 ns         11.7 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_stddev        0.119 ns        0.069 ns            5 BM_HashtableFind_0Miss/min_time:5.000/repeats:5_cv             1.01 %          0.59 %             5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               12.0 ns         11.9 ns    592642763 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               11.9 ns         11.9 ns    592642763 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               12.0 ns         12.0 ns    592642763 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               12.2 ns         12.1 ns    592642763 BM_HashtableFind_50Miss/min_time:5.000/repeats:5               11.9 ns         11.9 ns    592642763 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_mean          12.0 ns         12.0 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_median        12.0 ns         11.9 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_stddev       0.113 ns        0.069 ns            5 BM_HashtableFind_50Miss/min_time:5.000/repeats:5_cv            0.94 %          0.58 %             5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              11.9 ns         11.8 ns    590288406 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              11.9 ns         11.9 ns    590288406 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              12.0 ns         11.9 ns    590288406 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              11.9 ns         11.8 ns    590288406 BM_HashtableFind_100Miss/min_time:5.000/repeats:5              12.6 ns         12.1 ns    590288406 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_mean         12.1 ns         11.9 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_median       11.9 ns         11.9 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_stddev      0.303 ns        0.135 ns            5 BM_HashtableFind_100Miss/min_time:5.000/repeats:5_cv           2.51 %          1.14 %             5 ```  ---------  Signed-off-by: Rain Valentine <rsg000@gmail.com>",https://github.com/valkey-io/valkey/commit/d9382bd9f3cec97a57815e1ad9216aac08b47fbb
valkey-io/valkey,https://github.com/valkey-io/valkey,9d10abf,Viktor Söderqvist,2025-09-04T15:19:52Z,"Relaxed RDB check for foreign RDB formats (#2543)  In #1604, we attempt to read future Valkey RDB formats, but we rejected foreign RDB formats, because of the risk that the opcodes and types added by other projects collide with the new types and opcodes added in recent Valkey versions.  This change accepts foreign RDB versions but limits the types and opcodes to the ones that we can understand, to prevent misinterpretation of types/opcodes which could lead to undefined behavior. If unsupported RDB types or opcodes are seen, we error out.  Additional changes:  * Improve error reporting when encountering unknown RDB types in relaxed version check mode. * Tests for loading various RDB files. * Improvement to valkey-check-rdb to accept future and foreign RDB versions, including tests.  ---------  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/9d10abfbded4ed9633ac50c8c09a9a9965dd6740
valkey-io/valkey,https://github.com/valkey-io/valkey,811a644,Kyle J. Davis,2025-09-03T19:39:49Z,"Un-deprecate commands (#2546)  As per #2459, this PR removes deprecation and `deprecated_since` element and `DEPRECATED` doc flag from commands. Closes #2459.  ---------  Signed-off-by: Kyle J. Davis <kyledvs@amazon.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/811a64407be0e3f8e7d7ad597612eee179e86c46
valkey-io/valkey,https://github.com/valkey-io/valkey,971cdb7,Ted Lyngmo,2025-09-03T16:25:33Z,"Don't use AVX2 instructions if the CPU don't support it (#2571)  `bitops.c`: `serverPopcount()` used `popcountAVX2()`, which as the name implies requires AVX2 support, on AVX-only machines, causing an ""illegal instruction"" error.  Added a `__builtin_cpu_supports(""avx2"")` check and falling back to the platform agnostic version if AVX2 is not supported.  Fixes #2570  Signed-off-by: Ted Lyngmo <ted@lyncon.se>",https://github.com/valkey-io/valkey/commit/971cdb78363ba19306bb610efa9eca44543f6b70
valkey-io/valkey,https://github.com/valkey-io/valkey,47d2203,Ran Shidlansik,2025-09-03T07:03:49Z,Store number of keys with volatile items per slot in RDB aux field and pre-size hashtables on load (#2572)  In Valkey 9.0 we added HFE support which is currently using a per slot hashtable in order to track keys (hash objects) which contains volatile fields. in order to optimize the RDB load we should use the same method for expires and generic keys kvstores.  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Signed-off-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Co-authored-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>,https://github.com/valkey-io/valkey/commit/47d2203c1bba39dbd5de9da1ba1c7acb4b7316e0
valkey-io/valkey,https://github.com/valkey-io/valkey,5ccedaf,asagegeLiu,2025-09-02T23:36:02Z,"Delete the previous comment explaining why changed latency from 5 to 40 (#2574)  Delete the out-of-date comment explaining why changed latency from 5 to 40 in #2421 , which is a leftover of #2553  Signed-off-by: Alina Liu <liusalisa6363@gmail.com>",https://github.com/valkey-io/valkey/commit/5ccedafe3ff3895f73ef69084e9cdf042750d0f8
valkey-io/valkey,https://github.com/valkey-io/valkey,eebed88,Binbin,2025-09-02T01:08:14Z,"Remove deny_blocking check in moduleBlockClient, cleanup code and doc (#2215)  This flag.deny_blocking check causes some code to becomde dead code. Some of the code below checks islua or ismulti, but they are marked with flag.deny_blocking and will return early.  In addition, cleanup some documents, some of them are inaccurate, and restore the code of blocking_auth_cb in tests/modules/auth.c, this reply should be returned from core. The reply used to from the core and was changed to from the module in #1819, and now it is from the core again.  Cleanup some dead code around #1819.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/eebed884294c31c6a9040e5da4fd7f2830e2bf31
valkey-io/valkey,https://github.com/valkey-io/valkey,b44de37,Ricardo Dias,2025-09-01T14:02:26Z,"New module API event for tracking authentication attempts (#2237)  In this commit we introduce a new module API event called `ValkeyModuleEvent_AuthenticationAttempt` to track successful/failed authentication attempts.  This event will fill a struct, called `ValkeyModuleAuthenticationInfo`, with the client ID of the connection, the username, the module name that handle the authentication event, and the result of the authentication attempt.  Fixes: #2211  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/b44de37b7d2a2f6f313fd58f88bd1b1bddce195a
valkey-io/valkey,https://github.com/valkey-io/valkey,c039b69,Ricardo Dias,2025-09-01T10:35:37Z,"Fix module context object re-usage in scripting engines (#2358)  This commit refactors the scripting engine to support multiple cached module contexts per engine, rather than relying on a single cached `ValkeyModuleCtx` object.  Previously, having only one cached context object caused data races over the state stored in the context object, because it's possible that a script that is running for a long time to yield and the server event loop may call the `scriptingEngineCallGetMemoryInfo` function to get the scripting engine memory information, which re-uses the same cached context object. Another possible data-race is caused by the asynchronous scripts flush, which calls the `scriptingEngineCallFreeFunction` function in an background thread, and also re-uses the cached context object.  To address this, a cache array of module contexts was introduced in the scripting engine structure, with each slot dedicated to a specific use case—such as script execution, memory info queries, or function freeing.  ---------  Signed-off-by: Ricardo Dias <ricardo.dias@percona.com>",https://github.com/valkey-io/valkey/commit/c039b691c42810a39b08bc8223daba45a665d17f
valkey-io/valkey,https://github.com/valkey-io/valkey,e19fc4d,Binbin,2025-08-30T10:06:12Z,Add jacob as a commiter (#2566)  Add @murphyjacob4 as one of the folks with write permissions on the Valkey repo.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/e19fc4d1e6d1262531ddb77fb62087d91223394d
valkey-io/valkey,https://github.com/valkey-io/valkey,d6e011f,asagegeLiu,2025-08-29T19:32:33Z,"Reduce active defrag test latency by lowering hit threshold (#2553)  Changed the defrag hit threshold from 512 to 1 in the `defragLaterStep` & `defragStageKvstoreHelper` function to reduce defrag latency. (idea from Jim)  1. Previously, the defrag loop would continue processing up to 512 successful defragmentations before checking if the time limit was exceeded. Now it checks after every single successful allocation move. 2. The trade-off is slightly more frequent time checks, but the time check (~19ns) is negligible compared to the actual defragmentation work (even a single 8-byte reallocation takes ~43ns and the allocatorShouldDefrag function call takes ~49ns per block). This overhead is minimal compared to the latency improvement gained from better time management during active defragmentation. 3. Also revert the change from https://github.com/valkey-io/valkey/pull/2421/files to test. 4. Solved compilation issue with unsigned by changing the type of the local variable `prev_defragged `to match the type of `server.stat_active_defrag_hits`  Closes #2444  ---------  Signed-off-by: Alina Liu <alinalq@dev-dsk-alinalq-2b-2db84246.us-west-2.amazon.com> Co-authored-by: Alina Liu <alinalq@dev-dsk-alinalq-2b-2db84246.us-west-2.amazon.com>",https://github.com/valkey-io/valkey/commit/d6e011f955b18f5af46af07569c686a16d82e129
valkey-io/valkey,https://github.com/valkey-io/valkey,6774d17,zhaozhao.zz,2025-08-29T02:47:10Z,"Fix the issue of incorrect commandlog metrics in the script (#2565)  In script, client will be replaced with its caller, so commandlog needs to use the metrics of the client that currently executing the command.  Signed-off-by: zhaozhao.zz <zhaozhao.zz@alibaba-inc.com>",https://github.com/valkey-io/valkey/commit/6774d173c4a3b931dae953158beb1f85af43e972
valkey-io/valkey,https://github.com/valkey-io/valkey,3db75f5,withRiver,2025-08-29T02:21:23Z,"Reset cluster related stats in CONFIG RESETSTATS (#2458)  Previously CONFIG RESETSTATS only resets the slot statistics in cluster part, this PR makes it reset cluster bus messages at well. Additionally, we also reset stat_cluster_links_buffer_limit_exceeded.  Now we will reset: - cluster_stats_messages_sent* - cluster_stats_messages_received* - total_cluster_links_buffer_limit_exceeded  Closes #2439.  Signed-off-by: Hongrui <2086160503@qq.com>",https://github.com/valkey-io/valkey/commit/3db75f5551cdf6da8aa27b719d52cce598fd0b54
valkey-io/valkey,https://github.com/valkey-io/valkey,88cd208,Binbin,2025-08-29T02:20:50Z,"Split SLOT_EXPORT_AUTHENTICATING into SEND and READ to avoid synchronous reading of auth response (#2494)  The old SLOT_EXPORT_AUTHENTICATING added in #1949, when processed by the source node, we will send the AUTH command and then reads the response. If the target node is blocked during this process, the source node will also be blocked. We should use a read handler to handle this. We split SLOT_EXPORT_AUTHENTICATING into SLOT_EXPORT_SEND_AUTH and SLOT_EXPORT_READ_AUTH_RESPONSE to avoid this issue.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/88cd2086aef25183ae0c5fb8bc154d8206dd07f1
valkey-io/valkey,https://github.com/valkey-io/valkey,cf90acb,Marc Jakobi,2025-08-29T02:19:46Z,Correct path to gen-test-certs.sh in README.md (#2554)  Signed-off-by: Marc Jakobi <marc.jakobi@tiko.energy>,https://github.com/valkey-io/valkey/commit/cf90acbc6137ede7ae17fb1450c8aa19a62d163c
valkey-io/valkey,https://github.com/valkey-io/valkey,39fade4,Binbin,2025-08-29T02:18:45Z,"Do not migrate function in new atomic slot migration (#2547)  If all cluster nodes have functions, slot migration will fail since the target will return the function already exists error when doing the FUNCTION LOAD.  And in addition, the target's replica could panic when it executes the FUNCTION LOAD propagated from the primary (see propagation-error-behavior).  Introduced in #1949.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/39fade42d11a22d4a13beb98d6e36adaa12ecba3
valkey-io/valkey,https://github.com/valkey-io/valkey,682fc0b,Binbin,2025-08-29T02:17:10Z,"Remove the trailing chars of the --cluster reshard log message in valkey-cli (#2560)  It prints an extra "": "" after the message, which is a bit weird, i thought it was printing cluster-bus port information, but it was not. ``` Moving slot 5458 from 127.0.0.1:30001 to 127.0.0.1:30003: Moving slot 5459 from 127.0.0.1:30001 to 127.0.0.1:30003: Moving slot 5460 from 127.0.0.1:30001 to 127.0.0.1:30003: ```  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/682fc0b4197311a2bc0ea2512151ee29a2b1d327
valkey-io/valkey,https://github.com/valkey-io/valkey,06cefc1,Viktor Söderqvist,2025-08-27T05:24:00Z,"Attempt to fix sub-replica getting out of sync (#2548)  Try to fix the failures seen for `test ""PSYNC2 #3899 regression: verify consistency""`.  This change resets the query buffer parser state in `replicationCachePrimary()` which is called when the connection to the primary is lost. Before #2092, this was done by `resetClient()`.  The solution was inspired by the discussion about the regression mentioned (discussion from 2017) and the related commits from that time: 6bc6bd4c384d2b87353c3f2bb552e3b44dd53a5b, 469d6e2b37e2913ecb673f910cdb7dbd3af18a67, c180bc7d98061fd59be54ca83b67abfd6ce65414.  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/06cefc181abbe458d59a0c4865670810a9cb65d3
valkey-io/valkey,https://github.com/valkey-io/valkey,1ba622b,Binbin,2025-08-27T02:17:48Z,Update tests/xxx/tmp/.gitignore to ignore everything (#2542)  Ingore everything on its own directory.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/1ba622bad5369ece4e88946e7a9b1d65541bc8db
valkey-io/valkey,https://github.com/valkey-io/valkey,40fe422,Rain Valentine,2025-08-26T07:02:14Z,"deflake test: relax time requirement in hash ttl test (#2537)  tiny change. It failed once for me (a little time passed and it returned 2 seconds instead of 3), so I figured it's probably a little flaky for others too  ---------  Signed-off-by: Rain Valentine <rsg000@gmail.com>",https://github.com/valkey-io/valkey/commit/40fe4228992f39e31f1481f052ed6bc5c090353d
valkey-io/valkey,https://github.com/valkey-io/valkey,3086e61,Adam Fowler,2025-08-26T07:01:12Z,Update reply schema for LMOVE and BLMOVE (#2541)  Both LMOVE and BLMOVE can return null values because the source key is empty. PR changes include  - change the LMOVE reply_schema to include the possibility of a nil return value - Add comment to BLMOVE reply_schema to indicate it can return nil because the source does not exist  This fixes #2532  ---------  Signed-off-by: Adam Fowler <adamfowler71@gmail.com> Co-authored-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/3086e61d4b06a81602fc74163eb7d4eb6b6bfe41
valkey-io/valkey,https://github.com/valkey-io/valkey,9d682ba,Ted Lyngmo,2025-08-25T10:24:34Z,bio.c: Organize all worker data in a struct (#2530)  This gets rid of the need to use a void* as a carrier for the worker number. Instead a pointer to the relevant worker data is passed to the started thread.  Fixes #2529  ---------  Signed-off-by: Ted Lyngmo <ted@lyncon.se>,https://github.com/valkey-io/valkey/commit/9d682bad0bb731de8e21e15e4a1795c73aee9d0d
valkey-io/valkey,https://github.com/valkey-io/valkey,9aeab8c,Madelyn Olson,2025-08-24T12:59:13Z,"Consistently use static_assert across code (#2538)  In C99, we had to use `#define static_assert(expr, lit) extern char __static_assert_failure[(expr) ? 1 : -1]` for static assertions. However, we now have native support for static_assert with _Static_assert. Previously one of the correct #defines was getting called first, setting it to _Static_assert, however after https://github.com/valkey-io/valkey/commit/65215e5378db7b47c3460567da134ab7f0bfeb58 the first import defining the symbol was ""serverassert.h"", which included the old style.  This change removes all unnecessary imports and always defines static_assert as _Static_assert.  Signed-off-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/9aeab8ccbac0ca4923676c749c98d0de4718c872
valkey-io/valkey,https://github.com/valkey-io/valkey,8c55547,Binbin,2025-08-22T19:08:20Z,"Don't allow slot migration to myself node (#2497)  This may result in meaningless slot migration job, we should return an error to user in advance to avoid operation error. Also `by myself` is not correct English grammar and `myself` is a internal code terminology, changed to `by this node`.  Was introduced in #1949.  ---------  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/8c55547999a980680997a2c0c2bd292a7112da9c
valkey-io/valkey,https://github.com/valkey-io/valkey,09fb436,Viktor Söderqvist,2025-08-22T14:02:27Z,"Optimize pipelining by parsing and prefetching multiple commands (#2092)  Instead of parsing only one command per client before executing it, parse multiple commands from the query buffer and batch-prefetch the keys accessed by the commands in the queue before executing them.  This is an optimization for pipelined commands, both with and without I/O threads. The optimization is currently disabled for the replication stream, due to failures (probably caused by how the replication offset is calculated based on the query buffer offset).  * When parsing commands from the input buffer, multiple commands are parsed and stored in a command queue per client. * In single-threaded mode (I/O threads off) keys are batch-prefetched before the commands in the queue are executed. Multi-key commands like MGET, MSET and DEL benefit from this even if pipelining is not used. * Prefetching when I/O threads are used does prefetching for multiple clients in parallel. This code takes client command queues into account, improving prefetching when pipelining is used. The batch size is controlled by the existing config `prefetch-batch-max-size` (default 16), which so far only was used together with I/O threads. The config is moved to a different section in `valkey.conf`. * When I/O threads are used and the maximum number of keys are prefetched, a client's command is executed, then the next one in the queue, etc. If there are more commands in the queue for which the keys have not been prefetched (say the client sends 16 pipelined MGET with 16 keys in each) keys for the next few commands in the queue are prefetched before the commands is executed if prefetching has not been done for the next command. (This utilizes the code path used in single-threaded mode.)  Code improvements:  * Decoupling of command parser state and command execution state:   * The variables reqtype, multibulklen and bulklen refer to the current     position in the query buffer. These are no longer reset in resetClient     (which runs after each command being executed). Instead, they are     reset in the parser code after each completely parsed command.   * The command parser code is partially decoupled from the client struct.     The query buffer is still one per client, but the resulting argument     vector is stored in caller-defined variables.  Fixes #2044  ---------  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech> Signed-off-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/09fb436cf0e8804b1e16c8d83ccf9c27775e8742
valkey-io/valkey,https://github.com/valkey-io/valkey,ac51515,Binbin,2025-08-22T09:19:44Z,"Remove debug logging from cluster-flush-slot.tcl (#2535)  I believe this was a debug log at the time, and its printing was quite annoying locally. The test is quite simple so i think we can just remove it.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/ac515159a1e79ada6e43ed49c9ed9cb11178c50d
valkey-io/valkey,https://github.com/valkey-io/valkey,a680407,Roshan Khatri,2025-08-22T00:31:17Z,"Adds benchmark on demand workflow (#2442)  # Adds On-demand Benchmark Workflow  This PR introduces a new GitHub Actions workflow that enables on-demand performance benchmarking for pull requests through label-based triggers. This uses the new framework [valkey-perf-benchmark](https://github.com/valkey-io/valkey-perf-benchmark) developed for standard benchmarks and PR benchmarking.  ## What is being added by this PR  - **Workflow File**: `.github/workflows/benchmark_on_label.yml` - **Trigger**: Activated when specific labels are added to PRs - **Supported Labels**:   - `run-benchmark` - Runs standard benchmarks    ## Features  ### On-Demand Execution - Benchmarks run only when explicitly requested via PR labels - No automatic execution to avoid unnecessary resource usage  ### Performance Comparison - Compares PR performance against the `unstable` baseline - Generates detailed comparison reports - Posts results directly as PR comments for easy review  ### Flexible Configuration - Currently uses github runners by will use dedicated performance runners (`ec2-perf-ubuntu-24`) - Configurable benchmark suites via JSON config files  ### Artifact Management - Uploads benchmark results as workflow artifacts - Preserves both baseline and PR metrics for analysis - Includes comparison markdown for offline review  ### Automatic Cleanup - Removes trigger labels after execution (success or failure) - Prevents accidental re-runs from stale labels  ## Usage  To run benchmarks on a PR:  1. Add the `run-benchmark` label for standalone and cluster, non-tls mode 2. Wait for the workflow to complete 3. Review results in the automated PR comment  This workflow enhances our CI/CD pipeline by providing easy access to performance testing without impacting regular development workflows.  ---------  Signed-off-by: Roshan Khatri <rvkhatri@amazon.com> Signed-off-by: Roshan Khatri <117414976+roshkhatri@users.noreply.github.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>",https://github.com/valkey-io/valkey/commit/a68040789e7566ab2aabad28459fa07dad43db60
valkey-io/valkey,https://github.com/valkey-io/valkey,d2eee78,Allen Samuels,2025-08-21T20:09:22Z,"Module API: Add READONLY flag to ClientInfo.flags output structure (#2522)  * Add a flag `VALKEYMODULE_CLIENTINFO_FLAG_READONLY` to   `ValkeyModuleClientInfo.flags` and set it in   `ValkeyModule_GetClientInfoById()`. * Add an optimization for accessing the current client by ID, to avoid   looking it up in a radix tree.  Closes #2487  ---------  Signed-off-by: Allen Samuels <allenss@amazon.com>",https://github.com/valkey-io/valkey/commit/d2eee78a151884518441572c53fc378bf6689e81
valkey-io/valkey,https://github.com/valkey-io/valkey,85a0a01,Hanxi Zhang,2025-08-21T19:34:27Z,"Wait for log message occurrence in module test on message received (#2517)  ## Problem Test `Cluster module receive message API - VM_RegisterClusterMessageReceiver` fails sporadically in CI with ""Expected '2' to be equal to '1'"". The test failed in Daily CI 4 days ago but hasn't failed since, indicating flaky behavior that I cannot reproduce locally.   ## Hypothesis The failing line `assert_equal 2 [count_log_message 0 ""* <cluster> DONG (type 2) RECEIVED*""]` counts DONG message entries in node 0's log file and expects exactly 2. The failure suggests a possible race condition where there's a timing gap between when cluster statistics are updated and when the corresponding log entries become visible in the log file.   ## Solution Add `wait_for_condition` to ensure log messages are written before checking count:  ```tcl wait_for_condition 50 100 {     [count_log_message 0 ""* <cluster> DONG (type 2) RECEIVED*""] eq 2 } else {     fail ""node 1 didn't log 2 DONG messages"" }  ---------  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>",https://github.com/valkey-io/valkey/commit/85a0a017d28c1471885a0e10c3c9c3be64c3e4e8
valkey-io/valkey,https://github.com/valkey-io/valkey,b8357e5,Sarthak Aggarwal,2025-08-21T18:02:29Z,"Fix slot range lists overlap to rewind the nested list again  (#2527)  In the current implementation, the second list was never rewound again once it was iterated. So for the first element of `ranges1`, `ranges2` was iterated fully. But when the second element of `ranges1` was processed, the `ranges2` was not rewound again.  With this change, for every element of `ranges1`, we start from the beginning for `ranges2`  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/b8357e5be83dd19411c77a4e5f1052a3f863e8c9
valkey-io/valkey,https://github.com/valkey-io/valkey,2db4eeb,Björn Svensson,2025-08-21T08:18:29Z,Remove temporary build correction for RDMA and libvalkey 0.1.0  Signed-off-by: Björn Svensson <bjorn.a.svensson@est.tech>,https://github.com/valkey-io/valkey/commit/2db4eeb1fcd8316a792476c3023e705be24fdd70
valkey-io/valkey,https://github.com/valkey-io/valkey,11780db,Björn Svensson,2025-08-21T08:30:55Z,Update deps/libvalkey to version 0.2.1  Squashed 'deps/libvalkey/' changes from abcd27fbf..b012f8e85  b012f8e85 Release 0.2.1 9e10acbf7 Fix duplicate Acks for RDMA events. (#229) 1eadedf48 Remove the unused valDup API from dict a449f0ea1 Don't expose internal functions in shared libraries (#205) 178e350c7 Cluster code cleanup (#216) 4020396c8 Fix `unused-parameter` warning when building with `NDEBUG` (#212) 99aa158bc Use existing connections for blocking slotmap updates (#199) 969a8c546 Fix dependency issue with RDMA (#201) ...  git-subtree-dir: deps/libvalkey git-subtree-split: b012f8e85a9cc2c68bc2be982a4f6545c15042f0  Signed-off-by: Björn Svensson <bjorn.a.svensson@est.tech>,https://github.com/valkey-io/valkey/commit/11780db513b14034b3a314d4d4e5f52a3be44477
valkey-io/valkey,https://github.com/valkey-io/valkey,84fd626,asagegeLiu,2025-08-21T00:18:44Z,Refactor scanLaterList to fix latency issue (#2514),https://github.com/valkey-io/valkey/commit/84fd6264190094c045de488308b905853683d135
valkey-io/valkey,https://github.com/valkey-io/valkey,c6c91d1,Ted Lyngmo,2025-08-20T20:48:31Z,Fix assumptions that pthread functions set errno (#2526)  pthread functions return the error instead of setting errno.  Fixes #2525  Signed-off-by: Ted Lyngmo <ted@lyncon.se>,https://github.com/valkey-io/valkey/commit/c6c91d152fb706da9c7d40b7ed5dfd7216a88b5d
valkey-io/valkey,https://github.com/valkey-io/valkey,ab3ee2c,Sarthak Aggarwal,2025-08-20T18:16:37Z,Fix total test count while running over loop (#2524)  Command: `./runtest --single unit/bitops --loops 3`  Unstable  ``` [ignore]: large memory flag not provided [-1/1 done]: unit/bitops (4 seconds) [ignore]: large memory flag not provided [0/1 done]: unit/bitops (4 seconds) [ignore]: large memory flag not provided [1/1 done]: unit/bitops (4 seconds)                     The End  Execution time of different units:   4 seconds - unit/bitops   4 seconds - unit/bitops   4 seconds - unit/bitops ```  After fix  ``` [1/3 done]: unit/bitops (4 seconds) [ignore]: large memory flag not provided [2/3 done]: unit/bitops (4 seconds) [ignore]: large memory flag not provided [3/3 done]: unit/bitops (4 seconds)                     The End  Execution time of different units:   4 seconds - unit/bitops   4 seconds - unit/bitops   4 seconds - unit/bitops ```  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/ab3ee2ca9530ba527959fa36b1c3b0222a2675a6
valkey-io/valkey,https://github.com/valkey-io/valkey,23112fa,Ran Shidlansik,2025-08-20T11:54:11Z,fix hsetex handling of wrong number of fields (#2509)  currently hsetex is verifying the number of fields matches the provided number of fields by using div. instead it can match to the multiplication in order to prevent rounding the verified value down.  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>,https://github.com/valkey-io/valkey/commit/23112fad87e65380d4774233fc0fa1edb65c9364
valkey-io/valkey,https://github.com/valkey-io/valkey,39d5c6e,Ran Shidlansik,2025-08-20T09:34:58Z,Fix vset unittest compilation warning for bad signedness comparison (#2523)  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/39d5c6e6ee46b839c935974eb7ff4de7d87399f7
valkey-io/valkey,https://github.com/valkey-io/valkey,3b69618,Harkrishn Patro,2025-08-20T04:38:46Z,Update pong_received time via gossip only if the node is healthy from our view (#2512),https://github.com/valkey-io/valkey/commit/3b6961814b027b864b340c4e5c7dd41a2fc34cd2
valkey-io/valkey,https://github.com/valkey-io/valkey,e3bfc5f,Harkrishn Patro,2025-08-20T00:28:51Z,"Atomically update cluster and replication layer while marking self node as primary (#2510)  Fixes: #2460  With this change we avoid divergence in cluster and replication layer view. I've observed node can be marked as primary in cluster while it can be marked as replica in replication layer view and have a active replication link. Without this change, we used to end up in a invalid replica chain in replication layer.  ---------  Signed-off-by: Harkrishn Patro <harkrisp@amazon.com>",https://github.com/valkey-io/valkey/commit/e3bfc5f8c7146198ef2eb749866d7226f3b098d8
valkey-io/valkey,https://github.com/valkey-io/valkey,c8548f6,Seungmin Lee,2025-08-19T22:24:26Z,"Skip failure reports for already failed nodes (#2434)  This change avoids additional failure report creation if the node is already marked as failed. The failure report count has never been used after a node has been marked as failed. So, there is no value addition in maintaining it further. This reduces operation of both add and delete failure report. Hence, the performance benefit.  We can observe an avg. of 10% reduction in p99 CPU utilization (in a 2000 nodes cluster (1000 primary/ 1000 replica) with 330 nodes in failed state with this change.  ---------  Signed-off-by: Seungmin Lee <sungming@amazon.com>",https://github.com/valkey-io/valkey/commit/c8548f65d23725bcd70b92f4e06844274a940f40
valkey-io/valkey,https://github.com/valkey-io/valkey,eae23ba,Hanxi Zhang,2025-08-19T20:49:25Z,"Add auto-author-assign workflow (#2410)  Fixes #2372  ## Description  This PR adds an automated workflow that assigns PR authors to their own pull requests when opened or reopened.  ## Changes  - Added `.github/workflows/auto-author-assign.yml` workflow - Uses `toshimaru/auto-author-assign@v2.1.1` action - Triggers on `pull_request_target` events (opened, reopened) - Requires `pull-requests: write` permission  ## Benefits  - Improves PR tracking and organization - Automatically assigns responsibility to PR authors - Reduces manual assignment overhead for maintainers - Helps contributors track their own PRs more easily  ## Testing  ✅ **Tested on my fork before submission:**  1. Merged the workflow into my fork's unstable branch 2. Created a test PR within my fork 3. Verified that I was automatically assigned as the assignee 4. Screenshot showing successful auto-assignment: <img width=""1278"" height=""684"" alt=""Screenshot 2025-08-01 at 3 39 05 PM"" src=""https://github.com/user-attachments/assets/9ad643be-5eac-4ad6-bec7-184cf22e9cbd"" />  The workflow executed successfully and assigned me to the test PR as expected.  ---------  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com>",https://github.com/valkey-io/valkey/commit/eae23babe63e4e32498da3d16e4cb368354c044b
valkey-io/valkey,https://github.com/valkey-io/valkey,a97d584,Binbin,2025-08-19T13:01:56Z,"Fix slot-info expand not working, kvstoreHashtableExpand always creat… (#2466)  If we want to expand kvstoreHashtableExpand, we need to make sure the hashtable exists. Currently, when processing RDB slot-info, our expand has no effect because the hashtable does not exist (we initialize it only when we need it).  We also update kvstoreExpand to use the kvstoreHashtableExpand to make sure there is only one code path. Also see #1199 for more details.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/a97d584cc20013c6797843a30633f0f268874d28
valkey-io/valkey,https://github.com/valkey-io/valkey,bb81f8d,Ran Shidlansik,2025-08-19T08:31:37Z,fix hash ignore ttl management during active expiry (#2505)  several fixes: 1. fix not using bool input type for hashTypeIgnoreTTL - probably lost during the 3 HFE PR merges 2. remove vset change hashtable encoding to single - The current code is a bug. The entry is probably expired (or about to be expired soon) so we can leave it as a hashtable till it does. 3. enable incremental rehashing for volatile item keys kvstore - This is the center issue of this PR. without it the activeexpiry might not scan the kvstore which is very fragmented with lots of empty buckets.  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/bb81f8d14f6b32df7b4798dd8e35f45f257f6968
valkey-io/valkey,https://github.com/valkey-io/valkey,fb9503b,Binbin,2025-08-19T02:26:58Z,CLUSTER SYNCSLOTS ESTABLISH added source node == myself check (#2500)  Minor cleanup.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/fb9503bfd12bf8331647b151c3af0b28fa4d7e7a
valkey-io/valkey,https://github.com/valkey-io/valkey,2ca0dd8,Viktor Söderqvist,2025-08-18T13:34:51Z,"Make cluster failover delay relative to node timeout (#2449)  In clusters with a very short node timeout such as 2-3 seconds, the extra failover delay of 500-1000 milliseconds (500 + random value 0-500; total 750 on average) before initiating a failover is a significant extra downtime to the cluster. This PR makes this delay relative to node timeout, using a shorter failover delay for a smaller configured node timeout. The formula is `fixed_delay = min(500, node_timeout / 30)`.  | Node timeout  | Fixed failover delay | |---------------|----------------------| | 15000 or more | 500 (same as before) | | 7500          | 250                  | | 3000          | 100                  | | 1500          | 50                   |  Additional change: Add an extra 500ms delay to new replicas that may not yet know about the other replicas. This avoids the scenario where a new replica with no data wins the failover. This change turned out to be needed to for the stability of some test cases.  The purposes of the failover delay are  1. Allow FAIL to propagate to the voting primaries in the cluster 2. Allow replicas to exchange their offsets, so they will have a correct view of their own rank.  A third (undocumented) purpose of this delay is to allow newly added replicas to discover other replicas in the cluster via gossip and to compute their rank, to realize it's are not the best replica. This case is mitigated by adding another 500ms delay to new replicas, i.e. if it has replication offset 0.  A low node timeout only makes sense in fast networks, so we can assume that the above needs less time than in a cluster with a higher node timeout.  These delays don't affect the correctness of the algorithm. They are just there to increase the probability that a failover will succeed by making sure that the FAIL message has enough time to propagate in the cluster and to the random part is to reduce the probability that two replicas initiates the failover at the same time.  The typical use case is when data consistency matters and writes can't be skipped. For example, in some application, we buffer writes in the application during node failures to be able to apply them when the failover is completed. The application can't buffer them for a very long time, so we need the cluster to be up again within e.g. 5 seconds from the time a node starts to fail.  I hope this PR can be considered safer than #2227, although the two changes are orthogonal.  Part of issue #2023.  ---------  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>",https://github.com/valkey-io/valkey/commit/2ca0dd878196033811a69a9a2a3381030e5264dd
valkey-io/valkey,https://github.com/valkey-io/valkey,7a5c0d0,Binbin,2025-08-18T10:59:40Z,"Fix memory leak in saveSnapshotToConnectionSockets (#2503)  We now pass in rdbSnapshotOptions options in this function, and options.conns is now malloc'ed in the caller side, so we need to zfree it when returning early due to an error. Previously, conns was malloc'ed after the error handling, so we don't have this.  Introduced in #1949.  ---------  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/7a5c0d0ebf72354f122c64cd52788c671ae04064
valkey-io/valkey,https://github.com/valkey-io/valkey,390e0c9,yzc-yzc,2025-08-18T09:00:13Z,"CONFIG GET command return sorted output (#2493)  Previously, the config names and values were stored in a temporary dict. This ensures that no duplicates are returned, but it also makes the order random.  In this PR, the config names and values still stored in the temporary dict, but then they are copied to an array, which is sorted, before the reply is sent.  Resolves #2042  ---------  Signed-off-by: yzc-yzc <96833212+yzc-yzc@users.noreply.github.com>",https://github.com/valkey-io/valkey/commit/390e0c95551236c863da76fb0675f55b8b53cfcd
valkey-io/valkey,https://github.com/valkey-io/valkey,4a12021,Binbin,2025-08-18T04:18:32Z,Fix memory leak in rdbLoadObject when loading a wrong HFE (#2502)  There are memory leaks when we return NULL.  Signed-off-by: Binbin <binloveplay1314@qq.com>,https://github.com/valkey-io/valkey/commit/4a120217075c5ca4bacbeb13db6fdfe9df9e321e
valkey-io/valkey,https://github.com/valkey-io/valkey,410976d,Sarthak Aggarwal,2025-08-17T09:58:32Z,"Add test failure template to contributing guide (#2491)  We recently introduced a new template to create `test failures` issues from a template. This change makes this template visible in the `CONTRIBUTING.md` file. Also, added a tip to paste the stack trace since outputs of CI links can expire.  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>",https://github.com/valkey-io/valkey/commit/410976d509eb276cbdefd145257f83adafa9738f
valkey-io/valkey,https://github.com/valkey-io/valkey,e364c57,Ran Shidlansik,2025-08-17T09:53:41Z,simplify COPY Preserves TTLs hashexpire test (#2495)  Simplifies a test case seen to be flaky.  fixes: https://github.com/valkey-io/valkey/issues/2482  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/e364c57e3dd10c908aa98926c4a58148d1fe5bff
valkey-io/valkey,https://github.com/valkey-io/valkey,f36cc20,Hanxi Zhang,2025-08-15T18:40:34Z,Fix cluster test module to pass null terminated node-id to SendClusterMessage (#2484)  Fix https://github.com/valkey-io/valkey/issues/2438  Modified `DingReceiver` function in `tests/modules/cluster.c` by adding null-termination logic for cross-version compatibility  ---------  Signed-off-by: Hanxi Zhang <hanxizh@amazon.com>,https://github.com/valkey-io/valkey/commit/f36cc208368c4dd63f8e4a26f56d4ea1daf629f6
valkey-io/valkey,https://github.com/valkey-io/valkey,e7bb235,yzc-yzc,2025-08-15T18:37:15Z,"Don't call SSL_write() with num=0 (#2490)  https://github.com/valkey-io/valkey/blob/aefed3d363d1c7d7cb391d3f605484c78c9a88f2/src/networking.c#L2279-L2293 From above code, we can see that `c->repl_data->ref_block_pos` could be equal to `o->used`. When `o->used == o->size`, we may call SSL_write() with num=0 which does not comply with the openSSL specification. (ref: https://docs.openssl.org/master/man3/SSL_write/#warnings)  What's worse is that it's still the case after the reconnection. See https://github.com/valkey-io/valkey/blob/aefed3d363d1c7d7cb391d3f605484c78c9a88f2/src/replication.c#L756-L769. So in this case the replica will keep reconnecting again and again until it doesn't meet the requirements for partial synchronization.  Resolves #2119  ---------  Signed-off-by: yzc-yzc <96833212+yzc-yzc@users.noreply.github.com>",https://github.com/valkey-io/valkey/commit/e7bb2354da5c7c0b4f2135173ec00097178eec93
valkey-io/valkey,https://github.com/valkey-io/valkey,87d2330,Viktor Söderqvist,2025-08-15T18:28:14Z,Fix timeout in defrag tests (#2483)  * Use pipelines of length 1000 instead of up to 200000. * Use CLIENT REPLY OFF instead of reading and discarding the replies.  Fixes #2205  Signed-off-by: Viktor Söderqvist <viktor.soderqvist@est.tech>,https://github.com/valkey-io/valkey/commit/87d2330c222acf9efc181b98483af1566e213635
valkey-io/valkey,https://github.com/valkey-io/valkey,aefed3d,Binbin,2025-08-15T09:55:57Z,"Don't allow resize hashtable if rehashing is ongoing (#2465)  Similar to dicts, we disallow resizing while the hashtable is rehashing. In the previous code, if a resize was triggered during rehashing, like if the rehashing wasn't fast enough, we would do a while loop until the rehashing was complete, which could be a potential issue when doing resize.  ---------  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/aefed3d363d1c7d7cb391d3f605484c78c9a88f2
valkey-io/valkey,https://github.com/valkey-io/valkey,dcbaecd,Sarthak Aggarwal,2025-08-15T09:23:34Z,Ensures presence of slots on the node before test is run (#2486)  The change will ensure that the slot is present on the node before the slot is populated. This will avoid the errors during populating the slot.  Resolves #2480  ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/dcbaecddce5d56076189bcfb514eece917c1297e
valkey-io/valkey,https://github.com/valkey-io/valkey,de0e581,Sarthak Aggarwal,2025-08-15T02:47:38Z,Add bug / test-failure / enhancement label to issue template (#2273)  Automatically attach respective label to newly filled issues. ---------  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com> Signed-off-by: Sarthak Aggarwal <sarthakaggarwal97@gmail.com> Co-authored-by: Harkrishn Patro <bunty.hari@gmail.com>,https://github.com/valkey-io/valkey/commit/de0e581432089e554183b5753de3cabdad17dcf2
valkey-io/valkey,https://github.com/valkey-io/valkey,287fbcc,Sarthak Aggarwal,2025-08-14T22:20:13Z,Fixing Slot Migration Test Failure  (#2485)  Make sure slot migration has finished before moving on to the next test.  Resolves #2479  Signed-off-by: Sarthak Aggarwal <sarthagg@amazon.com>,https://github.com/valkey-io/valkey/commit/287fbcce335274a1a1f3d1908cbbe8e8200ba47e
valkey-io/valkey,https://github.com/valkey-io/valkey,0b4352c,Ping Xie,2025-08-14T20:15:52Z,"Consolidate slot migration logs by grouping consecutive slot migrations into a single log entry (#2481)  Previously, each slot migration was logged individually, which could lead to log spam in scenarios where many slots are migrated at once.  This commit enhances the logging mechanism to group consecutive slot migrations into a single log entry, improving log readability and reducing noise.  Log snippets  ``` 1661951:S 13 Aug 2025 15:47:10.132 * Slot range [16383, 16383] is migrated from node c3926da75f7c3a0a1bcd07e088b0bde09d48024c () in shard 7746b693330c0814178b90b757e2711ebb8c6609 to node 2465c29c8afb9231525e281e5825684d0bb79f7b () in shard 39342c039d2a6c7ef0ff96314b230dfd7737d646. 1661951:S 13 Aug 2025 15:47:10.289 * Slot range [10924, 16383] is migrated from node 2465c29c8afb9231525e281e5825684d0bb79f7b () in shard 39342c039d2a6c7ef0ff96314b230dfd7737d646 to node c3926da75f7c3a0a1bcd07e088b0bde09d48024c () in shard 7746b693330c0814178b90b757e2711ebb8c6609. 1661951:S 13 Aug 2025 15:47:10.524 * Slot range [10924, 16383] is migrated from node c3926da75f7c3a0a1bcd07e088b0bde09d48024c () in shard 7746b693330c0814178b90b757e2711ebb8c6609 to node 2465c29c8afb9231525e281e5825684d0bb79f7b () in shard 39342c039d2a6c7ef0ff96314b230dfd7737d646. ```  ---------  Signed-off-by: Ping Xie <pingxie@google.com>",https://github.com/valkey-io/valkey/commit/0b4352c98ccefac61e33c5da805357e909bf6d2f
valkey-io/valkey,https://github.com/valkey-io/valkey,3d1ff2a,Binbin,2025-08-13T09:01:00Z,"Remove if condition and disable the new failover test (#2477)  In #2431 we changed the assert to a if condition, and the test cause some trouble, now we just remove the assert (if condition) and disable the test for now due to #2441.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/3d1ff2a38c3a17644afa4b64f086ea110df5fa86
valkey-io/valkey,https://github.com/valkey-io/valkey,1535512,Ran Shidlansik,2025-08-13T07:22:44Z,"HSETEX 'hset' notification should only be generated if not expired (#2475)  Currently HSETEX always generate `hset` notification. In order to align with generic `set` command, it should only generate `hset` if the provided time-to-live is a valid future time.  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>",https://github.com/valkey-io/valkey/commit/15355124d42b0b82ca85adbf887b42a4a21b49b6
valkey-io/valkey,https://github.com/valkey-io/valkey,c93b297,Ran Shidlansik,2025-08-13T06:37:54Z,Increment expired_fields stat when assigned TTL is in the past (#2474)  fixes: https://github.com/valkey-io/valkey/issues/2461  ---------  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/c93b2971e6780a8f4c427752b9be1443a0f52d6a
valkey-io/valkey,https://github.com/valkey-io/valkey,58f5562,ruihong123,2025-08-13T06:28:44Z,"Fix duplicate Acks for RDMA events and fix extremely large max latency for RDMA benchmark. (#2430)  (1) The old logic may result in the RDMA event being acknowledged unexpectly in the following two scenarios. * ibv_get_cq_event get an EAGAIN error.  * ibv_get_cq_event get one event but it may ack multiple times in the pollcq loop.  (2) In the benchmark result of valkey over RDMA, the tail latency is as high as 177 milliseconds(almost 80x of TCP). This results from incorrect benchmark client setup which includes the connection setup time into the benchmark latency recording. This patch fixes this crazy tail latency issue by modifying the valkey-benchmark.c. This change only affects benchmark over RDMA as updates are regulated under Macro USE_RDMA.  There are following updates on valkey RDMA but I am willing to create separated pull requests.  ---------  Signed-off-by: Ruihong Wang <ruihong@google.com>",https://github.com/valkey-io/valkey/commit/58f5562d221d74ab85624a11ac330d9c5f69ae78
valkey-io/valkey,https://github.com/valkey-io/valkey,6c2e4f9,Ran Shidlansik,2025-08-12T10:32:19Z,Deflake hashexpire tests (#2473)  1. Better separation of test steps in `Chain Replication (Primary -> R1 -> R2) preserves TTL` This can help prevent or provide better understanding of a flakey fail: https://github.com/valkey-io/valkey/actions/runs/16867976482/job/47777607814  2. increase the millisecond short timeout to 1 second since some tests are failing because of it. It also better matches the second timeout. example fail: https://github.com/valkey-io/valkey/actions/runs/16867976482/job/47777607746  Signed-off-by: Ran Shidlansik <ranshid@amazon.com>,https://github.com/valkey-io/valkey/commit/6c2e4f955310f956b25696fd9d008ea0e13d980e
valkey-io/valkey,https://github.com/valkey-io/valkey,7a9ef29,Binbin,2025-08-12T02:37:11Z,"Change the same shard failover assert to if condition to avoid crash (#2431)  The assert was added in #2301 and we found that there are some situations would trigger assert and crash the server.  The reason we added the assert is because, in the code: 1. sender_claimed_primary and sender are in the same shard 2. and sender is the old primary, sender_claimed_primary is the old replica 3. and now sender become a replica, sender_claimed_primary become a primary  That means a failover happend in the shard, and sender should be the primary of sender_claimed_primary. But obviously this assumption may be wrong, we rely on shard_id to determine whether it is in a same shard, and assume that a shard can only have one primary.  But this is wrong, from #2279 we can know there will be a case that we can create two primaries in the same shard due to the untimely update of shard_id. So we can create a test that trigger the assert in this way: 1. pre condition: two primaries in the same shard, one has slots and one is empty. 2. replica doing a cluster failover 3. the empty primary doing a cluster replicate with the replica (new primary)  We change the assert to an if condition to fix it.  Closes #2423.  Note that the test written here also exposes the issue in #2441, so these two may need to be addressed together.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/7a9ef29f1ae6baa571a1ca30e68eed1fa0304fa2
valkey-io/valkey,https://github.com/valkey-io/valkey,8131c2b,Binbin,2025-08-12T02:21:06Z,"Add test for failover sub-replica replication loop case (#2456)  When we added the safeguard against sub-replicas logic, we didn't add much tests for it. As time has shown, it can happen in different scenarios. Here's a test case that used to happen in a failover scenario.  Signed-off-by: Binbin <binloveplay1314@qq.com>",https://github.com/valkey-io/valkey/commit/8131c2b07bcff0dd62c79f8495e45563eacadec1
valkey-io/valkey,https://github.com/valkey-io/valkey,d7993b7,Jacob Murphy,2025-08-12T01:02:37Z,"Introduce atomic slot migration (#1949)  Introduces a new family of commands for migrating slots via replication. The procedure is driven by the source node which pushes an AOF formatted snapshot of the slots to the target, followed by a replication stream of changes on that slot (a la manual failover).  This solution is an adaptation of the solution provided by @enjoy-binbin, combined with the solution I previously posted at #1591, modified to meet the designs we had outlined in #23.  ## New commands  * `CLUSTER MIGRATESLOTS SLOTSRANGE start end [start end]... NODE node-id`: Begin sending the slot via replication to the target. Multiple targets can be specified by repeating `SLOTSRANGE ... NODE ...` *  `CLUSTER CANCELMIGRATION ALL`: Cancel all slot migrations * `CLUSTER GETSLOTMIGRATIONS`: See a recent log of migrations  This PR only implements ""one shot"" semantics with an asynchronous model. Later, ""two phase"" (e.g. slot level replicate/failover commands) can be added with the same core.  ## Slot migration jobs  Introduces the concept of a slot migration job. While active, a job tracks a connection created by the source to the target over which the contents of the slots are sent. This connection is used for control messages as well as replicated slot data. Each job is given a 40 character random name to help uniquely identify it.  All jobs, including those that finished recently, can be observed using the `CLUSTER GETSLOTMIGRATIONS` command.  ## Replication  * Since the snapshot uses AOF, the snapshot can be replayed verbatim to any replicas of the target node. * We use the same proxying mechanism used for chaining replication to copy the content sent by the source node directly to the replica nodes.  ## `CLUSTER SYNCSLOTS`  To coordinate the state machine transitions across the two nodes, a new command is added, `CLUSTER SYNCSLOTS`, that performs this control flow.  Each end of the slot migration connection is expected to install a read handler in order to handle `CLUSTER SYNCSLOTS` commands:  * `ESTABLISH`: Begins a slot migration. Provides slot migration information to the target and authorizes the connection to write to unowned slots. * `SNAPSHOT-EOF`: appended to the end of the snapshot to signal that the snapshot is done being written to the target. * `PAUSE`: informs the source node to pause whenever it gets the opportunity * `PAUSED`: added to the end of the client output buffer when the pause is performed. The pause is only performed after the buffer shrinks below a configurable size * `REQUEST-FAILOVER`: request the source to either grant or deny a failover for the slot migration. The grant is only granted if the target is still paused. Once a failover is granted, the paused is refreshed for a short duration * `FAILOVER-GRANTED`: sent to the target to inform that REQUEST-FAILOVER is granted * `ACK`: heartbeat command used to ensure liveness  ## Interactions with other commands  * FLUSHDB on the source node (which flushes the migrating slot) will result in the source dropping the connection, which will flush the slot on the target and reset the state machine back to the beginning. The subsequent retry should very quickly succeed (it is now empty) * FLUSHDB on the target will fail the slot migration. We can iterate with better handling, but for now it is expected that the operator would retry. * Genearlly, FLUSHDB is expected to be executed cluster wide, so preserving partially migrated slots doesn't make much sense * SCAN and KEYS are filtered to avoid exposing importing slot data  ## Error handling  * For any transient connection drops, the migration will be failed and require the user to retry. * If there is an OOM while reading from the import connection, we will fail the import, which will drop the importing slot data * If there is a client output buffer limit reached on the source node, it will drop the connection, which will cause the migration to fail * If at any point the export loses ownership or either node is failed over, a callback will be triggered on both ends of the migration to fail the import. The import will not reattempt with a new owner * The two ends of the migration are routinely pinging each other with SYNCSLOTS ACK messages. If at any point there is no interaction on the connection for longer than `repl-timeout`, the connection will be dropped, resulting in migration failure * If a failover happens, we will drop keys in all unowned slots. The migration does not persist through failovers and would need to be retried on the new source/target.  ## State machine  ```                                                                                              Target/Importing Node State Machine                             ─────────────────────────────────────────────────────────────                                                                                                       ┌────────────────────┐              │SLOT_IMPORT_WAIT_ACK┼──────┐              └──────────┬─────────┘      │                      ACK│                │          ┌──────────────▼─────────────┐  │          │SLOT_IMPORT_RECEIVE_SNAPSHOT┼──┤          └──────────────┬─────────────┘  │             SNAPSHOT-EOF│                │                                           ┌───────────────▼──────────────┐ │                                           │SLOT_IMPORT_WAITING_FOR_PAUSED┼─┤                                           └───────────────┬──────────────┘ │                                                     PAUSED│                │                                           ┌───────────────▼──────────────┐ │ Error Conditions:                         │SLOT_IMPORT_FAILOVER_REQUESTED┼─┤  1. OOM                                   └───────────────┬──────────────┘ │  2. Slot Ownership Change                 FAILOVER-GRANTED│                │  3. Demotion to replica                    ┌──────────────▼─────────────┐  │  4. FLUSHDB                                │SLOT_IMPORT_FAILOVER_GRANTED┼──┤  5. Connection Lost                        └──────────────┬─────────────┘  │  6. No ACK from source (timeout)        Takeover Performed│                │                                            ┌──────────────▼───────────┐    │                                            │SLOT_MIGRATION_JOB_SUCCESS┼────┤                                            └──────────────────────────┘    │                                                                            │                                      ┌─────────────────────────────────────▼─┐                                    │SLOT_IMPORT_FINISHED_WAITING_TO_CLEANUP│                                    └────────────────────┬──────────────────┘                                 Unowned Slots Cleaned Up│                                                              ┌─────────────▼───────────┐                                                 │SLOT_MIGRATION_JOB_FAILED│                                                 └─────────────────────────┘                                                                                                                                                                                                                                                      Source/Exporting Node State Machine                                            ─────────────────────────────────────────────────────────────                                                                                                                                 ┌──────────────────────┐                                                                    │SLOT_EXPORT_CONNECTING├─────────┐                                                          └───────────┬──────────┘         │                                                             Connected│                    │                                                        ┌─────────────▼────────────┐       │                                                        │SLOT_EXPORT_AUTHENTICATING┼───────┤                                                        └─────────────┬────────────┘       │                                                         Authenticated│                    │                                                        ┌─────────────▼────────────┐       │                                                        │SLOT_EXPORT_SEND_ESTABLISH┼───────┤                                                        └─────────────┬────────────┘       │                                             ESTABLISH command written│                    │                                                ┌─────────────────────▼─────────────┐      │                                                │SLOT_EXPORT_READ_ESTABLISH_RESPONSE┼──────┤                                                └─────────────────────┬─────────────┘      │                                              Full response read (+OK)│                    │                                                     ┌────────────────▼──────────────┐     │ Error Conditions:                                   │SLOT_EXPORT_WAITING_TO_SNAPSHOT┼─────┤  1. User sends CANCELMIGRATION                      └────────────────┬──────────────┘     │  2. Slot ownership change                      No other child process│                    │  3. Demotion to replica                                 ┌────────────▼───────────┐        │  4. FLUSHDB                                             │SLOT_EXPORT_SNAPSHOTTING┼────────┤  5. Connection Lost                                     └────────────┬───────────┘        │  6. AUTH failed                                         Snapshot done│                    │  7. ERR from ESTABLISH command                           ┌───────────▼─────────┐          │  8. Unpaused before failover completed                   │SLOT_EXPORT_STREAMING┼──────────┤  9. Snapshot failed (e.g. Child OOM)                     └───────────┬─────────┘          │  10. No ack from target (timeout)                               PAUSE│                    │  11. Client output buffer overrun                     ┌──────────────▼─────────────┐      │                                                       │SLOT_EXPORT_WAITING_TO_PAUSE┼──────┤                                                       └──────────────┬─────────────┘      │                                                        Buffer drained│                    │                                                       ┌──────────────▼────────────┐       │                                                       │SLOT_EXPORT_FAILOVER_PAUSED┼───────┤                                                       └──────────────┬────────────┘       │                                              Failover request granted│                    │                                                      ┌───────────────▼────────────┐       │                                                      │SLOT_EXPORT_FAILOVER_GRANTED┼───────┤                                                      └───────────────┬────────────┘       │                                                 New topology received│                    │                                                       ┌──────────────▼───────────┐        │                                                       │SLOT_MIGRATION_JOB_SUCCESS│        │                                                       └──────────────────────────┘        │                                                                                           │                                                       ┌─────────────────────────┐         │                                                       │SLOT_MIGRATION_JOB_FAILED│◄────────┤                                                       └─────────────────────────┘         │                                                                                           │                                                      ┌────────────────────────────┐       │                                                      │SLOT_MIGRATION_JOB_CANCELLED│◄──────┘                                                      └────────────────────────────┘                                                  ```  Co-authored-by: Binbin <binloveplay1314@qq.com>  ---------  Signed-off-by: Binbin <binloveplay1314@qq.com> Signed-off-by: Jacob Murphy <jkmurphy@google.com> Signed-off-by: Madelyn Olson <madelyneolson@gmail.com> Co-authored-by: Binbin <binloveplay1314@qq.com> Co-authored-by: Ping Xie <pingxie@outlook.com> Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>",https://github.com/valkey-io/valkey/commit/d7993b78d82d9c9d2f9298159acd8f5a2fc997d4
