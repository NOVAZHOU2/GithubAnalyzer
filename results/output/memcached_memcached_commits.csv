项目名称,项目URL,提交ID,提交者,提交时间,提交信息,提交链接
memcached/memcached,https://github.com/memcached/memcached,62b3447,dormando,2025-07-29T01:02:35Z,tests: improve extstore-tiered2 reliability  Test would fail to move items to the OLD compaction bucket reliably on slow systems (rpi 3 32bit)  Think I have a real bug in the LRU balancer... somehow too much data is ending up in the COLD LRU and that's causing items to not move to OLD. Could also be a race with the LRU maintainer... would be nice to be able to pause that for tests.,https://github.com/memcached/memcached/commit/62b3447380d3fd547e432d1128d94cd12f2e6852
memcached/memcached,https://github.com/memcached/memcached,dcdae52,dormando,2025-07-25T05:04:21Z,proxy: very limited flagcopyall function  can only handle responses as source and no flag exemptions. just copies result line.,https://github.com/memcached/memcached/commit/dcdae52f9d138685e88f6e97af9e9e130d529c59
memcached/memcached,https://github.com/memcached/memcached,da93938,dormando,2025-07-25T00:32:08Z,proxy: flagcopy removes flag if source is nil,https://github.com/memcached/memcached/commit/da93938350fffc6d8dba1b0e3c420946d994b00b
memcached/memcached,https://github.com/memcached/memcached,37c9467,Tianon Gravi,2025-07-23T19:48:53Z,Fix typecast on setting stop_time during restart,https://github.com/memcached/memcached/commit/37c94672231c471de2d75ff73f46ec9e72f15f44
memcached/memcached,https://github.com/memcached/memcached,b37f6e5,dormando,2025-07-18T21:08:30Z,tests: make slabs-mover test more resilient  ... to slow machines.,https://github.com/memcached/memcached/commit/b37f6e517259ec609f73a3df96224e5ab88eb30c
memcached/memcached,https://github.com/memcached/memcached,bb01954,dormando,2025-07-18T20:39:34Z,"tests: fix low TTL test on slow systems  Was giving 20 seconds of TTL for a ""low TTL item test"" - the test was to ensure that the TEMP_LRU gets recovered properly on restart, not that an item of 20 seconds survives. So we can set that TTL to be much higher to cope with very slow ARM or emulated systems.",https://github.com/memcached/memcached/commit/bb019547f163aaed715df4f9e11c25879ac2d4bd
memcached/memcached,https://github.com/memcached/memcached,cff9e68,dormando,2025-07-15T23:54:07Z,mcmc: upstream updates,https://github.com/memcached/memcached/commit/cff9e685c638054eca586f6807a4e8a119ae431b
memcached/memcached,https://github.com/memcached/memcached,a9fdca2,dormando,2025-07-11T21:12:11Z,proxy: add test for corruption fault  confirmed asserts without the fix in previous commit.,https://github.com/memcached/memcached/commit/a9fdca2918dcd9deb7754921398251c91cc9198a
memcached/memcached,https://github.com/memcached/memcached,5267f14,dormando,2025-07-11T20:39:48Z,proxy: fix memory corruption from bad set uploads  Double-freeing of an rctx was possible if the data format from a set was corrupt (missing final \r\n),https://github.com/memcached/memcached/commit/5267f14c0b439206af856368ff8c951bdb4dffcb
memcached/memcached,https://github.com/memcached/memcached,28f4abf,dormando,2025-07-10T19:21:23Z,"core: fix pipelined set failures on pending reads  - IO objects are enqueued per-worker-thread since a refactor in ec1fb560 - If a set payload is being read off the network but the read gets   EAGAIN, _and_ there are already pending IO objects on the connection,   the worker thread will execute the pending IOs - The worker resume code did not check for conn_nread state and would   resume the connection's state machine if those IO's completed before   the conn_nread state completes. - The connection state is now corrupt and will both leak memory and   throw parsing errors.  This is a one-line fix to avoid resuming the state machine if we were in conn_nread state, as well as avoiding finalizing a connection from the conn_closing state if there are pending suspended responses.",https://github.com/memcached/memcached/commit/28f4abf8edc3ed652fad4c03767d8ee84e70015a
memcached/memcached,https://github.com/memcached/memcached,a5b3ce9,dormando,2025-07-03T18:16:40Z,mcmc: upstream updates  tokenizer optimizations.,https://github.com/memcached/memcached/commit/a5b3ce99806724320b3e81770037dc543ed32806
memcached/memcached,https://github.com/memcached/memcached,750a7d1,dormando,2025-06-25T22:59:33Z,proxy: more inspector tests  nothing was explicitly testing missing flags.,https://github.com/memcached/memcached/commit/750a7d1e6d2ba1ffc992efdc95285900f8bb83c4
memcached/memcached,https://github.com/memcached/memcached,4c5b1e9,dormando,2025-05-23T01:32:51Z,"proxy: fix subrctx issues during error handling  If subrctx hits a fatal error inbetween enqueueing subrctxs but before dispatching requests, the parent rctx will attempt to run the cleanup routines and hit a debug assert since the final pending_reqs never decremented.  If the tree runs again and does _not_ hit the same fatal error it would not return to the cache properly since pending_reqs would never hit 0 on the leaf nodes.  In reality if lua's throwing fatals you've probably goofed the code and it will never work again, so impact is minimal.",https://github.com/memcached/memcached/commit/4c5b1e99b62de642b777baf0ec9e7c6bfde129ee
memcached/memcached,https://github.com/memcached/memcached,c25ddfe,dormando,2025-05-19T22:42:59Z,"proxy: repair proxy_req_active counter  much to my surprise: no actual unit tests checking that proxy_req_active works! Dammit!  Missed the spot in the stat aggregator, so the previous update worked internally but always printed zero in stats output.",https://github.com/memcached/memcached/commit/c25ddfe3a6007d3595be6850d8596c35de170224
memcached/memcached,https://github.com/memcached/memcached,f47aa28,dormando,2025-05-17T00:38:40Z,tls: minor fix when tls disabled  forgot to check before committing..,https://github.com/memcached/memcached/commit/f47aa28c4a0578a45309efd76568c7efec136dde
memcached/memcached,https://github.com/memcached/memcached,53163d9,dormando,2025-05-17T00:26:08Z,"proxy: improvements for proxy_req_active  Improves test coverage for returning request contexts. Changes proxy_req_active from unsigned to signed int, so accidental overdecrements won't trigger the request limit.",https://github.com/memcached/memcached/commit/53163d9259e65bd79df27cc37b19510b659f546d
memcached/memcached,https://github.com/memcached/memcached,96e05b7,dormando,2025-05-16T18:47:57Z,"tls: fix potential hang when pipelining sets  If TLS is in use and sets are being pipelined together, it's possible for OpenSSL to read the next command into pending BIO data while we're reading the payload of a prior set. We then go to sleep expecting epoll to wake us up if data is still available on the socket.  We now check for SSL_pending bytes before stopping the state machine loop.  This _may_ not be the only fix required for this state but it will be the most common one.",https://github.com/memcached/memcached/commit/96e05b75f0e095e0a603ac64422976ef1e0c9363
memcached/memcached,https://github.com/memcached/memcached,94026ef,dormando,2025-04-02T03:15:47Z,proxy: fix idiot bug  dormando is stupid. how did this work when I tested it?,https://github.com/memcached/memcached/commit/94026ef1c309386ccdbcecd24621eb573fafec73
memcached/memcached,https://github.com/memcached/memcached,3047889,dormando,2025-04-01T23:18:10Z,proxy: missing OR for error flag,https://github.com/memcached/memcached/commit/3047889f983617fb7a7aa6da01998120ffe0e55b
memcached/memcached,https://github.com/memcached/memcached,e895b82,dormando,2025-03-31T23:01:29Z,proxy: fix double logging with subrctx's,https://github.com/memcached/memcached/commit/e895b8262451f04f151b39500c6ab66e5544d46b
memcached/memcached,https://github.com/memcached/memcached,a2e47b5,dormando,2025-03-29T01:14:21Z,"tests: attempt to make extstore tests less flaky  on very slow systems we may not wait long enough for background threads to run, and may end up waiting a long time for them to wake up. So we changed the item_age from 2 seconds to 0 seconds in hopes of preventing the bg thread from sleeping. We also watch the sysevents log to ensure the compaction thread is idle for a while after we expect it to run.",https://github.com/memcached/memcached/commit/a2e47b5afdf6ad7deeb54ce9fb1d45cf8cfd1024
memcached/memcached,https://github.com/memcached/memcached,9f9d286,dormando,2025-03-27T21:59:02Z,crawler: fix issue with strict alignment (ARM)  introduced in c46431105 - copying wrong amount of bytes.,https://github.com/memcached/memcached/commit/9f9d286d3128fa666d486c303ce62c63b008b642
memcached/memcached,https://github.com/memcached/memcached,1a0a0b2,Tianon Gravi,2025-03-25T00:00:10Z,"proxy: fix `time_*_millis` overflow on 32bit sys  This fixes a time overflow by casting `tv_sec` to `lua_Integer` (which is `long long` unless explicitly configured otherwise) before multiplying it by 1000, which ensures the result doesn't become negative before being assigned to a `lua_Integer` value and returned.  Concretely, this fixes the test failure in `t/proxyunits.t` on systems that have not yet transitioned to `time64_t` (notably, Debian 12 / Bookworm; that transition should be part of 13 / Trixie, which will likely be released later this year).",https://github.com/memcached/memcached/commit/1a0a0b2591176a7c82412e27f3e17ba9133cd8dd
memcached/memcached,https://github.com/memcached/memcached,c464311,dormando,2025-03-24T19:56:42Z,crawler: speedup and extstore info  Unrolls the sprintf used for `lru_crawler metadump` since it is a hot path. Increases dump speed with no crawler sleep by 30%.  Also adds the disk page and disk page offset via `ext_page` and `ext_offset` if the item is on disk.  Credit to @hemal-shah for the idea on dumping extstore information.,https://github.com/memcached/memcached/commit/c464311059b54bbd92f07550f1eb3a1eb49dae68
memcached/memcached,https://github.com/memcached/memcached,efac473,dormando,2025-03-20T02:41:09Z,mcmc: upstream updates,https://github.com/memcached/memcached/commit/efac473013a9bc967b6fec22a73c7027a926c0ab
memcached/memcached,https://github.com/memcached/memcached,db6cc06,dormando,2025-03-19T21:49:00Z,docs: clean up README more,https://github.com/memcached/memcached/commit/db6cc06efcd77ca6c74f568507159066d2104349
memcached/memcached,https://github.com/memcached/memcached,7c8b7f2,dormando,2025-03-19T21:44:46Z,proxy: extra test for subrctx code  ensuring FASTGOOD isn't returning early on errors from subrctx.,https://github.com/memcached/memcached/commit/7c8b7f23507762343ceac2099f27c239aae99224
memcached/memcached,https://github.com/memcached/memcached,7ae9de6,dormando,2025-03-19T17:09:16Z,"proxy: wait for all possible responses on errors  previous commit ""fixed"" a situation where it waits for all responses in impossible situations, but this breaks FASTGOOD specifically.  I may add the early resume code back to non-FASTGOOD cases but that requires a test suite audit first.",https://github.com/memcached/memcached/commit/7ae9de68fa74db0ceec84fac31f29db5c7d9b09a
memcached/memcached,https://github.com/memcached/memcached,2ae1b4e,jinyaoguo,2025-03-18T23:06:08Z,Release memory in function restart_get_kv,https://github.com/memcached/memcached/commit/2ae1b4ee7e40ec10b78ddada391c20c5a86e30e8
memcached/memcached,https://github.com/memcached/memcached,f9fc4e4,jinyaoguo,2025-03-18T22:31:47Z,Release memory in function _evict_page,https://github.com/memcached/memcached/commit/f9fc4e4e6d44bbeca39531c5e1781e3cfc608ecc
memcached/memcached,https://github.com/memcached/memcached,a3f9fed,Kanak Kshetri,2025-03-07T17:48:50Z,assoc.c: fix leak in assoc_get_iterator  when trylock fails,https://github.com/memcached/memcached/commit/a3f9fedd11d29d53f789456d14f17292490d666c
memcached/memcached,https://github.com/memcached/memcached,91de5e8,mugitya03,2025-02-26T17:34:29Z,Free `subopts_orig` in function main  The memory allocated at line 5179 is not freed when function exits.,https://github.com/memcached/memcached/commit/91de5e8e55303ae410c4b35cd188b22ed75c5478
memcached/memcached,https://github.com/memcached/memcached,e505574,mugitya03,2025-02-26T17:15:58Z,Free `temp_portnumber_filename` before exits  A memory is allocated and stored in pointer `temp_portnumber_filename`  temp_portnumber_filename = malloc(len);  It is not freed when the function exits at exception branches.,https://github.com/memcached/memcached/commit/e5055740aebd04492f02179b0e8f3bbccd7d71bb
memcached/memcached,https://github.com/memcached/memcached,6fb5ef7,dormando,2025-03-19T00:27:32Z,proxy: flag error res objects properly  pertains to fix in previous commit.  also improves `rctx:worst_result` since the flags are increasingly-worse numerically.,https://github.com/memcached/memcached/commit/6fb5ef76014a32f9e13ad54f4ea10c87614252fa
memcached/memcached,https://github.com/memcached/memcached,d0341eb,dormando,2025-03-18T22:19:52Z,"proxy: fix wait_cond with subrctx errors  If a subrctx completes a response to the parent but still has an executing child (ie; async request or wait timeout), the pending_reqs counter would not decrement on the parent rctx and a wait_cond will either delay or never complete when there are not potential responses to wait for.",https://github.com/memcached/memcached/commit/d0341eb159d6c5a409d4908626a3029fa0d68ba4
memcached/memcached,https://github.com/memcached/memcached,1396d75,dormando,2025-03-18T00:58:43Z,docs: move build instructions to README.md,https://github.com/memcached/memcached/commit/1396d755a3db863d16a2b917ddc21693439ab703
memcached/memcached,https://github.com/memcached/memcached,8280485,dormando,2025-03-18T00:48:11Z,"proxy: rctx:best_result fix for missed responses  best_result would return an initialized but not filled response object if the underlying handler had either not been dispatched or did not respond yet.  now returns nil, nil properly if all responses are missing.",https://github.com/memcached/memcached/commit/8280485d2b93432d9dd532ef7b2147d09ae5488c
memcached/memcached,https://github.com/memcached/memcached,dfe439d,dormando,2025-03-04T00:43:42Z,proxy: add tests for best/worst result API  Feels like I'm missing a deeper test case but can't come up with it right now.,https://github.com/memcached/memcached/commit/dfe439d4cba3748bad5b0c8adaf1b7fb0c98ea40
memcached/memcached,https://github.com/memcached/memcached,ffe8d03,dormando,2025-03-03T20:33:31Z,"extstore: multiple tunings for small values  small items are roughly 500 bytes or less.  if we are flushing small items to disk, we allocate a relatively large amount of memory from the page pool to make headers to swap them out. IE: we may only gain 30-50% overall memory improvement after flushing.  This commit improves a few scenarios: - clamps the amount of memory the storage flush thread will try to   reclaim from small slab classes. The flush thread gets more aggressive   based on how far below the ""global pool minimum"" it currently is. - begin flushing items when memory is _at_ the global pool minimum but   not below it, freeing at most one megabyte of memory per class. This   reduces calls to the page mover if we can flush memory without   allocating more pages. - fix for the page mover being unable to move pages quickly if a slab   class is completely empty, but has pages available to move. - improve the responsiveness of the page mover by sleeping at most 100ms   if it recently moved pages, falling back to the one-second sleep if   it hasn't moved anything for a full second.  For the latter fix, I observed under benchmarks the page mover was flooding moves and then sleeping for a full second, causing large oscillations.",https://github.com/memcached/memcached/commit/ffe8d03d64981861f74ee00ae4d19096b49accb6
memcached/memcached,https://github.com/memcached/memcached,d918990,dormando,2025-02-26T23:21:23Z,"slabs: wait before adjusting memory watermark  If running extstore and the ""global page pool minimum free ratio"" setting is live-tuned, we immediately change the minimum memory target but cannot move memory pages until one full ""time window"" has passed. By default this time window is 10s (as of this commit).  This means if extstore values are very small, and the ratio change is relatively large, we can bottom out all memory before deciding to move free memory from high slab classes to low slab classes.",https://github.com/memcached/memcached/commit/d918990f861756216da4ba5eba2819331c311b07
memcached/memcached,https://github.com/memcached/memcached,0e6ba4d,dormando,2025-02-20T20:44:19Z,"proto: -X disables `stats detail` as well  Since it's possible to gather information about unrelated keys via `stats detail dump`, it should be included in the --disable-dump list.  Credit to Wallarm / https://www.wallarm.com/ for pointing this out.  Since there is _no multitenancy guarantee_ in memcached disabling of dumps is just for layered protection. Commits to disable the other dump commands were treated as new features and not security vulnerabilities in the past... so we will continue to do so.  Out of an abundance of caution we're putting out a notice about this regardless.",https://github.com/memcached/memcached/commit/0e6ba4da1fcaa3bf93f588d6d1144c9ecb231f9e
memcached/memcached,https://github.com/memcached/memcached,3d8bda4,dormando,2025-02-19T00:44:18Z,mcmc: upstream updates,https://github.com/memcached/memcached/commit/3d8bda41139f63399fd4898d67ea6e0ed5c9b6c0
memcached/memcached,https://github.com/memcached/memcached,bb964f4,dormando,2025-02-10T21:15:52Z,proxy: build mcmc directly  ... so we get all the fancy compiler options for it.,https://github.com/memcached/memcached/commit/bb964f4f583e402f6df1f561c20a0e3f28f4baef
memcached/memcached,https://github.com/memcached/memcached,1b981b0,dormando,2025-02-05T00:10:49Z,proxy: antiflap tests are flappy. sigh.  I know it works so not concerned about temporarily disabling them.,https://github.com/memcached/memcached/commit/1b981b040d51d3cedb7e4a001ab642c46a685271
memcached/memcached,https://github.com/memcached/memcached,d315f07,dormando,2025-02-04T22:43:19Z,"proxy: fix mcp.internal memory corruption  - Fetches from extstore malloc a temporary buffer to hold the item data - The ownership of this buffer passes from an IO object to a proxy   response object - The ownership is then _supposed_ to transfer to the frontend response   object (mc_resp), but it was not. - This means when the proxy response object gets ""cleaned up"", we free   that buffer. - Which can then get malloced by some other part of the code, and then   corrupted, before the result is transmitted to the client.  There are currently two modes for using mcp.internal: V1 API ""direct calls"" and V2 style where internal is a magic pool object.  The V2 API is affected worse than the V1 API. In the V2 API we more quickly clean up response objects. While the V1 API needs to wait for the next GC run, which is going to mostly be delayed longer than it takes to send a response back to the client.  It's still possible to corrupt memory in V1 just far less likely: a client would have to have its receive buffer full longer than the next GC run takes to process.",https://github.com/memcached/memcached/commit/d315f074a6e1bfac1f775d6aa3d466f19568b3ed
memcached/memcached,https://github.com/memcached/memcached,e433644,dormando,2025-02-02T01:56:34Z,vendor: bump vendor sha,https://github.com/memcached/memcached/commit/e43364402195c8e822bb8f88755a60ab8bbed62a
memcached/memcached,https://github.com/memcached/memcached,5d17f8f,Peter (Stig) Edwards,2025-01-15T13:33:04Z,"docs: update -I in manpage  Remove ""Override the size of each slab page"" from the man page for the -I, --max-item-size option  https://github.com/memcached/memcached/issues/1196  I think since version 1.4.29 , released on 2016 July 13th, pages are fixed at 1mb in size and the maximum slab chunk size is no longer tied to the maximum item size.  ""Override the size of each slab page"" was removed from the --help in https://github.com/memcached/memcached/commit/3f3e1379368753e540a332f90f996a3eb7ab8e9e",https://github.com/memcached/memcached/commit/5d17f8f4bb068a0bdd4809e80e3ed5d378ef2fad
memcached/memcached,https://github.com/memcached/memcached,0c5733b,dormando,2025-01-30T05:36:31Z,core: link to proxy docs from help,https://github.com/memcached/memcached/commit/0c5733bd8529849925b269d54acec9bd745e3d34
memcached/memcached,https://github.com/memcached/memcached,d5bff03,dormando,2025-01-30T05:05:08Z,core: improve msg when starting as root without -u  explain how to use the command instead of saying something semi-cryptic.,https://github.com/memcached/memcached/commit/d5bff0314d432fd4738b17e83f1f284fec1cdc9e
memcached/memcached,https://github.com/memcached/memcached,650a42b,dormando,2025-01-30T04:49:21Z,"proxy: null mutator, best_result, log fix  mix of small changes: - a mutator step to create a ""null"" result, meaning miss, not stored, or   not found depending on the command. - rctx:best_result and rctx:worst_result (untested) to simplify/speedup   a common lua pattern. - if logging specified but no conditions, assume rate of 1.",https://github.com/memcached/memcached/commit/650a42bc884038159265debdb88cabf1c97a4ff4
memcached/memcached,https://github.com/memcached/memcached,fc354ee,dormando,2025-01-27T21:49:29Z,"core: tweak batch IO submission  reset the counter during each submission, to ensure we can batch up to N clients for each epoll loop.",https://github.com/memcached/memcached/commit/fc354ee58a748f78affcaf0c427e2f68b3fb50d8
memcached/memcached,https://github.com/memcached/memcached,4a04d84,dormando,2025-01-22T00:09:33Z,"core: allow batch submission to IO subsystem  If the event loop has many clients to work on, allow processing multiple clients before submitting IO queues to the backend systems.  This is a massive reduction in syscalls when there are few backend sockets. A test with many active clients went from p50 of 700us to p50 of 100us, both with p99 of 1ms. 500k rps on a 16 core 7950x.  Bounding the batch submission size with a magic value (20) while I learn more about what workloads this does and doesn't work for. This may be less great for extstore than the proxy, so need to be conservative for now. For the proxy any amount of batching is a win, but too much batching creates a longer tail latency (p99.9 though, p99 seems unchanged).",https://github.com/memcached/memcached/commit/4a04d84691917247cf676b5746197e4aa6b6c46d
memcached/memcached,https://github.com/memcached/memcached,c0f01ef,dormando,2025-01-21T23:43:19Z,proto: allow bare 'get' cmd to autobatch  Since the meta protocol was introduced we will keep parsing requests that were already read off of the network until we hit the end of the buffer or need to yield to other connections.  This was true for every command except bare 'get'. This is now fixed.,https://github.com/memcached/memcached/commit/c0f01efa3a87aca4ee7789c00a665e8ab6a12f3f
memcached/memcached,https://github.com/memcached/memcached,3365189,dormando,2025-01-16T02:46:20Z,"proxy: per-backend automatic logging  Options similar to mcp.log_reqsample() are applied to responses as they're read off the network.  Can be a lot faster than relying on callbacks to do logging, if you're not doing logging inline with a route handler. Also simpler in some cases (ie routelib).",https://github.com/memcached/memcached/commit/336518952ffc1047f5c9d524202dfc8e871f5858
memcached/memcached,https://github.com/memcached/memcached,5fe01d0,dormando,2025-01-18T04:04:25Z,"proxy: speed up coro recycling  Coroutines grow/shrink their stacks on every request which causes some malloc/freeing (but not GC work). This avoids that which helps CPU a bit, mostly noticable with pipelined work.",https://github.com/memcached/memcached/commit/5fe01d0c191e1af64223d3f430b8648ac115d16e
memcached/memcached,https://github.com/memcached/memcached,33cf4cc,dormando,2024-12-27T05:54:13Z,"proxy: internal backend for V2 API  Replaces `res = mcp.internal(req)` with the standard V2 API flow. Create a handle for an fgen using `mcp.internal_handler` as an argument, then call wait against it like a normal pool.",https://github.com/memcached/memcached/commit/33cf4ccd324f838f1199b9e2b69b7c299ffff3cf
memcached/memcached,https://github.com/memcached/memcached,83425f3,dormando,2025-01-14T20:03:10Z,"proxy: speed up per-worker backend IO  Uses a shorter return path for completed IO objects, resulting in 5%+ performance bump.  Also cleans up some of the remaining hack code from before the IO subsystem fix.",https://github.com/memcached/memcached/commit/83425f30ef505dcbd2e646bbb09276cec5a2999e
memcached/memcached,https://github.com/memcached/memcached,ec1fb56,dormando,2024-12-30T02:36:08Z,"core: IO subsystem refactoring  Aligns the ""Background IO system"" closer to what the proxy needs to operate cleanly. Reduces connection structure size ~10% as well.  Mainly this moves the ""queue of work"" concept from ""per connection structure"" to ""per event thread"". It then changes the concept of a ""suspended connection"" to be ""suspended responses"", which has a counter per conn. This allows a single suspended response to internally make many sub IO's and then later resume the original connection without overcomplicating things.  Most of the time IO's are enqueued to the event thread and then executed within the context of a single connection executing requests: meaning we will almost always submit queued for a single connection even with the new code.  This also fixes rctx:sleep() and unblocks using mcp.internal as a V2 API backend.",https://github.com/memcached/memcached/commit/ec1fb560fae7a6dbbce8670f4c30121c51f3ae19
memcached/memcached,https://github.com/memcached/memcached,7d6bc7b,dormando,2024-12-23T00:57:30Z,core: more dtrace fixes,https://github.com/memcached/memcached/commit/7d6bc7b09e3c6bb8eaff8b2b3d78d01e0bf17f6f
memcached/memcached,https://github.com/memcached/memcached,dc68c54,dormando,2024-12-22T23:40:51Z,core: fix compilation when extstore disabled,https://github.com/memcached/memcached/commit/dc68c54c84b8302995ef33facd6ffdfe2865ed08
memcached/memcached,https://github.com/memcached/memcached,550b0fa,dormando,2024-12-22T23:33:32Z,core: dtrace fixes.,https://github.com/memcached/memcached/commit/550b0fa0bdbca40ceca8a40d7c423a207ed7875c
memcached/memcached,https://github.com/memcached/memcached,f392de2,dormando,2024-12-22T23:24:49Z,"core: restore automove == 2 mode  I hate how this is implemented, but a better approach would be to make the in-memory mover algorithm much more aggressive and remove the in-line reassign. Instead of removing the feature, that is.  The memory algo could be set to ""if any class has evictions, move random slab class to it, and don't delay"" or something.",https://github.com/memcached/memcached/commit/f392de251b5974fb3e6b80956b289984b99c4c63
memcached/memcached,https://github.com/memcached/memcached,c360ce8,dormando,2024-12-20T19:37:26Z,extstore: refresh automove on ext_item_size change  internal balancing and calculations weren't following ext_item_size on account of caching the value internally.,https://github.com/memcached/memcached/commit/c360ce8693a610f4e37a23fd8091ce0d08ba4119
memcached/memcached,https://github.com/memcached/memcached,a2dac19,dormando,2024-12-17T22:36:23Z,"proxy: fix issue with waiting on subreqs  If a rctx enqueues N subrctx's, then issues a wait, but all of the subrctx's fast fail... if you then issue another wait API call the parent will get resumed recursively before the child is completed.  Meaning the parent won't resume the coroutine if the subrctx's did _not_ match the wait condition (ie: looking for WAIT_GOOD and got WAIT_ANY).  To be honest the issue is so complex but the fix so simple I'm not going to attempt to describe it past this point.",https://github.com/memcached/memcached/commit/a2dac1908bd36435e83870e844b9036ea45b284a
memcached/memcached,https://github.com/memcached/memcached,4c56c8d,dormando,2024-11-14T23:58:26Z,"core: slabs automover improvements  Overhaul of how page moving works for memory balancing.  Removes `slabs_evictions_nomem` case entirely. Instead of sometimes evicting random memory when re-assigning memory, it will pull from the LRU tail. If memory is not completely full it will not evict items when moving pages.  The extstore related memory balancing algorithm has been simplified and improved. The new stat `extstore_memory_pressure` has been added. It is a percentage between 0 and 100: At 100 extstore will be forced to evict items instead of simply moving items from memory to disk.  Many performance improvements and code cleanups were also done.",https://github.com/memcached/memcached/commit/4c56c8d3e2b226ece24e5822ee08a9e31c101552
memcached/memcached,https://github.com/memcached/memcached,5b84e42,dormando,2024-12-03T01:04:56Z,proxy: fix mutator reserr err messages  mode was renamed to code.,https://github.com/memcached/memcached/commit/5b84e42599b741a1d83dccd3371a5c90c93f2068
memcached/memcached,https://github.com/memcached/memcached,a19c07b,dormando,2024-12-03T00:39:26Z,proxy: set result object status from mutator  frick.,https://github.com/memcached/memcached/commit/a19c07b6aa465007fc8f9152ca4ff311fcdf3f57
memcached/memcached,https://github.com/memcached/memcached,b4a061c,Yufei Hu,2024-11-25T18:21:16Z,Changing the proxy GC default ratio from 1.9 to 2.0,https://github.com/memcached/memcached/commit/b4a061ccaa85973716a347841e374a9a4683f591
memcached/memcached,https://github.com/memcached/memcached,08b0057,dormando,2024-11-14T18:04:12Z,proxy: fix compilation issue on beta RHEL/GCC  Apparently _rotl no-go as a function name. no idea why but we generally use the mcp_ and _mcp namespace anyway.  Fixes #1186,https://github.com/memcached/memcached/commit/08b00579fd9d2abd5d5116bbda27f8eceaba6038
memcached/memcached,https://github.com/memcached/memcached,d164eb1,dormando,2024-11-11T22:58:27Z,"proxy: simplify lua GC logic  Do not let the speed of the GC bounce up and down as total memory moves, only increase. If memory decreases during a GC run the speed will stay constant.  Simplify some of the logic around the functions; removes a few branches from fixed overhead.  Make ""gc timerpoke"" even less likely to run: if the main GC is running _or_ if memory changes at all, don't run the poker. This should avoid a situation where the poker very slowly frees memory, preventing the main GC algorithm from knowing when it should actually run next.  Also make the ""timerpoke"" not update the internal notes on when to run the GC next. This keeps the ownership of when to start the GC in one place, also all other accounting can continue to make sense.",https://github.com/memcached/memcached/commit/d164eb151af58f3835b63a83bb38e8d42892e669
memcached/memcached,https://github.com/memcached/memcached,998e18c,dormando,2024-11-08T23:04:31Z,proxy: add mcp.luagc_ratio(float)  changes the default GC growth ratio from 2.0 to 1.9. 1.9 was the previous value we were setting to the internal lua GC algorithm.,https://github.com/memcached/memcached/commit/998e18c7833ace2bbcbf18880787510f53401abd
memcached/memcached,https://github.com/memcached/memcached,65b570b,dormando,2024-10-31T21:54:42Z,proxy: update mutator header warning,https://github.com/memcached/memcached/commit/65b570bda0d23d68f7776cf28bfa4131cc772617
memcached/memcached,https://github.com/memcached/memcached,b2e4515,dormando,2024-10-31T21:50:26Z,proxy: fix mutator reserr step  also fix letting it parsing actual error messages.,https://github.com/memcached/memcached/commit/b2e451598e9f50a55918890cb5d7c96fb41b43e3
memcached/memcached,https://github.com/memcached/memcached,49850fb,dormando,2024-10-31T21:03:28Z,proxy: mutator code cleanups,https://github.com/memcached/memcached/commit/49850fb714aa72854438a3a29a9b064d4a6630d4
memcached/memcached,https://github.com/memcached/memcached,d44c8f0,dormando,2024-10-31T20:34:50Z,proxy: improve various mutator copy steps  now always checks the input argument properly and handles appropriately instead of crashing or not being able to use strings vs objects.,https://github.com/memcached/memcached/commit/d44c8f0c27c5334c57cda34e057a9be362158ab8
memcached/memcached,https://github.com/memcached/memcached,bdc8c68,dormando,2024-10-30T21:46:19Z,proxy: update TODO/FIXME notes inside mutator,https://github.com/memcached/memcached/commit/bdc8c6844437b162b71a2c29e97eb2766d45d3e4
memcached/memcached,https://github.com/memcached/memcached,8cfaf31,dormando,2024-10-30T20:38:19Z,proxy: don't allow mutating mutated objects,https://github.com/memcached/memcached/commit/8cfaf3107c55625f7517818eb491b1d3bfd38b32
memcached/memcached,https://github.com/memcached/memcached,e887658,dormando,2024-10-30T20:31:44Z,"proxy: fix for result value buffers  wasn't malloc'ing space for a value to copy into a result object.  we still can't copy a value from a result object, which prevents us from creating new requests from a response or a response from a response, but that will happen after upstream mcmc fixes.",https://github.com/memcached/memcached/commit/e887658d74d0a21eb038ff0d38e8aa8250365a4e
memcached/memcached,https://github.com/memcached/memcached,e368cd2,dormando,2024-10-30T19:00:45Z,proxy: improve mutator constructor consistency  instead of 'str' just take 'val' for the 'value' part of a step specification. previously was sometimes val and sometimes str.,https://github.com/memcached/memcached/commit/e368cd26b98a6233aceba4a145b00bebdf3f48d8
memcached/memcached,https://github.com/memcached/memcached,1c8f59f,dormando,2024-10-30T18:44:43Z,"proxy: make mutator user args start at 1 not 2  We already ++'ed the arg internally to skip ""self"" from the OO call format. mutator is always called as mut(dest, args) so 1 would be the ""first user argument""",https://github.com/memcached/memcached/commit/1c8f59fabaae265f1f6a031c22f57b0169d71006
memcached/memcached,https://github.com/memcached/memcached,b038067,dormando,2024-10-30T18:24:20Z,"proxy: internally track rctx:*_new objects  We need to issue a request or result object cleanup _after_ a request context has been completed and returned to the slot cache. Else request or result buffer memory will hang around until the next time the slot is used.  This requires internally tracking when these objects are created and directly freeing them. We do this by adding extra rqu's in the existing rcontext structure, so we can efficiently loop them instead of having to go through lua.",https://github.com/memcached/memcached/commit/b038067c6b3e225a39d8d06d8ac5b203324053af
memcached/memcached,https://github.com/memcached/memcached,5c225c2,dormando,2024-10-29T23:07:02Z,"proxy: fix mutator with dynamic arguments  valcopy/flagcopy/etc weren't able to ""do the right thing"" based on the passed argument. now it'll quickly parse the type of the input argument and source the data properly.  flagcopy now supports a raw string input as well.  numerics are still unimplemented.  removes a few more remaining assert's.",https://github.com/memcached/memcached/commit/5c225c2fac47b89c7428069fd64e17e4076cef6e
memcached/memcached,https://github.com/memcached/memcached,937d130,dormando,2024-10-29T01:21:48Z,proxy: assert -> errors in mutator,https://github.com/memcached/memcached/commit/937d130272d7ad44d1c271b1e4e84342c60f65c6
memcached/memcached,https://github.com/memcached/memcached,5d4b309,dormando,2024-10-29T01:00:12Z,proxy: handle mutator errors in totalling phase  copy/run phase should have no reason to hit errors.,https://github.com/memcached/memcached/commit/5d4b309c1d76c8a685c146f273aa379e84f81dd3
memcached/memcached,https://github.com/memcached/memcached,a0f288b,dormando,2024-10-28T04:12:30Z,"proxy: fixes to request object  - mcp.request() was not honoring the request maxlen limit, leading to   crashes if long requests were made. - when allocating a request, we were allocating an extra KEY_MAX_LENGTH   on top of MCP_REQUEST_MAXLEN (which is itself KEY_MAX_LENGHT*2). This   memory was never used and thus wasted. - we were allocating an upvalue (which is extra memory) for requests,   which was never used. - some minor/comment fixes  also: - remove t/startfile.lua since it no longer serves as a code example for   v2",https://github.com/memcached/memcached/commit/a0f288b05d55d716ef4d3918ec4ec832211f9376
memcached/memcached,https://github.com/memcached/memcached,76f40c6,dormando,2024-10-24T19:27:43Z,proxy: embed routelib  If started with `-o proxy_config=routelib` then we load an internally compiled copy of routelib. Further user config is specified via `proxy_arg=file.lua`  Includes the original .lua file in the dist tarball for users to modify if needed.,https://github.com/memcached/memcached/commit/76f40c6b7812a749a3da12c35c7f6d96b258c3e0
memcached/memcached,https://github.com/memcached/memcached,85bbc93,dormando,2024-10-24T19:43:04Z,vendor: bump sha,https://github.com/memcached/memcached/commit/85bbc935068ea363891c5313ebe13320f6e05c3d
memcached/memcached,https://github.com/memcached/memcached,8203c93,dormando,2024-10-20T21:52:54Z,"core: fix ascii auth bug with missing newlines  If a user supplies an authfile to -Y with a single user:pass and no newline, we were cutting the final character of the password and failing to authenticate.",https://github.com/memcached/memcached/commit/8203c934bac24ff9f54e837d618c2521ef826a64
memcached/memcached,https://github.com/memcached/memcached,30f302f,dormando,2024-10-13T20:22:30Z,"proxy: tune slot cache freeing algorithm  Main goals for slot-cache-freeing algorithm: 1. Avoid hard limits on free slots. Prevents freeing/allocating slots    in tight loops. 2. Don't hang onto slot memory forever after temporary traffic bursts.  Something like a PID controller to tune ""Free slot limit"" would run afoul of rule 1: if we have slightly too many free sometimes we can end up alloc/freeing during heavily pipelined traffic. Best case until the PID controller adjusts. This might still be useful for finding a target number of free slots in the future so I may revisit this.  In the meantime the current algorithm can be made less aggressive by giving it a concept of clock time. It would decide on when to free things after every N requests are processed; now it will wait until things are ""too free"" for at least a minute before adjusting. This should prevent wobbles from brusty traffic.  If slot counts do still wobble with this adjustment, the allocations should be far enough apart (60 seconds) to be generally amortized.",https://github.com/memcached/memcached/commit/30f302fd4ea5b865466d674c57437f975cfcecfd
memcached/memcached,https://github.com/memcached/memcached,bc7ef4a,Yufei Hu,2024-10-08T04:03:28Z,proxy: add mcp.internal() tests on watch deletions,https://github.com/memcached/memcached/commit/bc7ef4aad238d0de8b62043ae0094dc876a8ec64
memcached/memcached,https://github.com/memcached/memcached,7c47610,dormando,2024-10-10T00:11:14Z,proxy: add missing delete logs to mcp.internal,https://github.com/memcached/memcached/commit/7c476107ef90b1411819b10bafc6eecb738e923d
memcached/memcached,https://github.com/memcached/memcached,1da0e29,dormando,2024-10-09T22:00:34Z,proxy: more inspector unit tests,https://github.com/memcached/memcached/commit/1da0e29ec48a15f618fb3c6723577312985209e3
memcached/memcached,https://github.com/memcached/memcached,0ccaf43,Finn Frankis,2024-10-04T22:01:00Z,proxy: add inspector tests for res with values,https://github.com/memcached/memcached/commit/0ccaf4373d708604e4873c373a4df323705c8cb3
memcached/memcached,https://github.com/memcached/memcached,04e123a,dormando,2024-10-10T00:01:04Z,mcmc: upstream updates,https://github.com/memcached/memcached/commit/04e123a79253bae1fc04b6904c21c3184c3aeb41
memcached/memcached,https://github.com/memcached/memcached,c71868a,dormando,2024-10-04T22:30:05Z,"proxy: fix crash in router code  If using a multi-character separator the check for end of bounds could underflow, and wasn't being detected.  This fixes #1175",https://github.com/memcached/memcached/commit/c71868a1c7a43ba92df9535534cf26612d0640fa
memcached/memcached,https://github.com/memcached/memcached,3c03f2f,dormando,2024-10-03T02:24:33Z,"core: fix quoted start arguments  From #1174: ""-l localhost:11211"" will fail. internally we end up with a suboption string of "" localhost:11211"" instead of ""localhost:11211"". The same happens with `-o` suboptions.  A simple fix to to ensure we skip leading whitespace in optarg.",https://github.com/memcached/memcached/commit/3c03f2f0b48b2f2ea41354f5f992f27c5d58b6e8
memcached/memcached,https://github.com/memcached/memcached,af53ab8,dormando,2024-09-25T22:27:05Z,"core: fix some potential crash with libevent code  When a log watcher or lru crawler closes early, we re-arm the connection's event structure, but we may not have first removed the event.  This seems unnecessary: instead we just do a blind delete when the connection closes, which libevent seems happy with.  I've also added an event_del to the default, which I don't believe gets executed.  Do not understand as of this writing how it's possible to get into this situation, but someone's test is causing it to happen.",https://github.com/memcached/memcached/commit/af53ab8d8abceee7c0d67d020402838a3e42e8c3
memcached/memcached,https://github.com/memcached/memcached,18b189b,dormando,2024-09-24T00:19:23Z,"proxy: fix potential crash under high write load  This is a multi-pronged bug: - Was using libevent's event_pending() wrong: should just check for 0 - Was checking for pending events when resetting a dead backend instead   of always deleting an event (just in case; which seems to happen) - ""stop main event"" function was actually deleting the write event - ""start write event"" was checking for pending events in main event   instead of write event - ""stop write event"" was checking for pending events in main event   instead of write event - in proxy_beconn_handler: if a new connection has a queue of large   requests that full the write socket buffer, it was not initiating a   wait for the socket to become writable, which can cause requests to   wait too long or hang.  Combined together, depending on binary layout, OS, libevent version, etc, either nothing happens or sometimes an event can become corrupted and point to itself, hitting an infinite loop.  Getting into this condition requires writing very large requests faster than the system can write to backend nodes, _and_ read timeouts have to be low enough that backend sockets time out waiting for responses. This would lead to the wrong event being stopped when a backend is reset, and later reconnects and resets could lead to corruption.  In short reproducing this requires maxing out node backend while writing large set requests with low timeout settings.",https://github.com/memcached/memcached/commit/18b189b41bb2836880caccc0bec85c109d44befd
memcached/memcached,https://github.com/memcached/memcached,7a4fb19,dormando,2024-09-23T22:09:58Z,proxy: internal debug functions  call from gdb while stopped to help walk internal data structures.,https://github.com/memcached/memcached/commit/7a4fb19647627c94f582fc1df7f81c59f5c91beb
memcached/memcached,https://github.com/memcached/memcached,5609673,dormando,2024-09-06T21:33:32Z,"tls: fix logging crash  If TLS enabled but we immediately fail a handshake, it was looking for an event thread, which is not here because the acceptor thread is in the main process.",https://github.com/memcached/memcached/commit/5609673ed29db98a377749fab469fe80777de8fd
memcached/memcached,https://github.com/memcached/memcached,b8b872a,dormando,2024-09-05T04:47:55Z,"proxy: fix proxy_req_active accounting  In V1 active reqs and await reqs were accounted for differently. In V2 there's no reason to do this. This is also less code and cleaner.  So now proxy_req_active will be the total of all active slots, allowing the active req limit setting to properly limit global request memory.",https://github.com/memcached/memcached/commit/b8b872ab5ce5bc74073e9bf63dc3791d462dda09
memcached/memcached,https://github.com/memcached/memcached,707594d,dormando,2024-08-23T21:17:14Z,"proxy: remove V1 API  res = pool(r) rtable = mcp.await(r, pools)  ... are no longer supported. this paves way for lots of internal cleanups and optimizations. This is because V2 holds long term references to pools in higher level objects, so the memory management for pool objects can be done more exactly.",https://github.com/memcached/memcached/commit/707594d4c1a5987fed35923b20d99aecea735fd8
memcached/memcached,https://github.com/memcached/memcached,2395a2d,dormando,2024-08-27T23:40:12Z,"core: fix usleep not working on NetBSD  On NetBSD, and so far as I can tell _only_ NetBSD, if you ask `usleep` to sleep for more than 1 second it will instead do nothing. This causes the LRU maintainer to suddenly max out CPU on an idle server, because it stops sleeping once it hits the max backoff of 1 second, exactly 1us longer than NetBSD usleep can handle.  I'm sure there's an interesting history if I feel like digging into it, but maybe some other time. It doesn't seem very helpful.",https://github.com/memcached/memcached/commit/2395a2d770db8965a23abe423b1b23e7e9617a98
memcached/memcached,https://github.com/memcached/memcached,852f648,dormando,2024-08-27T22:54:03Z,tls: fix compile error when tls not built in  from previous commit.,https://github.com/memcached/memcached/commit/852f648a0984e85c85aa8a27fe78b5f1c1574783
memcached/memcached,https://github.com/memcached/memcached,9c81709,dormando,2024-08-25T01:11:47Z,tls: fix another conn flag leading to crash  fixes a second case of a tls related value not getting reset when a connection structure is being reused.,https://github.com/memcached/memcached/commit/9c81709c6ab8302e101fee718ff4891972b0d9b7
memcached/memcached,https://github.com/memcached/memcached,461d873,dormando,2024-08-24T00:39:12Z,"tls: crash fix: clear c->ssl on new  conn structures are reused without fully wiping the struct, so if the same conn object would go from ssl to non ssl it could crash.",https://github.com/memcached/memcached/commit/461d8737ec0e021b5af5454550a0d1b232ef33ff
memcached/memcached,https://github.com/memcached/memcached,dbe1819,dormando,2024-08-11T18:44:31Z,proxy: [EXPERIMENTAL] mutator framework  See WARNING at top of `proxy_mutator.c`: this is a non-production-ready experimental interface that needs further work. It's being merged in order to facilitate easier testing without having losing significant time to rebasing or fiddling with branches.  THERE IS NO RISK TO DEPLOYMENT if the code is NOT USED. It does not make any core changes and the only hooks into files outside its own .c are just enabling the API in lua.,https://github.com/memcached/memcached/commit/dbe18199207e5d275631d2727d4f5a39c4f8093e
memcached/memcached,https://github.com/memcached/memcached,de26646,dormando,2024-08-20T22:03:05Z,proxy: test changes  make funcgen tests more verbose as to where they're failing  attempt to make antiflap test less flaky... but still seems off.,https://github.com/memcached/memcached/commit/de2664673f20911f2bc936f78eff97bbffb6c091
memcached/memcached,https://github.com/memcached/memcached,cf21aae,dormando,2024-08-20T19:37:04Z,proxy: improve test  adds subtest markers to t/proxylimts.t since the wait_reload() failure doesn't croak the stack lines.,https://github.com/memcached/memcached/commit/cf21aae410c8216bea522ccfa90044db332bb5a3
memcached/memcached,https://github.com/memcached/memcached,e078242,dormando,2024-06-01T03:21:55Z,proxy: str = rctx:tls_peer_cn()  Returns a string copy of the TLS peer CN entry. Returns nil if none exists or unable to parse the certificate.,https://github.com/memcached/memcached/commit/e078242ed34cc7974d6e3af1d40f2098170aa723
memcached/memcached,https://github.com/memcached/memcached,41db678,dormando,2024-08-19T23:26:28Z,"proxy: fix inspector with mcp.internal() responses  mcp.internal's result lines are in r->cresp->wbuf referenced into an iov, not r->buf. This fix checks for where the res line is before attempting to reference it.",https://github.com/memcached/memcached/commit/41db67890dcc7fdc511df5274a1a9c593bb1acd6
memcached/memcached,https://github.com/memcached/memcached,b2fb23d,dormando,2024-08-09T21:10:15Z,mcmc: upstream update  small fix.,https://github.com/memcached/memcached/commit/b2fb23d54414e9f135a86304d5d238fb847d3ed9
memcached/memcached,https://github.com/memcached/memcached,3ef3b76,dormando,2024-08-07T02:07:10Z,"proxy: req/res inspector objects  See t/proxyins.lua or wiki docs for usage. Also #1162  Also adds res:flag_blank(""f"") for quickly removing a flag and its token from a result line by replacing it with blanks.",https://github.com/memcached/memcached/commit/3ef3b768e62f30b6be1d7b1278adbf5216f83638
memcached/memcached,https://github.com/memcached/memcached,c237556,dormando,2024-08-07T02:06:07Z,mcmc: upstream update  new tokenizer and other things. small API change for existing code: no functional change.,https://github.com/memcached/memcached/commit/c23755614ae4039fa3bbc90ed9f9ed1acd4b0d44
memcached/memcached,https://github.com/memcached/memcached,e6970b9,dormando,2024-07-25T21:58:16Z,proxy: r:token_int()  for getting a non-metaget command token as a lua integer.,https://github.com/memcached/memcached/commit/e6970b9f80014704826a8c3fdf852f1b68d69906
memcached/memcached,https://github.com/memcached/memcached,f5fe7d1,dormando,2024-07-25T19:37:28Z,"proxy: req:flag_token_int(""f"")  returns 'bool, int' where bool is true if the flag exists, and int is not nil if the flag had a token and it could be converted to an integer successfully.  might adjust this: bool is true/false if total success or not and int is not-nil on success.",https://github.com/memcached/memcached/commit/f5fe7d1e4df24d9f05b21ad6ce49651fd7f6c0f0
memcached/memcached,https://github.com/memcached/memcached,05320c9,dormando,2024-08-08T21:53:31Z,"tls: per-listener cert validation  For the -l arguments with 'notls:ip:port' we now have 'btls:ip:port' and 'mtls:ip:port'  'btls' disables peer certificate verify on this listener, if it was enabled globally by `ssl_verify_peer`. 'mtls' enables peer certificate verify on this listener. This is the same as setting ssl_verify_peer to 'require'",https://github.com/memcached/memcached/commit/05320c9e02624439040bd9939e28a35e4281ab3d
memcached/memcached,https://github.com/memcached/memcached,a4bc538,dormando,2024-06-24T21:25:18Z,"tls: actually look at TLS errors  Adds TLS specific errors to `watch connevents` log stream. Ensures read/write retry errors have the correct errno set before returning to caller.  add ssl_proto_errors counter  If this is ticking, you can look at `watch connevents` to get full detail. log entires are type=conntlserr",https://github.com/memcached/memcached/commit/a4bc53841b18df0b2d14b0be3caa7baeb3795c21
memcached/memcached,https://github.com/memcached/memcached,999912e,dormando,2024-06-22T23:33:03Z,"tls: update min OpenSSL to 1.1.1  1.1.0 was EOL'ed at the end of 2019 so far as I can tell. 1.1.1 was EOL'ed in september 2023, so even this new minimum version is too old.  In future months I might bump the minimum version again, but there are API backcompat reasons why setting this to 1.1.1 is useful for now.",https://github.com/memcached/memcached/commit/999912eae5ae377e26bd66ea22139d22d68f4a82
memcached/memcached,https://github.com/memcached/memcached,27ee1bc,dormando,2024-06-22T23:02:24Z,"tls: quarantine openssl headers  To reduce ifdef soup and proliferation of OpenSSL headers, ensure all openssl-specific calls and defines are only used within tls.c. This reduces the scope we need to check for compliance with the openssl API.  This change also reduces the amount of ifdef TLS going on.. There is still a lot left but this is enough change for now.",https://github.com/memcached/memcached/commit/27ee1bce41f773ca0441382bf6d7ec04b0151339
memcached/memcached,https://github.com/memcached/memcached,73669eb,dormando,2024-08-05T22:57:44Z,"proxy: fix potential mcp.match false negative  I'm not sure how to reproduce this issue in production but the problem is obvious.  The response line is copied from a backend-specific read buffer into a response object buffer. However the struct holding the response value has string pointers that point at the _backend_ buffer, not the _response_ buffer.  Thus, if you attempt to mcp.match() after the backend has reused its read buffer for other work you might fail accidentally.  This fixes that in a minimal way by re-parsing the result directly out of the buffer before using it.",https://github.com/memcached/memcached/commit/73669eba9f01e308fecaa3e2a6b9d3197d0cfe69
memcached/memcached,https://github.com/memcached/memcached,6b10771,ArtemIsmagilov,2024-07-09T09:29:14Z,Update doc/protocol.txt for watch/automove  Adds missing options,https://github.com/memcached/memcached/commit/6b1077185b309384e53ab23383e154e6e5a521c3
memcached/memcached,https://github.com/memcached/memcached,33ee3f9,Ryuichi Watanabe,2024-06-24T02:13:37Z,actions/checkout update,https://github.com/memcached/memcached/commit/33ee3f95d233aa7e6d856e6022c574b2464e98d0
memcached/memcached,https://github.com/memcached/memcached,3031e79,dormando,2024-07-23T18:19:51Z,mcmc: upstream update  fix fault if connecting to down servers (sometimes),https://github.com/memcached/memcached/commit/3031e790d2e5869a775394e707b8ead8e588cb54
memcached/memcached,https://github.com/memcached/memcached,bc15562,dormando,2024-07-16T19:32:47Z,"proxy: fix O token for some mcp.internal calls  Was done correctly in almost all cases, but missed advancing the string pointer in two cases.",https://github.com/memcached/memcached/commit/bc15562b625798b2232a26a95bf7bb562119ec71
memcached/memcached,https://github.com/memcached/memcached,2793cd3,dormando,2024-07-16T16:11:24Z,"proxy: fix router regression with cmaps  Fixes crash when a router only has a command map, as we were attempting to walk a map that didn't exist.",https://github.com/memcached/memcached/commit/2793cd3e96884fa0defa50517b770fac5905e5e1
memcached/memcached,https://github.com/memcached/memcached,b1aefcd,dormando,2024-06-19T22:52:52Z,"proxy: ustats internal refactor  If a ustat changes name for the same index, its value is reset to 0.  Cleans up some confusing code around how ustats are handled; the global ctx and worker threads now use different structures with different intent, instead of different sides of the same struct.  Speeds up `stats proxy` dumping by compacting stat names into a linear buffer, and unrolls some snprintf's into direct memory copies plus a faster itoa.  Also reorders the entries in the global ctx so the most frequently accessed ones are clustered toward the front of the struct.",https://github.com/memcached/memcached/commit/b1aefcdf8a265f8a5126e8aa107a50988fa1ec35
memcached/memcached,https://github.com/memcached/memcached,82ac525,dormando,2024-06-19T00:37:02Z,"proxy: router refactor and cmap fallback  Allows specifying a commandmap on a router as well as a map and default route. Lookup order is: - Check map, if entry is map, check that - If none matched, check fallback command map - If nothing matched, return default route handler if exists  Also removes the router struct from the funcgen object, saving 32 bytes and letting me extend the size of the router struct without bloating every allocated fgen. This will later allow inlining the lookup map into the router struct for a lookup speedup.  Finally, this adds support for ""cmap only routers"", which is mostly useful when working with abstractions like routelib.",https://github.com/memcached/memcached/commit/82ac5259f7f181fac13ea730ad6c7bc26bd17400
memcached/memcached,https://github.com/memcached/memcached,a36ea4d,dormando,2024-06-10T23:59:34Z,"proxy: match, token = req:match_res(res)  If req has 'k' and/or 'O' flags, match against the result object.",https://github.com/memcached/memcached/commit/a36ea4df1469ee2c3988e2f3242b13fb98e8f9bb
memcached/memcached,https://github.com/memcached/memcached,05f5d56,dormando,2024-06-26T00:52:47Z,"proxy: ensure resp.elapsed gets set  If a response is returned because of an error clearing a backend queue the elapsed time never gets set, leaving it as zero. Unless you're using mcp.await(), which was setting the elapsed time itself.  would be better to wrap return_io_pending() to cut the calls down to 1. Should do that later.",https://github.com/memcached/memcached/commit/05f5d562f3246d55d105dd76c3a5527f422bbe58
memcached/memcached,https://github.com/memcached/memcached,aeb1ea1,dormando,2024-06-17T16:38:31Z,proxy: let proxy build without openssl installed  If proxy specific TLS features were not enabled we were still including the openssl headers.,https://github.com/memcached/memcached/commit/aeb1ea17a0ef5b1688527084fc60ef4ebcf774b0
memcached/memcached,https://github.com/memcached/memcached,90f1d91,Pierre-Yves Rofes,2024-05-25T14:06:19Z,"memcached-tool: add -u flag to unescape special chars in keys names  The ""lru_crawler metadump all"" command called by ""keys"" option escapes unsafe special chars with corresponding %xx codes. For example, a key named ""keywith+"" will be shown in ""memcached-tool keys"" as:  key=keywith%2B exp=... la=... cas=...  But in some cases in can be useful to have the original key name printed as-is. This commit adds a ""-u"" flag to do the unescaping of lru_crawler output before displaying it.",https://github.com/memcached/memcached/commit/90f1d91bd0b3048fc2e3dffad8511559568b8ac2
memcached/memcached,https://github.com/memcached/memcached,68d0b9e,Daniel Vasquez-Lopez,2024-05-15T03:46:21Z,core: Reorder r/w for itemstats aggregation  to leverage SIMD instructions. See https://godbolt.org/z/7GGEM1e7j,https://github.com/memcached/memcached/commit/68d0b9eba62891d2d737f98312df6e3206366952
memcached/memcached,https://github.com/memcached/memcached,6fdc1e6,dormando,2024-05-31T05:14:02Z,"proxy: add counters for VM memory and GC runs  vm_gc_runs: number of times a lua VM GC has been run. Each worker thread VM causing a GC run increases this number. vm_memory_kb: total memory in kilobytes of all worker thread VM's. Does not include the config thread.  Wanted to add a counter for gc steps as well, but am not convinced it's useful information.  Also adds a VM fudge when freeing a request slot. This tricks the GC to run if slots are being freed up, as otherwise memory can stick around for a long time if nothing else is being allocated and dropped.",https://github.com/memcached/memcached/commit/6fdc1e6470760fdc681e8212c38038e94c710d74
memcached/memcached,https://github.com/memcached/memcached,f370037,dormando,2024-05-30T01:15:23Z,"proxy: make iov limit bugs easier to see  Shredders bench suite can trigger the former BE IOV limit issue easily when the IOV limit is 128 or less, but somehow very very rare for 256+. Also adds an assert that will fire if the condition is hit rather than corrupt data.",https://github.com/memcached/memcached/commit/f3700374f40385b3288c961401be4b0895642235
memcached/memcached,https://github.com/memcached/memcached,5d97fda,dormando,2024-05-29T17:56:37Z,proxy: `res:close()`  alias the __close to close() so users can manually clear an object.,https://github.com/memcached/memcached/commit/5d97fda21fe3c855c23f4504140d77cb93143e5c
memcached/memcached,https://github.com/memcached/memcached,33c00b4,dormando,2024-05-28T23:45:11Z,"proxy: fix stupid write flush bug  If we can't write the entire backend request queue within the IOV limit, we mark where in the request queue we were and try again later if the socket is still writeable.  Out of paranoia I had marked the position _before_ the next not-flushed IO, but that is obviously wrong: any _flushed_ IO can be _removed_ from the stack after processing a READ event from the socket. If we start again at the position of a flushed IO it might be reclaimed memory.  Somehow this was extremely hard for the bench suite to reproduce, unless I cut the IOV limit from 1024 to 32.",https://github.com/memcached/memcached/commit/33c00b49f20a092a33ffb5d48ff3a0037088fc7c
memcached/memcached,https://github.com/memcached/memcached,8a9b709,dormando,2024-05-21T22:39:42Z,"proxy: backend TLS support [EXPERIMENTAL]  Has not been extensively tested or validated under benchmarks. Please let us know if you intend to use the feature, but feel free to try it out yourself since it will likely work.  To use, within `mcp_config_pools`: mcp.init_tls() -- before making any backends mcp.backend_use_tls(true) or pass 'tls = true' as an argument to `mcp.backend`  Does not currently support client certificates or peer verification. Let us know if you need this support and we will prioritize it.",https://github.com/memcached/memcached/commit/8a9b709265cc0e7b786aa6d43dcc80206a8311af
memcached/memcached,https://github.com/memcached/memcached,788f592,dormando,2024-05-24T20:18:48Z,"crawler: don't block during hash expansion  if using `lru_crawler metadump hash` the client could block while trying to grab the maintenance lock potentially held by the hash table expander. Hash expansion can potentially take a long time.  Further, while waiting for this lock, the crawler is holding the lru crawler lock, which could cause other clients trying to talk to the crawler code to themselves block.  So... throw a locked error and don't do that.",https://github.com/memcached/memcached/commit/788f592f4a93a8f4f4ff2721f119f7de269e22c9
memcached/memcached,https://github.com/memcached/memcached,0954b53,dormando,2024-05-24T19:22:53Z,"proxy: support to-be-closed for result objects  if using mcp.internal(r) to fetch keys, but not returning them to the user, the underlying item references will normally stick around until they are garbage collected. Memcached is _not_ designed for this: references must be held for a short and temporary period of time.  If using a res object that you don't intend to send back to the user, it must be marked with <close>",https://github.com/memcached/memcached/commit/0954b53cd18cbc185fbf26d44f1c22c8a692fc36
memcached/memcached,https://github.com/memcached/memcached,4a75ac2,dormando,2024-05-16T00:25:52Z,"proxy: add mcp.backend_depth_limit(int)  If a backend has a queue depth limt over this amount, fast-fail any further requests.  A global parallel request limit can mean a single slow or overloaded backend causes the entire proxy to stop working. As a first layer of defence the depth for a particular backend should be capped.",https://github.com/memcached/memcached/commit/4a75ac2415549eca39dece91c7292378018f785b
memcached/memcached,https://github.com/memcached/memcached,14ad193,dormando,2024-05-10T20:12:52Z,"proxy: fix refcount leak in mcp.internal()  If running a fetch request without returning the result upstream to the user, a successfully fetched item would leak its reference.",https://github.com/memcached/memcached/commit/14ad1931b91eb12778ed0d2c6b2969e2aa0af24a
memcached/memcached,https://github.com/memcached/memcached,9dc8b14,dormando,2024-05-06T03:58:37Z,"proxy: fix backend depth counter  The ""request depth"" value for a backend could go negative in some cases. We used a magic value to attempt to speed up the sub-connection selector but I don't think that's necessary. Without the magic value we don't need to reset the depth to 0, so it stays balanced.  Added some new asserts so test and bench suites can find this issue more easily going forward. Survived the full bench suite with asserts enabled.",https://github.com/memcached/memcached/commit/9dc8b148345b27dd86580641d17f4268885b5894
memcached/memcached,https://github.com/memcached/memcached,a4d8324,dormando,2024-05-03T21:48:59Z,"proxy: fix short writes caused by mcp.internal  Wasn't filling in the 'tosend' portion of a response structure when using mcp.internal to create a response object.  This field is used as a fastpath check to see if a response has been completely transmitted to the socket or not. Since it was zero, we would always consider an mcp.internal() based response as completely sent, cutting off the data for larger items.  Expands tests for ""simply large"" and also a large enough to be chunked item.",https://github.com/memcached/memcached/commit/a4d8324942e653ec5fb5682d3ddeba38d00ff578
memcached/memcached,https://github.com/memcached/memcached,8a188a0,dormando,2024-05-03T17:58:48Z,"proxy: fix IO backlog softlock  If an IO thread got a large depth backlog it would only be able to write 1024-ish items at a time, requiring more requests coming in to continue the flush backlog. This is invisible in normal traffic conditions since a sudden burst in traffic would still quickly dequeue with normal traffic levels.  So if you cause a huge backlog and then _stop_ traffic it would never flush everything and appear to hang.  This does not apply to cases where the backend cannot finish flushing due to EWOULDBLOCK. That worked fine already.",https://github.com/memcached/memcached/commit/8a188a09916029abbc15526bbcd4b02c5b94ccc2
memcached/memcached,https://github.com/memcached/memcached,38ac376,dormando,2024-05-02T22:20:55Z,"proxy: even more GC tuning  Fixes lua GC getting behind and bloating memory in certain conditions.  I think this can only happen if you're running the debug binary and doing a pipelined benchmark from tons of client connections. This would create tons of garbage very quickly before the inbetween-requests GC collection system could catch up. With the debug binary the newer API recycles request slots 10x more often, making the problem visible.",https://github.com/memcached/memcached/commit/38ac3768755b40de58c24b9d45a01004c6f493ee
memcached/memcached,https://github.com/memcached/memcached,4d9b0e0,dormando,2024-05-02T01:11:14Z,"proxy: fix race condition leading to hang  If a lua function schedules extra requests after an initial set of requests, we need to use a workaround to ensure the second set of requests is actually submitted to the proxy backends.  This workaround was in the wrong place. If connections are being cut and reconnected between batches of requests it's possible for the workaround to trigger on a connection object that has since moved to another thread.  This patch tightens up the workaround to run before the client connection has a chance to resume.",https://github.com/memcached/memcached/commit/4d9b0e066b1ceeb3fc9f44c83046eee46ba73aa4
memcached/memcached,https://github.com/memcached/memcached,cf132f5,dormando,2024-04-28T22:06:25Z,"proxy: fix possible corruption with global objects  If a global object (ie; pool, global tbf) is created during `mcp_config_pools`, _and_ copied to each worker VM during a config reload, _but not used_ during `mcp_config_routes`, the worker VM's could cause the global object to be reaped early.  Convoluted: - Create pool obj - Return pool obj - Get pool proxy obj in `mcp_config_routes`, but don't use it! - Don't pass it to any funcgens! - Config thread moves on to next worker - Worker VM runs GC, clears pool proxy obj - _before_ config reload moves onto the next worker VM - Worker VM sees proxy refcount as 0, signals to reap object - The above can happen multiple times as refcount bounces between 1 and   0.  I have no idea how realistic it is to hit this problem and what the symptoms even are. I caused this via a long benchmark with constant reloads and hitting an assert in the debug binary. Changing the asserts around made them trigger from startup, making it easier to see the problem.  The fix: - When we first reference a proxy object, take an extra reference. - We get a signal bit by negating the lua self reference. - Enqueue the object for the manager thread to examine after the   config reload completes. - The manager thread ack's the object and reduces the refcount by 1,   negating the self ref back to positive. - If needed, immediately reap.",https://github.com/memcached/memcached/commit/cf132f5c4f86e18d49d5d4fec4a73bc0d6227d01
memcached/memcached,https://github.com/memcached/memcached,5c7e102,dormando,2024-04-26T21:36:39Z,"core: add queue info to `stats conns`  Adds to `stats conns` the state of deferred IO queues: extstore or proxy. The number of queues waiting (it can be both proxy and extstore), and within each queue how many sub-IO's are waiting.",https://github.com/memcached/memcached/commit/5c7e102326de0ab8267cad27e2ce52648d9d8925
memcached/memcached,https://github.com/memcached/memcached,3700411,dormando,2024-04-23T23:30:30Z,proxy: allow passing nil to mcp.server_stats()  ignores nil as though the argument were blank instead.,https://github.com/memcached/memcached/commit/37004115c9deb9ecb2722565bdcbd3c4e6a0d764
memcached/memcached,https://github.com/memcached/memcached,eb159bf,dormando,2024-04-23T23:04:27Z,"extstore: start arg tokenizer fix  checking for wrong separator for final token in a file descriptor. This didn't leak to a bug because there were no tokens after the bucket, but if we ever added one it would break so it's worth fixing.",https://github.com/memcached/memcached/commit/eb159bf768f377e28ada10927ee9c90cb1d2cc5d
memcached/memcached,https://github.com/memcached/memcached,6a8ee47,dormando,2024-04-23T23:01:42Z,"proxy: fix proxy_config with > 2 lua files  typo'ed a , for : in the second strtok_r, causing failure if more than two lua files are specified.",https://github.com/memcached/memcached/commit/6a8ee471d21c36e5a048d1dd2a8d0219fcc7e6e3
memcached/memcached,https://github.com/memcached/memcached,8e497e9,dormando,2024-04-11T21:45:54Z,"proxy: `mcp.server_stats(subcmd)`  Allow accessing server stats from the configuration thread (useful for crons, checking start args, etc). Does not support cachedump or detail.  Returns a table of the results. The results are thus unordered.",https://github.com/memcached/memcached/commit/8e497e9f091e46f3c4700b56024eae8e48bc5eb5
memcached/memcached,https://github.com/memcached/memcached,c824841,dormando,2024-04-15T21:37:06Z,proto: fix md with x and E  The new md flag 'x' was ignoring the 'E' flag and getting an internal CAS id.,https://github.com/memcached/memcached/commit/c824841a06d1c27b00274ea313e7a7b62f142cfa
memcached/memcached,https://github.com/memcached/memcached,563d05a,dormando,2024-03-13T20:51:32Z,meta: md with I and x removes value  If `md` is given the `x` flags it will remove the value but leave the item. When combined with 'I' it will mark this new item as stale as well.  This allows the user to create a tombstone of a previous value with a new TTL.,https://github.com/memcached/memcached/commit/563d05a82f1156de4f5b9b90876737df0777bd11
memcached/memcached,https://github.com/memcached/memcached,6537dcd,dormando,2024-04-02T05:47:40Z,proxy: wait timeout API  Give request contexts the ability to time out on wait operations. this allows moving along the logic without cancelling in flight requests or resetting backends.  This is done by adding an extra parameter to the various enqueue and wait functions. This parameter is seconds in floating point.,https://github.com/memcached/memcached/commit/6537dcdc3d4c69149521636ed8157f83113dd179
memcached/memcached,https://github.com/memcached/memcached,f678ae1,dormando,2024-04-10T03:47:24Z,"proxy: config thread cron functions  Adds a system for periodically running functions in the configuration thread. These crons may also signal to reload the configuration after they run. IE: you may shell out or run a module to fetch and download new json data, then reload the configuration.  mcp.register_cron(""name"",   { every = seconds, func = function()     print(""cron running"")   end })  Also accepts { rerun = false } to run the cron once after a reload. Can be used to check something after a reload has run, or simply issue a reload after an exact amount of time since the previous reload finished.  Crons that are not seen after a config reload are unloaded. IE: the only crons that may run must have been registered during the last configuration reload.  If a cron is overwriting itself, and the 'every' period has not changed, it will ""inherit"" the next scheduled run time. Thus config reloads will not interrupt the scheduling of crons that are not changing their time schedule.  Also adds `mcp.config_reload()` which will schedule the system to reload its configuration after the cron finishes running.",https://github.com/memcached/memcached/commit/f678ae129ba707708c8f733ffaf8f556ef564f2e
memcached/memcached,https://github.com/memcached/memcached,d995880,dormando,2024-04-10T03:52:25Z,"proxy: compile with rdynamic  When building proxy, use -rdynamic to export symbols. This allows, to start, re-exporting all of the lua symbols so modules don't need to pre-link with lua and can be a lot smaller.",https://github.com/memcached/memcached/commit/d995880c3daa58ded9e8af5a4c55eed08556686e
memcached/memcached,https://github.com/memcached/memcached,22480de,dormando,2024-03-06T19:38:27Z,"meta: E flag for overriding CAS value  Ecas means: if operation succeeds, set the item's CAS value to this. This allows external versioning of item data. This could be a row version, a time stamp, a crc32 or 64bit data integrity hash, and so on.  overriding the CAS value may make some features not work as well (ie; runtime enable/disable of `stats sizes`)",https://github.com/memcached/memcached/commit/22480de784b1f8bd3a6f832c18cbf28421a73667
memcached/memcached,https://github.com/memcached/memcached,ea66fe0,dormando,2024-03-28T22:59:41Z,"proxy: `stats proxybe` to show bad backends  stats command intended for backend state information.  so far just outputs ""bad_label"" [count] for each backend currently marked bad. The count is the number of backend objects marked bad.  If in ""per worker thread mode"" (default) if all workers recognize the backend as down, the count will be the same as the number of worker threads. If the IO thread is in use it would be 1.  If a backend has normal status, it is not included in the output.  Also fixes a bug with reconnects:  - If a remote server is listening for new connections but not accepting   them, the backend will fail in readvalidate and never get marked bad. - Now we only reset the fail counter and remove bad status if a backend   is fully validated.",https://github.com/memcached/memcached/commit/ea66fe0c6fbf4f1f82f77eea3cdbed89064aa00f
memcached/memcached,https://github.com/memcached/memcached,53f6650,dormando,2024-03-28T21:04:31Z,"proxy: rctx:cfd() and `log_req` cfd  log_req() now takes an optional 4th integer argument which is supposed to be the client file descriptor  log_reqsample() takes an optional 7th integer argument which is supposed to be the client file descriptor  rctx object now has an `rctx:cfd()` function to return the client fd.  since client objects are lost after a response has been returned upstream, we have to store the original cfd in the request context.",https://github.com/memcached/memcached/commit/53f665066ac92fbc5e5e1ebd85e3b69587735b36
memcached/memcached,https://github.com/memcached/memcached,77709d0,dormando,2024-03-25T19:42:35Z,"proxy: -o `proxy_arg` to pass cmdline to lua  Assigned to `mcp.start_arg` and available in all threads.  If argument is a normal string, it is assigned as a string.  If the argument contains ':' then it is split into a table. If sections of the string contain '_' then they are treated as key/value.  `proxy_arg=foo` -> foo.  `proxy_arg=foo_bar:baz' -> { foo = ""bar"", baz = true }",https://github.com/memcached/memcached/commit/77709d04dd4fc7d59f59425802cb9645b2cfe0f8
memcached/memcached,https://github.com/memcached/memcached,e9b2550,dormando,2024-03-24T19:05:17Z,"proxy: -o proxy_config takes multiple files  Allows a list of lua files separated by ':' to be loaded, in order. Useful for providing extensions to a library, or if there is a desire to split code between config_pools and config_routes into differnt files",https://github.com/memcached/memcached/commit/e9b2550d5edbec1896785aced4da659344e8dcfa
memcached/memcached,https://github.com/memcached/memcached,4ff4e81,dormando,2024-03-21T19:41:01Z,crawler: fix potential memory corruption  if the client closes during the finalization stages of the dump we can crash attempting to write a final END/EN to the client buffer.,https://github.com/memcached/memcached/commit/4ff4e8169c5f73e37a17df482916752bc0b17d1f
memcached/memcached,https://github.com/memcached/memcached,6f3eb9c,Qu Chen,2024-03-14T16:19:56Z,core: Add a couple of sanity checks.   - Handle failure to malloc for temp port number file initialization.  - Ensure value of c->rbytes is positive before using it in memmove  - Avoid implicit conversion of unsigned int to signed int for keylen,https://github.com/memcached/memcached/commit/6f3eb9c773eed15f2d942dbc359872fe25e918c6
memcached/memcached,https://github.com/memcached/memcached,80c2bca,dormando,2024-03-19T18:18:49Z,"proxy: tune slot cache aggressiveness  Wasn't handling short bursts very well, causing too much memory churn.  The ultimate answer is still a PID controller setting a target free amount but I'm hoping this still helps.",https://github.com/memcached/memcached/commit/80c2bca7352ea7388b8ea73bf3e0f271a1e29c05
memcached/memcached,https://github.com/memcached/memcached,bc608f0,dormando,2024-03-18T21:21:21Z,extstore: test fix on slow arm devices  tried to fix this by looking for compaction to run in the watcher but it wasn't doing it. need to try harder later.,https://github.com/memcached/memcached/commit/bc608f0fa127488d8eb11e007b8bb3f9634e6ce1
memcached/memcached,https://github.com/memcached/memcached,aa20d78,dormando,2024-03-15T23:09:56Z,core: remove `stats sizes_enable|disable`  Fixes #728 - rare crash when `stats sizes` feature is enable/disabled at runtime. Also removes dependency on internal CAS feature.,https://github.com/memcached/memcached/commit/aa20d785ab6d66b11a8e392f3d877624c8987c86
memcached/memcached,https://github.com/memcached/memcached,8aad5ae,dormando,2024-03-08T02:17:14Z,"core: stop using cas for flush_all  If CAS was enabled, it was used to make `flush_all` more accurate. Otherwise items set on the same second that a `flush_all` is run would fail to set.  This restores the old flush method of actively expiring items from the top of the LRU, but using proper locking. Thus no more use of CAS comparison and should work properly with our without CAS enabled.",https://github.com/memcached/memcached/commit/8aad5ae0709d922f60408b0a22c74b53f1c60d34
memcached/memcached,https://github.com/memcached/memcached,277f54d,dormando,2022-02-21T20:42:59Z,"extstore: tiered storage  This commit ads the concept of assigning data storage to specialized ""buckets"" in extstore. This can be used to create tiered storage between new and old/cold data. You can also tier between normal, compacted, ""low ttl"" and so on.  run with: ext_path=/path/f1:64m,ext_path=/path2/f2:128m:compact creates a 64m file for ""Default"" pages and a 128m file for compacted pages. Also works with 'chunked' and 'lowttl'.  OLD storage:  - If the above bucket is 'old' (ie; ext_path=/etc:1G:old) then when the   ""main"" disk is full, valid items are moved to the ""old"" bucket to free   up space in the main disk. This allows using cheaper storage for old   data. Especially useful if cache is an A/B data load.  - If the bucket is 'coldcompact' then the behavior is similar to 'old',   except that it will only move items that are in the COLD LRU.  Both of these features can be combined at once. Old active data could go to more expensive drives and cold data could go to cheaper networked drives.  Improvements: - fixes off-by-one preventing first page in each file from being used. - makes page eviction inline with allocation, making it more responsive   when necessary. - removes the ""fragmentation slew"" calculation from when compaction   should kick in. Instead of writing early, should wait until we've hit   the compact_under page limit then start compacting the emptiest pages. - begins compaction when free pages are nearly all gone, instead of when   fewer than 25% of pages are free. - defragments the _most fragmented page_ first instead of the oldest - uses a dedicated IO thread for data writes and compaction IO,   improving tail latency. - Runs the compaction checker algorithm less often, saving CPU.",https://github.com/memcached/memcached/commit/277f54dfeb8a95dbcb685d28a3065a6661cf408a
memcached/memcached,https://github.com/memcached/memcached,e58b8dc,dormando,2024-02-13T23:37:07Z,"proxy: run lua GC outside of request path  Keeps the GC paused while requests run, since each individual request can't generate much garbage. Instead we run steps inbetween batches of requests, getting progressively more aggressive by how much extra memory is allocated.",https://github.com/memcached/memcached/commit/e58b8dcc62484e86cd0d91ca454b0d19d4a37549
memcached/memcached,https://github.com/memcached/memcached,0210db5,dormando,2024-03-13T00:43:02Z,proxy: fix anonymous funcs in V1 API  missed a spot when converting name from a reference to a builtin string.,https://github.com/memcached/memcached/commit/0210db5d613e0f60d48dc068f64afb17c48477dd
memcached/memcached,https://github.com/memcached/memcached,b4db7c3,dormando,2024-03-10T17:17:24Z,"proxy: fix leak in config reload  - config reload loads the code from disk, then dumps it into an internal   binary blob - that binary blob is loaded from memory into each worker thread - that temporary blob wasn't being freed  if you have large initial lua and reload every second for hours on end you'd leak a few megs of ram",https://github.com/memcached/memcached/commit/b4db7c3855c22c5b6cfcbabffd760e1808144e2e
memcached/memcached,https://github.com/memcached/memcached,221f4d1,dormando,2024-03-08T22:41:17Z,"proxy: allow early freeing rcontexts  Any allocated request context would stay in memory attached to its function generator until the next reload, which would replace the function generators. A replaced fgen would eventually run out of attach references and cleanup itself, removing all rcontexts.  A one-time burst of concurrent request contexts would thus take up memory forever. With this change we use an easing function to slowly free unneeded request contexts.  This can help for both memory usage scenarios and instances where the GC is still used in the request path and tail latency can become poor.",https://github.com/memcached/memcached/commit/221f4d1f07467cd0c04571bec302dd0388bf3c2e
memcached/memcached,https://github.com/memcached/memcached,3304459,dormando,2024-03-06T19:31:30Z,"proxy: add new request meta flag APIs  All throw errors if arguments are bad  `req:flag_add(""F"", token)`  If token is nil, just adds ""F"" to request. If token is ""example"", adds ""Fexample"" to request. returns boolean false if failed (flag exists, request too long)  `req:flag_set(""F"", token)`  If token is nil, adds ""F"" to request. If token is ""example"", adds ""Fexample"" to request. If request had flag with a token, but supplied token is nil, will remove token from flag in the request. returns boolean false if failed (request too long)  `req:flag_replace(""F"", ""N"", token)`  If token is nil, adds ""N"" to request. If token is ""example"", adds ""Nexample"" to request. returns boolean false if failed (request too long)  `req:flag_del(""F"")`  If flag and/or flag+token exists, delete from request.  These functions are able to modify the underlying request string without creating lua string garbage. IE:  `req:flag_add(""F"" .. token)` would create a new string then pass that into the function, needing to GC it later.",https://github.com/memcached/memcached/commit/3304459c0956bd13d34ea42064a66071cc5bf73e
memcached/memcached,https://github.com/memcached/memcached,156ca80,dormando,2024-03-06T19:21:19Z,"tests: add T_MEMD_EXTERNAL  If environment variable T_MEMD_EXTERNAL exists when tests run, a request to start a memcached daemon will instead print the command line and wait for the user to start the daemon (ie; in GDB). it will poll and continue the tests as soon as it can connect.  This is simpler than the old method I was using for T_MEMD_USE_MEMD where you'd manually start a memcached then run the test.",https://github.com/memcached/memcached/commit/156ca8048a3738795acffef8a3adfb60ccc9b3a5
memcached/memcached,https://github.com/memcached/memcached,d9bf02f,Fabrice Fontaine,2024-02-28T08:35:53Z,fix build on uclibc-ng  Fix the following build failure with uclibc-ng raised since version 1.6.18 and https://github.com/memcached/memcached/commit/875371a75cbf1f92350de2d1fa0fae4a35ed572b:  /home/buildroot/autobuild/instance-2/output-1/host/lib/gcc/arc-buildroot-linux-uclibc/10.2.0/../../../../arc-buildroot-linux-uclibc/bin/ld: memcached-thread.o: in function `thread_setname': thread.c:(.text+0xea2): undefined reference to `pthread_setname_np'  Fixes:  - http://autobuild.buildroot.org/results/e856d381f5ec7d2727f21c8bd46dacb456984416  Signed-off-by: Fabrice Fontaine <fontaine.fabrice@gmail.com>,https://github.com/memcached/memcached/commit/d9bf02f6331fc0098af8997d2a571fc4525696fc
memcached/memcached,https://github.com/memcached/memcached,1b3b855,dormando,2024-02-27T22:20:57Z,"core: fix issues with `-o slab_chunk_max=kb`  wasn't exiting on error conditions! was also asking for kilobytes then accepting bytes. Decided to change the behavior instead of the text, and add a guard rail for obvious byte inputs.",https://github.com/memcached/memcached/commit/1b3b8555734f9b7b8d979924c7f8d6cf82194ba8
memcached/memcached,https://github.com/memcached/memcached,1776b02,dormando,2024-02-27T22:06:42Z,"proto: fix exptime in debug command  the ""meta"" command which would dump item data had the expiration calculation backwards, leading to a negative exptime value.  Reported in #1100",https://github.com/memcached/memcached/commit/1776b021e4d0ddc9975ef7fb1a9db0ebdab93f45
memcached/memcached,https://github.com/memcached/memcached,2bc409e,Ing-eoking,2024-01-25T06:28:33Z,"fix: prevent giving negative number with -R, -m options",https://github.com/memcached/memcached/commit/2bc409e8b464579b996f4d19cfc99748ea934a21
memcached/memcached,https://github.com/memcached/memcached,aceefca,Fabrice Fontaine,2023-09-24T15:05:07Z,"logger.c: initialize rport  Fix the following build failure raised since version 1.6.11 and https://github.com/memcached/memcached/commit/617d7cd64d04698b76fee74882627690017e20ad:  logger.c: In function '_logger_parse_cce': logger.c:297:13: error: 'rport' may be used uninitialized in this function [-Werror=maybe-uninitialized]   297 |     total = snprintf(scratch, LOGGER_PARSE_SCRATCH,       |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   298 |             ""ts=%d.%d gid=%llu type=conn_close rip=%s rport=%hu transport=%s reason=%s cfd=%d\n"",       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   299 |             (int) e->tv.tv_sec, (int) e->tv.tv_usec, (unsigned long long) e->gid,       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   300 |             rip, rport, transport_map[le->transport],       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   301 |             reason_map[le->reason], le->sfd);       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  Fixes:  - http://autobuild.buildroot.org/results/7a46ac38d10b1859034017e0294961daa8f48dd2  Signed-off-by: Fabrice Fontaine <fontaine.fabrice@gmail.com>",https://github.com/memcached/memcached/commit/aceefca9bc7635eab4893f626aec78e9966db93c
memcached/memcached,https://github.com/memcached/memcached,e5a3050,Finn Frankis,2024-02-15T17:40:18Z,crawler: include client flags in metadump output,https://github.com/memcached/memcached/commit/e5a305085df64826cf04e6e4275dac6e43c0bd94
memcached/memcached,https://github.com/memcached/memcached,707eecf,dormando,2024-02-20T00:43:27Z,"extstore: fix CAS changing during recache  If an item is recached from disk back into main cache memory, its CAS value would update. This was likely unintentional.  The recache feature isn't commonly used so this was hard to track.",https://github.com/memcached/memcached/commit/707eecf941c5df3b957e174f4f747f0630e08b22
memcached/memcached,https://github.com/memcached/memcached,2b97c38,dormando,2024-02-20T00:21:50Z,"slabs: fix CAS changing during page move rescues  When a slab page is being moved between slab classes, it might have valid memory in it still. In these cases we try to ""rescue"" the item by moving it into free memory within the source slab class and updating its entry in the hash table.  During this move, we were accidentally updating the CAS value. This one-liner + test fixes this.",https://github.com/memcached/memcached/commit/2b97c389f0726131688f6a8bb8f9da2e9aa66327
memcached/memcached,https://github.com/memcached/memcached,7d2a68c,dormando,2024-01-18T02:15:07Z,"proxy: add global rate limiter  If created during mcp_config_pools() and then passed into mcp_config_routes(), utilizes a centralized rate limiter.  Generalizes the ""proxied reference counting"" that the pools system uses so it can be reused here. This is a system where:  - The object memory is created/managed/owned by the ""configuration VM"" - The object is used from worker VM's, thus needs a local lua object to   represent it.  A ""proxy"" object is created in each worker VM, which just points back to the global memory.  When all of the ""proxy"" objects are GC'ed from all worker VM's, a management thread is notified and the object is unreferenced from the configuration VM, allowing it to be GC collected.",https://github.com/memcached/memcached/commit/7d2a68cc29f544f57f74f214419f6c2b6152685b
memcached/memcached,https://github.com/memcached/memcached,9425a89,dormando,2024-02-15T17:59:33Z,proxy: add lua registry dump functions  helpful for finding memory leaks in C-side references.,https://github.com/memcached/memcached/commit/9425a89acd9e823fae02621b95259ececce71f6f
memcached/memcached,https://github.com/memcached/memcached,20744e6,dormando,2024-02-15T17:58:00Z,"proxy: fix memory leaks when freeing funcgens  Wasn't releasing the generator function, argument table, or persistent response objects.",https://github.com/memcached/memcached/commit/20744e6cb25146d861d644bac6eab6c667bbfa03
memcached/memcached,https://github.com/memcached/memcached,2980d34,dormando,2024-02-15T17:56:28Z,proxy: fix leak of `nil`s during reload  Would add a single `nil` entry to the worker VM's on reloads.  Note that this would only stack if you were just reloading and not doing anything else; the worker VM stack is fully reset after certain common functions.,https://github.com/memcached/memcached/commit/2980d3489feb37452debb1bf35cf64697e2008dd
memcached/memcached,https://github.com/memcached/memcached,6cee41c,dormando,2024-02-15T06:23:35Z,"proxy: fix leak of unassigned fgens  if a function generator was created but never referenced, it would not get properly cleaned up from the GC function, since self_ref was never being set and we shortcut the cleanup routine without self_ref.  now we only shortcut if no self ref and not closed.",https://github.com/memcached/memcached/commit/6cee41c893b0ce0031015e272165450b1a9fd6d3
memcached/memcached,https://github.com/memcached/memcached,9afc420,dormando,2024-02-15T05:57:15Z,"proxy: fix router accounting in `stats proxyfuncs`  ""router"" objects were being counted as anonymous generators, but only when being freed up, leading to negative ""anonymous"" values.  Now they are both incremented and decremented properly, under ""mcp_router""",https://github.com/memcached/memcached/commit/9afc420a36e6c124588423461c50c0c374149088
memcached/memcached,https://github.com/memcached/memcached,5cee151,dormando,2024-02-15T05:05:29Z,proxy: fix crash in `stats proxyfuncs`  Was popping the key during a table walk if a funcgen count was zero.,https://github.com/memcached/memcached/commit/5cee1510fde192661d66e12248747272676aadb5
memcached/memcached,https://github.com/memcached/memcached,4d02d80,dormando,2024-01-29T19:20:56Z,proxy: extra output for proxylimits.t,https://github.com/memcached/memcached/commit/4d02d804a0c70497e91991f1fa671033b0c6b522
memcached/memcached,https://github.com/memcached/memcached,9ed2b44,dormando,2024-01-28T18:46:18Z,"proxy: fix bug in config reload cleanup phase  In mcp_funcgen_cleanup there is a loop that frees all of the referenced subrctx's, then a second loop that frees the top level funcgen references that were held. In the second loop I was treating a subfgen as a subrctx. Weirdly I'm pretty sure that code had test coverage!  This is obviously the right fix: will figure out what went wrong with tests later.",https://github.com/memcached/memcached/commit/9ed2b44d4ed7f02d762d3838739de473324f7c99
memcached/memcached,https://github.com/memcached/memcached,d2258ab,dormando,2024-01-22T18:17:28Z,"proxy: fix unlocked usage of config VM  This bug means under some conditions it's possible for the Lua configuration VM to be accessed by multiple threads, leading to corruption. Found by eyeballing it.  In practice this is likely impossible to trigger: only two threads access the configuration VM: - Config thread - Config Manager thread (handles GC'ing of pools)  The manager thread only activates after a configuration reload when old pool objects are being reaped. It's also only possible to trigger a configuration reload once per second.  We also _do_ use the configuration lock for most of the manager thread, the bug just unlocks it early. This means to produce an error you would need to:  - Issue a reload - Reload completes - Some in-flight requests hold the old pool-objects open - Issue another reload (minimum time 1s) - A pool object GC's at the same time as the reload is triggered - The configuration thread serializes behind the manger thread and   blocks on the config lock during a _very_ narrow window. - Manager thread releases lock - Configuration thread acquires lock - Manager thread issues lua GC calls while config thread is doing other   things - Now config VM crash/corruption.  If you're issuing reloads more than a few seconds apart the odds of triggering this bug are zero.",https://github.com/memcached/memcached/commit/d2258ab13ea9e34da1c6368af22222b07a2703c4
memcached/memcached,https://github.com/memcached/memcached,494fbb4,dormando,2024-01-09T23:59:23Z,proxy: remove API docs from t/proxyfuncgen.lua  they live on the wiki now. were slightly wrong anyway.,https://github.com/memcached/memcached/commit/494fbb4e707ea690365a3f61b1757aa6253d851f
memcached/memcached,https://github.com/memcached/memcached,490a4aa,dormando,2024-01-09T04:41:40Z,proxy: command map router default routes  Allow adding CMD_ANY_STORAGE as a sub-default in a command map under a router. Also ensures we fall back to the top level router default if a command map does not have an exact match.,https://github.com/memcached/memcached/commit/490a4aa483e0073735d636c57ed5a7056e06ada3
memcached/memcached,https://github.com/memcached/memcached,b80e2a5,dormando,2024-01-09T04:09:37Z,proxy: add mcp.backend_use_iothread(bool) + bufix  We no longer use the iothread by default; instead we use the worker threads. This gives better scaling and performance by default.  Switching this around exposed two bugs:  1) For some reason I had un-fixed (bad rebase?) a bug causing pipelines    to a single backend to be reversed specifically with worker io. 2) A crash bug with failing to NULL out the read buffer pointer in    response objects once freed.  Need to add another set of tests that specifically validates pipelined ordering for both iothread and not iothread.,https://github.com/memcached/memcached/commit/b80e2a5385a9b7150c71a25174f496d10710dd57
memcached/memcached,https://github.com/memcached/memcached,1518d89,dormando,2023-08-18T16:44:42Z,"proxy: lua API version 2  See t/proxyfuncgen.lua for documentation on API changes.  See also https://github.com/memcached/memcached/wiki/Proxy  This change revolves around holding context during request execution. Previously the lua context simply ""floated"", being carried with a backend IO request when necessary and resumed during a later callback. It was not possible to know things for the full duration of a request. It was also not possible to hold references for the full duration of a request.  For example, previously when lua executes a request against a single pool (pool(req) syntax), the pool and request objects are held in the coroutine's execution stack, then the coroutine is suspended. This prevents the pool from being garbage collected while the request executes. Nothing else explicitly prevents this from happening.  Nor can we pre-allocate memory and request objects. In a typical request, at minimum:  - a coroutine thread is allocated - a request object is allocated - response objects are allocated - any strings are allocated - all of the above must later be garbage collected.  This can add up to a lot of CPU. Object creation is especially slow (setting metatables) and argument checking can get expensive. This puts a high floor on the CPU usage of a request. With pre-allocation it should be possible to run a request from start to finish with zero allocations (and thus zero garbage collection).  Further, the ""async API"" available via mcp.await was supposed to be a temporary workaround before making the API change available in this pull request. mcp.await is implemented by bolting itself over the existing system, with hacks to know when to resume the coroutine. Further, it creates even more allocations:  - the await tracking object - a table to hold the response objects to be returned to lua  ... and itself is limited. There is no way to execute callbacks, to execute different requests against different pools, to wait on specific pools, and so on.  Further, there is no way to compose a configuration as a directed graph, as was done with mcrouter and similar systems. Without this configurations are less composible, requiring significant code changes to do things like shadow traffic, pre-warm pools, and so on.  ---  We now use a request context to track an incoming request until the response has been sent to the client. We use a pre-generation stage to allow pre-allocating objects, caching lookups, creating callback contexts, and so on. These pre-allocted request contexts and their associated functions are re-used until the configuration is reloaded and overwritten.  The new API allows for composing configurations as a directed graph, composing functions that can call either pools or other functions directly.",https://github.com/memcached/memcached/commit/1518d8950eec537c726ea3f4358625cf6d1427ab
memcached/memcached,https://github.com/memcached/memcached,2ded557,dormando,2023-11-30T23:25:57Z,"proxy: add mcp.time_[real|mono]_millis()  time_real_millis returns the wall clock time milliseconds time_mono_millis returns ""stable"" clock milliseconds, usually starting from the process start time.",https://github.com/memcached/memcached/commit/2ded557497f3771409984466a83a8c32d33b793a
memcached/memcached,https://github.com/memcached/memcached,86b87fb,dormando,2023-11-10T04:35:53Z,proxy: modify dump_stack() debug func,https://github.com/memcached/memcached/commit/86b87fb2885914d2ff292eede89c5cd4fac035c7
