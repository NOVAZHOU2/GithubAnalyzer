# src/github_analyzer.py
import requests
import time
import json
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import os
from dotenv import load_dotenv
import logging
import csv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ProjectConfig:
    """é¡¹ç›®é…ç½®ç±»"""
    min_stars: int = 1000
    max_projects: int = 5
    commits_per_project: int = 20
    language: str = "C"
    per_page: int = 100
    sort: str = "stars"
    order: str = "desc"


class GitHubAPI:
    """GitHub APIå®¢æˆ·ç«¯"""

    def __init__(self, token: Optional[str] = None):
        self.token = token or os.getenv("GITHUB_TOKEN")
        self.user_agent = os.getenv("GITHUB_USER_AGENT", "GitHub-Commit-Analyzer")
        self.timeout = int(os.getenv("REQUEST_TIMEOUT", 30))
        self.max_retries = int(os.getenv("MAX_RETRIES", 3))

        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": self.user_agent
        }

        if self.token:
            self.headers["Authorization"] = f"token {self.token}"

        # API çŠ¶æ€è·Ÿè¸ª
        self.remaining_requests = 60
        self.reset_time = 0

    def _check_rate_limit(self, response_headers):
        """æ£€æŸ¥å¹¶å¤„ç†APIé€Ÿç‡é™åˆ¶"""
        if 'X-RateLimit-Remaining' in response_headers:
            self.remaining_requests = int(response_headers['X-RateLimit-Remaining'])

        if 'X-RateLimit-Reset' in response_headers:
            self.reset_time = int(response_headers['X-RateLimit-Reset'])

        if self.remaining_requests < 10:
            wait_time = max(self.reset_time - int(time.time()), 0) + 5
            if wait_time > 0:
                logger.warning(f"APIè¯·æ±‚å‰©ä½™ {self.remaining_requests} æ¬¡ï¼Œç­‰å¾… {wait_time} ç§’")
                time.sleep(wait_time)

    def search_c_projects(self, min_stars: int, max_projects: int = 5) -> List[Dict]:
        """æœç´¢Cè¯­è¨€é¡¹ç›®"""
        projects = []
        page = 1

        logger.info(f"ğŸ” æœç´¢Cè¯­è¨€é¡¹ç›®ï¼Œæœ€å°staræ•°: {min_stars}")

        while len(projects) < max_projects:
            query = f"language:C stars:>={min_stars}"
            params = {
                "q": query,
                "sort": "stars",
                "order": "desc",
                "per_page": min(100, max_projects - len(projects)),
                "page": page
            }

            try:
                response = requests.get(
                    "https://api.github.com/search/repositories",
                    headers=self.headers,
                    params=params,
                    timeout=self.timeout
                )

                self._check_rate_limit(response.headers)

                if response.status_code == 200:
                    data = response.json()
                    items = data.get("items", [])

                    for item in items:
                        if len(projects) >= max_projects:
                            break

                        project_info = {
                            "name": item["name"],
                            "full_name": item["full_name"],
                            "owner": item["owner"]["login"],
                            "html_url": item["html_url"],
                            "description": item["description"] or "No description",
                            "stars": item["stargazers_count"],
                            "language": item["language"],
                            "created_at": item["created_at"],
                            "updated_at": item["updated_at"]
                        }
                        projects.append(project_info)

                        logger.info(f"ğŸ“¦ æ‰¾åˆ°é¡¹ç›®: {item['full_name']} (â­ {item['stargazers_count']})")

                elif response.status_code == 403:
                    logger.error("APIè¯·æ±‚è¢«é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•æˆ–æ·»åŠ GitHub Token")
                    break
                else:
                    logger.error(f"æœç´¢å¤±è´¥: {response.status_code}")
                    break

            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
                break

            page += 1
            time.sleep(1)  # é¿å…è¿‡å¿«è¯·æ±‚

        logger.info(f"âœ… å…±æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®")
        return projects

    def get_project_total_commits(self, owner: str, repo: str) -> int:
        """è·å–é¡¹ç›®çš„æ€»commitæ•°"""
        try:
            url = f"https://api.github.com/repos/{owner}/{repo}"
            response = requests.get(url, headers=self.headers, timeout=self.timeout)

            if response.status_code == 200:
                data = response.json()
                return data.get("size", 0)  # ä»“åº“å¤§å°å¯ä»¥ä½œä¸ºå‚è€ƒ
        except Exception as e:
            logger.warning(f"è·å–é¡¹ç›®{owner}/{repo}ä¿¡æ¯å¤±è´¥: {e}")

        return 0  # å¦‚æœæ— æ³•è·å–ï¼Œè¿”å›0

    def get_commits(self, owner: str, repo: str, max_commits: int = 20) -> List[Dict]:
        """è·å–é¡¹ç›®çš„commits - ç±»ä¼¼å›¾ç‰‡ä¸­çš„æ ¼å¼"""
        commits = []
        page = 1
        total_commits_obtained = 0
        max_attempts = 10  # æœ€å¤§å°è¯•é¡µæ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯

        logger.info(f"ğŸ“„ è·å– {owner}/{repo} çš„æäº¤è®°å½•ï¼ŒæœŸæœ›è·å– {max_commits} æ¡...")

        # å…ˆè·å–é¡¹ç›®çš„æ€»commitæ•°ï¼ˆä¼°ç®—ï¼‰
        total_commits_estimate = self.get_project_total_commits(owner, repo)
        if total_commits_estimate > 0:
            logger.info(f"ğŸ“Š é¡¹ç›® {owner}/{repo} é¢„è®¡æœ‰ {total_commits_estimate} æ¡commit")
            # å¦‚æœæ€»commitæ•°å°äºè¯·æ±‚æ•°ï¼Œåˆ™è°ƒæ•´max_commits
            if total_commits_estimate < max_commits:
                max_commits = total_commits_estimate
                logger.info(f"ğŸ”§ è°ƒæ•´è·å–æ•°é‡ä¸º: {max_commits} æ¡")

        attempts = 0
        while len(commits) < max_commits and attempts < max_attempts:
            per_page = min(100, max_commits - len(commits))
            url = f"https://api.github.com/repos/{owner}/{repo}/commits"
            params = {
                "per_page": per_page,
                "page": page
            }

            try:
                response = requests.get(
                    url,
                    headers=self.headers,
                    params=params,
                    timeout=self.timeout
                )

                self._check_rate_limit(response.headers)

                if response.status_code == 200:
                    commit_data = response.json()

                    # å¦‚æœæ²¡æœ‰æ•°æ®äº†ï¼Œè¯´æ˜å·²ç»è·å–äº†æ‰€æœ‰commit
                    if not commit_data:
                        logger.info(f"ğŸ“­ å·²è·å–æ‰€æœ‰å¯ç”¨commitï¼Œå…± {len(commits)} æ¡")
                        break

                    current_batch_count = 0
                    for commit_item in commit_data:
                        if len(commits) >= max_commits:
                            break

                        # åªè·å–éœ€è¦çš„å­—æ®µï¼Œç±»ä¼¼å›¾ç‰‡ä¸­çš„æ ¼å¼
                        commit_info = {
                            "sha_short": commit_item["sha"][:7],
                            "message": commit_item["commit"]["message"],
                            "title": self._extract_commit_title(commit_item["commit"]["message"]),
                            "author_name": commit_item["commit"]["author"]["name"],
                            "author_date": commit_item["commit"]["author"]["date"],
                            "html_url": commit_item["html_url"]
                        }
                        commits.append(commit_info)
                        current_batch_count += 1

                    total_commits_obtained += current_batch_count

                    # æ˜¾ç¤ºè¿›åº¦
                    if len(commits) % 10 == 0 or current_batch_count < per_page:
                        logger.info(f"  å·²è·å– {len(commits)} æ¡æäº¤è®°å½•")

                    # å¦‚æœè¿™ä¸€æ‰¹æ•°æ®é‡å°äºè¯·æ±‚çš„per_pageï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šæ•°æ®äº†
                    if current_batch_count < per_page:
                        logger.info(f"ğŸ“­ å·²è·å–æ‰€æœ‰å¯ç”¨commitï¼Œå…± {len(commits)} æ¡")
                        break

                elif response.status_code == 404:
                    logger.warning(f"ä»“åº“ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {owner}/{repo}")
                    break
                elif response.status_code == 409:  # ç©ºä»“åº“
                    logger.warning(f"ä»“åº“ {owner}/{repo} ä¸ºç©º")
                    break
                elif response.status_code == 422:  # åˆ†é¡µè¶…å‡ºèŒƒå›´
                    logger.info(f"ğŸ“­ å·²è·å–æ‰€æœ‰commitï¼Œå…± {len(commits)} æ¡")
                    break
                else:
                    logger.error(f"è·å–æäº¤å¤±è´¥: {response.status_code}")
                    break

            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
                break

            page += 1
            attempts += 1
            time.sleep(0.5)  # é¿å…è¿‡å¿«è¯·æ±‚

        # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœå®é™…è·å–çš„commitæ•°å°äºè¯·æ±‚æ•°ï¼Œç»™å‡ºæç¤º
        if len(commits) < max_commits:
            logger.info(f"ğŸ“Š å®é™…è·å– {len(commits)} æ¡commitï¼ˆå°äºè¯·æ±‚çš„ {max_commits} æ¡ï¼‰")

        logger.info(f"âœ… æœ€ç»ˆè·å–åˆ° {len(commits)} æ¡æäº¤è®°å½•")
        return commits

    def _extract_commit_title(self, message: str) -> str:
        """æå–commitæ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰"""
        lines = message.split('\n')
        if lines:
            return lines[0].strip()
        return message

    def get_commit_details(self, owner: str, repo: str, sha: str) -> Optional[Dict]:
        """è·å–å•ä¸ªcommitçš„è¯¦ç»†ä¿¡æ¯"""
        url = f"https://api.github.com/repos/{owner}/{repo}/commits/{sha}"

        try:
            response = requests.get(
                url,
                headers=self.headers,
                timeout=self.timeout
            )

            if response.status_code == 200:
                return response.json()
        except Exception as e:
            logger.error(f"è·å–commitè¯¦æƒ…å¤±è´¥: {e}")

        return None


class CommitAnalyzer:
    """Commitåˆ†æå™¨"""

    def __init__(self, config: ProjectConfig, output_dir: str = "output"):
        """åˆå§‹åŒ–åˆ†æå™¨ï¼ŒæŒ‡å®šè¾“å‡ºç›®å½•"""
        self.config = config
        self.github = GitHubAPI()
        self.projects = []
        self.project_commits = {}  # é¡¹ç›®å -> commitsåˆ—è¡¨
        self.output_dir = output_dir

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•è®¾ç½®ä¸º: {os.path.abspath(self.output_dir)}")

    def _get_output_path(self, filename: str) -> str:
        """è·å–è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        return os.path.join(self.output_dir, filename)

    def run(self):
        """è¿è¡Œåˆ†æ"""
        print("=" * 60)
        print("GitHub Cé¡¹ç›®æäº¤åˆ†æå·¥å…·")
        print("=" * 60)
        print(f"è¾“å‡ºç›®å½•: {os.path.abspath(self.output_dir)}")
        print()

        # 1. æœç´¢é¡¹ç›®
        self.projects = self.github.search_c_projects(
            min_stars=self.config.min_stars,
            max_projects=self.config.max_projects
        )

        if not self.projects:
            logger.error("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")
            return

        # ä¿å­˜é¡¹ç›®ä¿¡æ¯åˆ°outputç›®å½•
        self.save_projects_csv()

        # 2. è·å–æ¯ä¸ªé¡¹ç›®çš„commits
        total_expected_commits = 0
        total_actual_commits = 0

        for i, project in enumerate(self.projects, 1):
            print(f"\n[{i}/{len(self.projects)}] åˆ†æé¡¹ç›®: {project['full_name']}")

            # è·å–commits
            commits = self.github.get_commits(
                owner=project["owner"],
                repo=project["name"],
                max_commits=self.config.commits_per_project
            )

            if commits:
                self.project_commits[project["full_name"]] = {
                    "project": project,
                    "commits": commits
                }

                # ç»Ÿè®¡commitæ•°é‡
                expected = self.config.commits_per_project
                actual = len(commits)
                total_expected_commits += expected
                total_actual_commits += actual

                # æ˜¾ç¤ºè·å–æƒ…å†µ
                if actual < expected:
                    print(f"   ğŸ“Š è·å–æƒ…å†µ: {actual}/{expected} æ¡commit")
                else:
                    print(f"   âœ… æˆåŠŸè·å–: {actual} æ¡commit")

                # ä¿å­˜æ¯ä¸ªé¡¹ç›®çš„æ•°æ®åˆ°outputç›®å½•
                self.save_project_commits_csv(project, commits)

        # 3. ä¿å­˜åˆå¹¶çš„è¡¨æ ¼åˆ°outputç›®å½•
        if self.project_commits:
            # ä¿å­˜ä¸ºç±»ä¼¼å›¾ç‰‡çš„æ ¼å¼
            self.save_picture_format_csv()
            # ä¿å­˜ä¸ºåˆå¹¶è¡¨æ ¼
            self.save_combined_table()
            # ä¿å­˜ä¸ºMarkdownæ ¼å¼
            self.save_markdown_table()

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self.print_summary(total_expected_commits, total_actual_commits)

    def save_projects_csv(self, filename: str = "projects.csv"):
        """ä¿å­˜é¡¹ç›®ä¿¡æ¯åˆ°CSVï¼ˆåœ¨outputç›®å½•ä¸‹ï¼‰"""
        filepath = self._get_output_path(filename)

        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(["åºå·", "é¡¹ç›®åç§°", "é¡¹ç›®URL", "Staræ•°", "æè¿°", "åˆ›å»ºæ—¶é—´", "æ›´æ–°æ—¶é—´"])

            for i, project in enumerate(self.projects, 1):
                writer.writerow([
                    i,
                    project["full_name"],
                    project["html_url"],
                    project["stars"],
                    project["description"],
                    project["created_at"],
                    project["updated_at"]
                ])

        logger.info(f"âœ… é¡¹ç›®åˆ—è¡¨å·²ä¿å­˜åˆ° {filepath}")

    def save_project_commits_csv(self, project: Dict, commits: List[Dict], filename: str = None):
        """ä¿å­˜å•ä¸ªé¡¹ç›®çš„commitsåˆ°CSVï¼ˆåœ¨outputç›®å½•ä¸‹ï¼‰"""
        if not filename:
            safe_name = project["full_name"].replace("/", "_").replace("\\", "_")
            filename = f"{safe_name}_commits.csv"

        filepath = self._get_output_path(filename)

        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(["é¡¹ç›®åç§°", "é¡¹ç›®URL", "æäº¤ID", "æäº¤è€…", "æäº¤æ—¶é—´", "æäº¤ä¿¡æ¯", "æäº¤é“¾æ¥"])

            for commit in commits:
                writer.writerow([
                    project["full_name"],
                    project["html_url"],
                    commit["sha_short"],
                    commit["author_name"],
                    commit["author_date"],
                    commit["message"].replace('\n', ' '),  # ç§»é™¤æ¢è¡Œç¬¦
                    commit["html_url"]
                ])

        logger.info(f"ğŸ“ æäº¤è®°å½•å·²ä¿å­˜åˆ° {filepath}")
        return filepath

    def save_picture_format_csv(self, filename: str = "commits_picture_format.csv"):
        """ä¿å­˜ä¸ºå›¾ç‰‡ä¸­çš„æ ¼å¼ï¼ˆåœ¨outputç›®å½•ä¸‹ï¼‰"""
        filepath = self._get_output_path(filename)

        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            # å›¾ç‰‡ä¸­çš„è¡¨æ ¼æ ¼å¼
            writer.writerow(["Commitæ ‡é¢˜", "ä½œè€…å’Œæ—¶é—´", "Commité“¾æ¥"])

            all_commits = []
            for project_full_name, data in self.project_commits.items():
                project = data["project"]
                commits = data["commits"]

                for commit in commits:
                    # æ ¼å¼åŒ–æ—¶é—´ï¼ˆç±»ä¼¼å›¾ç‰‡ä¸­çš„"2 hours ago"æ ¼å¼ï¼‰
                    time_str = self.format_relative_time(commit["author_date"])
                    author_time = f"{commit['author_name']} committed {time_str}"

                    all_commits.append({
                        "title": commit["title"],
                        "author_time": author_time,
                        "url": commit["html_url"]
                    })

            # æŒ‰ç…§æ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            all_commits.sort(key=lambda x: x["author_time"], reverse=True)

            for commit in all_commits:
                writer.writerow([
                    commit["title"],
                    commit["author_time"],
                    commit["url"]
                ])

        logger.info(f"ğŸ–¼ï¸ å›¾ç‰‡æ ¼å¼è¡¨æ ¼å·²ä¿å­˜åˆ° {filepath}")
        return filepath

    def save_combined_table(self, filename: str = "all_commits.csv"):
        """ä¿å­˜åˆå¹¶è¡¨æ ¼ï¼ˆåœ¨outputç›®å½•ä¸‹ï¼‰"""
        filepath = self._get_output_path(filename)

        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(["é¡¹ç›®åç§°+URL", "æäº¤æ—¶é—´", "Commitæ ‡é¢˜", "Commit URL"])

            for project_full_name, data in self.project_commits.items():
                project = data["project"]
                commits = data["commits"]

                for commit in commits:
                    # æ ¼å¼åŒ–æ—¶é—´ï¼ˆç±»ä¼¼å›¾ç‰‡ä¸­çš„"2 hours ago"æ ¼å¼ï¼‰
                    time_str = self.format_relative_time(commit["author_date"])

                    writer.writerow([
                        f"{project['full_name']} ({project['html_url']})",
                        f"{commit['author_name']} committed {time_str}",
                        commit["title"],
                        commit["html_url"]
                    ])

        logger.info(f"âœ… åˆå¹¶è¡¨æ ¼å·²ä¿å­˜åˆ° {filepath}")
        return filepath

    def save_markdown_table(self, filename: str = "all_commits.md"):
        """ä¿å­˜ä¸ºMarkdownè¡¨æ ¼æ ¼å¼ï¼ˆåœ¨outputç›®å½•ä¸‹ï¼‰"""
        filepath = self._get_output_path(filename)

        with open(filepath, 'w', encoding='utf-8-sig') as f:
            f.write("# GitHub Cé¡¹ç›®æäº¤è®°å½•\n\n")
            f.write("> ç”Ÿæˆæ—¶é—´: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n\n")
            f.write("> è¾“å‡ºç›®å½•: " + os.path.abspath(self.output_dir) + "\n\n")

            for project_full_name, data in self.project_commits.items():
                project = data["project"]
                commits = data["commits"]

                f.write(f"## {project['full_name']}\n")
                f.write(f"- **é¡¹ç›®URL**: {project['html_url']}\n")
                f.write(f"- **Staræ•°**: {project['stars']}\n")
                f.write(f"- **æäº¤è®°å½•æ•°**: {len(commits)}\n\n")

                f.write("| Commitæ ‡é¢˜ | æäº¤è€… | æäº¤æ—¶é—´ | é“¾æ¥ |\n")
                f.write("|------------|--------|----------|------|\n")

                for commit in commits:
                    time_str = self.format_relative_time(commit["author_date"])
                    commit_title = commit["title"]

                    # ç¼©çŸ­è¿‡é•¿çš„æ ‡é¢˜
                    if len(commit_title) > 100:
                        commit_title = commit_title[:97] + "..."

                    f.write(
                        f"| {commit_title} | {commit['author_name']} | {time_str} | [æŸ¥çœ‹]({commit['html_url']}) |\n")

                f.write("\n---\n\n")

        logger.info(f"ğŸ“„ Markdownæ ¼å¼å·²ä¿å­˜åˆ° {filepath}")
        return filepath

    def format_relative_time(self, iso_time: str) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºç›¸å¯¹æ—¶é—´ï¼ˆå¦‚'2 hours ago'ï¼‰"""
        try:
            # è§£æISOæ—¶é—´
            commit_dt = datetime.fromisoformat(iso_time.replace('Z', '+00:00'))
            now_dt = datetime.now(commit_dt.tzinfo)

            # è®¡ç®—æ—¶é—´å·®
            delta = now_dt - commit_dt

            # è½¬æ¢ä¸ºç›¸å¯¹æ—¶é—´
            if delta.days > 365:
                years = delta.days // 365
                return f"{years} year{'s' if years > 1 else ''} ago"
            elif delta.days > 30:
                months = delta.days // 30
                return f"{months} month{'s' if months > 1 else ''} ago"
            elif delta.days > 0:
                if delta.days == 1:
                    return "1 day ago"
                else:
                    return f"{delta.days} days ago"
            elif delta.seconds >= 3600:
                hours = delta.seconds // 3600
                if hours == 1:
                    return "1 hour ago"
                else:
                    return f"{hours} hours ago"
            elif delta.seconds >= 60:
                minutes = delta.seconds // 60
                if minutes == 1:
                    return "1 minute ago"
                else:
                    return f"{minutes} minutes ago"
            else:
                return "just now"
        except:
            return iso_time

    def print_summary(self, total_expected: int, total_actual: int):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("åˆ†ææ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ“Š åˆ†æå®Œæˆï¼")
        print(f"  é¡¹ç›®æ•°é‡: {len(self.projects)}")

        print(f"   ğŸ“ˆ Commitè·å–ç»Ÿè®¡:")
        print(f"     æœŸæœ›è·å–: {total_expected} æ¡")
        print(f"     å®é™…è·å–: {total_actual} æ¡")

        if total_actual < total_expected:
            print(f"     âš ï¸  å®é™…è·å–å°‘äºæœŸæœ›å€¼")
        else:
            print(f"     âœ… æˆåŠŸè·å–æ‰€æœ‰æœŸæœ›çš„commit")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(self.output_dir)}")
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")

        # åˆ—å‡ºoutputç›®å½•ä¸‹çš„æ–‡ä»¶
        for filename in os.listdir(self.output_dir):
            if filename.endswith(('.csv', '.md')):
                filepath = os.path.join(self.output_dir, filename)
                size = os.path.getsize(filepath)
                print(f"   - {filename} ({size} bytes)")

        print(f"\nğŸ“ˆ é¡¹ç›®è¯¦æƒ…:")
        for i, project in enumerate(self.projects[:5], 1):
            commits = self.project_commits.get(project["full_name"], {}).get("commits", [])
            expected = self.config.commits_per_project
            actual = len(commits)
            status = "âœ…" if actual >= expected else "âš ï¸"
            print(f"{i:2d}. {project['full_name']:<30} â­ {project['stars']:<6} {status} {actual}/{expected} commits")

        if self.project_commits:
            print(f"\nğŸ“‹ æœ€è¿‘æäº¤ç¤ºä¾‹ï¼ˆå›¾ç‰‡æ ¼å¼ï¼‰:")
            for project_full_name, data in list(self.project_commits.items())[:1]:
                commits = data["commits"][:2] if len(data["commits"]) >= 2 else data["commits"]

                for commit in commits:
                    time_str = self.format_relative_time(commit["author_date"])
                    author_time = f"{commit['author_name']} committed {time_str}"
                    title = commit["title"]

                    if len(title) > 80:
                        title = title[:77] + "..."

                    print(f"\n{title}")
                    print(f"{author_time}")
                    print(f"{commit['html_url']}")